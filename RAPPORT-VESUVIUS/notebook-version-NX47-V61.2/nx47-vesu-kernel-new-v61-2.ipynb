{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed404a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T13:17:29.554932Z",
     "iopub.status.busy": "2026-02-18T13:17:29.554685Z",
     "iopub.status.idle": "2026-02-18T13:17:49.293083Z",
     "shell.execute_reply": "2026-02-18T13:17:49.292339Z"
    },
    "papermill": {
     "duration": 19.743258,
     "end_time": "2026-02-18T13:17:49.294752",
     "exception": false,
     "start_time": "2026-02-18T13:17:29.551494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/nx47-dependencies\n",
      "Processing /kaggle/input/nx47-dependencies/imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imagecodecs) (2.0.2)\n",
      "Installing collected packages: imagecodecs\n",
      "Successfully installed imagecodecs-2026.1.14\n",
      "Looking in links: /kaggle/input/nx47-dependencies\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (2025.10.16)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tifffile) (2.0.2)\n",
      "[1771420660117207566][SEQ:000001] LOGGER_INIT {\"gpu\": true}\n",
      "[1771420660150577546][SEQ:000001][SYSTEM][a78785b8e53f6bca] LOGGER_V28_INIT | DATA: {\"session\": \"cdffa7284d7d4c78\"}\n",
      "[1771420660151732338][SEQ:000002] NX47_OK {}\n",
      "[1771420660168252069][SEQ:000003] AIMO3_OK {}\n",
      "[1771420660383189268][SEQ:000004] FILES_READY {\"count\": 1}\n",
      "[1771420663379283635][SEQ:000002][INFO][c1439aa04c85d892] BLOC1_START: Performance brute CPU/Mémoire\n",
      "[1771420663380324892][SEQ:000003][INFO][cfe002ea92858277] BLOC1_TEST_CREATE_DESTROY: iterations=10000\n",
      "[1771420663396222827][SEQ:000004][METRIC][912ce07a2e415526] METRIC: B1_CREATE_DESTROY_OPS_SEC=1292959.3836204028ops/s\n",
      "[1771420663397171011][SEQ:000005][METRIC][fa27983e3a48dd7c] METRIC: B1_CREATE_DESTROY_MEAN=773.4195ns\n",
      "[1771420663398129183][SEQ:000006][INFO][2524c539ab404844] BLOC1_TEST_MOVE: size=1024, iterations=5000\n",
      "[1771420663402009789][SEQ:000007][METRIC][eed4cfc04c183a08] METRIC: B1_MOVE_THROUGHPUT=3.3312729756986235GB/s\n",
      "[1771420663402978726][SEQ:000008][INFO][4eec6791ea45e7f2] BLOC1_TEST_FUSE: n_elements=100, iterations=1000\n",
      "[1771420663435309337][SEQ:000009][METRIC][73e827967ec48b2a] METRIC: B1_FUSE_ELEM_SEC=9371261.45238434elem/s\n",
      "[1771420663436109237][SEQ:000010][INFO][82df06452a54b9b1] BLOC1_TEST_SPLIT: size=4096, splits=8, iterations=1000\n",
      "[1771420663439196983][SEQ:000011][METRIC][00d7caed1c81b2e2] METRIC: B1_SPLIT_PER_SEC=5391638.512204311splits/s\n",
      "[1771420663440077496][SEQ:000012][INFO][ae49256afaac2db9] BLOC1_TEST_ALIGN_AB: size=8192, iterations=2000\n",
      "[1771420663776305761][SEQ:000013][METRIC][9220f4caf792dbc1] METRIC: B1_ALIGN_SPEEDUP=0.6708206123054716x\n",
      "[1771420663777266418][SEQ:000014][INFO][0e0f757fa3b65de2] BLOC1_TEST_SCALING: base_work=10000, threads=[1, 2, 4]\n",
      "[1771420663781351610][SEQ:000015][METRIC][ffd10a87ebd0be83] METRIC: B1_SCALING_2T_EFF=55.90944708359861%\n",
      "[1771420663782138260][SEQ:000016][INFO][02a89db2ba2437bd] BLOC1_COMPLETE | DATA: {\"tests\": 6}\n",
      "[1771420663782853050 ns][AUDIT] SOLVER_INIT: sum all values\n",
      "[1771420663814646367][SEQ:000005] FUSION_SCORE_GLOBAL {\"file\": \"1407735.tif\", \"score\": 0.0}\n",
      "[1771420668964950296][SEQ:000006] FILE_DONE {\"file\": \"1407735.tif\", \"checksum\": \"1ffbed07500aba29\", \"slices\": 320}\n",
      "\n",
      "===== SLICE SUMMARY (ALL FILES) =====\n",
      "            latency_ms                                 fusion_score            \\\n",
      "                 count       mean       min        max        count mean  min   \n",
      "file                                                                            \n",
      "1407735.tif        320  13.962458  8.386568  1172.5619          320  0.0  0.0   \n",
      "\n",
      "                 weight            ...       p_hi             p_lo             \\\n",
      "             max  count      mean  ...        min        max count       mean   \n",
      "file                               ...                                          \n",
      "1407735.tif  0.0    320  0.181828  ...  90.633904  92.407372   320  85.542331   \n",
      "\n",
      "                                  w_mean                                \n",
      "                   min        max  count      mean       min       max  \n",
      "file                                                                    \n",
      "1407735.tif  84.633904  86.407372    320  0.109108  0.098496  0.120121  \n",
      "\n",
      "[1 rows x 24 columns]\n",
      "\n",
      "===== GLOBAL SLICE MEAN (ALL FILES) =====\n",
      "13.962458403124998 ms\n",
      "\n",
      "===== FILE CHECKSUMS =====\n",
      "       file         checksum  slices\n",
      "1407735.tif 1ffbed07500aba29     320\n",
      "[1771420669286661814][SEQ:000007] SUBMISSION_READY {\"zip\": \"/kaggle/working/submission.zip\"}\n",
      "[1771420669286722745][SEQ:000008] EXEC_COMPLETE {}\n",
      "READY: /kaggle/working/submission.zip\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NX47-VESU KERNEL V61.2 ULTRA-AGGRESSIVE++ ULTRA-DEBUG++ — ONE-CELL ULTRA-FORNSIC (V28-COMPAT)\n",
    "# GPU STRICT • NON-LINEAR FUSION • DYNAMIC SLICE WEIGHT • ABLATION READY\n",
    "# FULL SLICE-LOCAL LOGGING: fusion_score, weight, p_hi, p_lo, w\n",
    "# ============================================================\n",
    "\n",
    "# ---------------------- INSTALL (OFFLINE SAFE) ----------------------\n",
    "import sys, subprocess, os\n",
    "def install_offline(package_name):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", \"--find-links=/kaggle/input/nx47-dependencies\", package_name])\n",
    "    except:\n",
    "        print(f\"Offline install failed for {package_name}, attempting standard install...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package_name])\n",
    "\n",
    "install_offline(\"imagecodecs\")\n",
    "install_offline(\"tifffile\")\n",
    "\n",
    "# ---------------------- IMPORTS ----------------------\n",
    "import os, time, json, hashlib, gc, zipfile, threading, importlib.util\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------- GPU STRICT ----------------------\n",
    "GPU_STRICT = True\n",
    "try:\n",
    "    import cupy as cp\n",
    "    cp.cuda.runtime.getDeviceCount()\n",
    "    xp = cp\n",
    "    GPU = True\n",
    "except:\n",
    "    if GPU_STRICT:\n",
    "        raise RuntimeError(\"GPU REQUIRED — GPU_STRICT ENABLED\")\n",
    "    xp = np\n",
    "    GPU = False\n",
    "\n",
    "if GPU:\n",
    "    from cupyx.scipy.ndimage import gaussian_filter\n",
    "else:\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# ---------------------- PATHS ----------------------\n",
    "ROOT = Path(\"/kaggle/input/competitions/vesuvius-challenge-surface-detection\")\n",
    "TEST_DIR = ROOT / \"test_images\"\n",
    "OUT = Path(\"/kaggle/working/tmp\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "ZIP_PATH = Path(\"/kaggle/working/submission.zip\")\n",
    "\n",
    "# ---------------------- LOGGER ULTRA-DEBUG++ ----------------------\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.seq = 0\n",
    "        self.slice_rows = []\n",
    "        self.file_rows = []\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def _safe(self, v):\n",
    "        if hasattr(v, \"item\"): return v.item()\n",
    "        if isinstance(v, np.ndarray): return float(np.mean(v))\n",
    "        return v\n",
    "\n",
    "    def log(self, msg, data=None):\n",
    "        with self.lock:\n",
    "            self.seq += 1\n",
    "            payload = {k:self._safe(v) for k,v in (data or {}).items()}\n",
    "            print(f\"[{time.time_ns()}][SEQ:{self.seq:06d}] {msg} {json.dumps(payload)}\")\n",
    "\n",
    "    def slice_metric(self, file, z, latency_ns, fusion_score=None, weight=None, p_hi=None, p_lo=None, w=None):\n",
    "        self.slice_rows.append({\n",
    "            \"file\": file,\n",
    "            \"slice\": z,\n",
    "            \"latency_ms\": latency_ns / 1e6,\n",
    "            \"fusion_score\": fusion_score,\n",
    "            \"weight\": weight,\n",
    "            \"p_hi\": p_hi,\n",
    "            \"p_lo\": p_lo,\n",
    "            \"w_mean\": w if w is None else float(np.mean(w))\n",
    "        })\n",
    "\n",
    "    def file_metric(self, file, checksum, slices):\n",
    "        self.file_rows.append({\n",
    "            \"file\": file,\n",
    "            \"checksum\": checksum,\n",
    "            \"slices\": slices\n",
    "        })\n",
    "\n",
    "logger = Logger()\n",
    "logger.log(\"LOGGER_INIT\", {\"gpu\": GPU})\n",
    "\n",
    "# ---------------------- NX47 ----------------------\n",
    "sys.path.append(\"/kaggle/input/datasets/ndarray2000/nx47-arc-kernel-v2-fixed-py\")\n",
    "from nx47_arc_kernel_v2_fixed import PerformanceProofBloc1\n",
    "nx47 = PerformanceProofBloc1()\n",
    "logger.log(\"NX47_OK\")\n",
    "\n",
    "# ---------------------- AIMO3 ----------------------\n",
    "aimo3_path = \"/kaggle/input/datasets/ndarray2000/iamo3-shf-resonance-v3/aimo3_shf_resonance_v3.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"aimo3\", aimo3_path)\n",
    "aimo3 = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(aimo3)\n",
    "solve_aimo3 = aimo3.solve_enhanced\n",
    "logger.log(\"AIMO3_OK\")\n",
    "\n",
    "# ---------------------- TIFF ----------------------\n",
    "import tifffile\n",
    "def read_tiff(p):\n",
    "    return tifffile.imread(p).astype(np.float32)\n",
    "\n",
    "# ---------------------- AUTO THRESHOLD SLICE-LOCAL ----------------------\n",
    "def slice_percentiles(slice_data):\n",
    "    flat = slice_data.ravel()\n",
    "    p90 = np.percentile(flat, 90)\n",
    "    p95 = np.percentile(flat, 95)\n",
    "    std = np.std(flat)\n",
    "    hi = float(np.clip(88 + 6*(p95 - p90)/(std + 1e-6), 88, 96))\n",
    "    lo = max(hi - 6, 80)\n",
    "    return hi, lo\n",
    "\n",
    "# ---------------------- PROCESS ONE FILE ----------------------\n",
    "def process_file(path, ablation=None, ultra_aggressive=True):\n",
    "    t_file = time.time_ns()\n",
    "\n",
    "    vol = read_tiff(path)\n",
    "    vol = (vol - vol.min()) / (vol.max() - vol.min() + 1e-6)\n",
    "    vol_gpu = xp.asarray(vol)\n",
    "\n",
    "    sigma = float(xp.std(vol_gpu) * 0.9 + 0.4)\n",
    "    smooth = gaussian_filter(vol_gpu, sigma=sigma)\n",
    "    resid = vol_gpu - smooth\n",
    "\n",
    "    # ----- SCORES (REAL, DYNAMIC) -----\n",
    "    nx_vals = [v for v in nx47.run_all().values() if isinstance(v,(int,float))]\n",
    "    nx_score = float(np.mean(nx_vals)) if nx_vals else 0.0\n",
    "    a3 = solve_aimo3(\"sum all values\")\n",
    "    a3_score = float(np.mean(list(a3.values()))) if isinstance(a3,dict) and a3 else 0.0\n",
    "\n",
    "    # ----- ABLATION CONTROL -----\n",
    "    if ablation == \"nx47\": a3_score = 0.0\n",
    "    if ablation == \"aimo3\": nx_score = 0.0\n",
    "\n",
    "    # ----- NON-LINEAR FUSION -----\n",
    "    fusion_score_global = 0.7*np.tanh(nx_score*2.0) + 0.3*np.tanh(a3_score*2.5)\n",
    "\n",
    "    # ----- ULTRA-AGGRESSIVE ADAPTIVE BOOST -----\n",
    "    if ultra_aggressive:\n",
    "        vol_std_global = float(xp.std(vol_gpu))\n",
    "        fusion_score_global *= 1.0 + 0.5*np.tanh(vol_std_global*1.5)\n",
    "\n",
    "    logger.log(\"FUSION_SCORE_GLOBAL\", {\"file\": path.name, \"score\": fusion_score_global})\n",
    "\n",
    "    Z = vol_gpu.shape[0]\n",
    "    out = []\n",
    "\n",
    "    for z in range(Z):\n",
    "        t0 = time.time_ns()\n",
    "        z0, z1 = max(0, z-1), min(Z, z+2)\n",
    "        proj = xp.mean(resid[z0:z1], axis=0)\n",
    "\n",
    "        # ----- LOCAL MULTI-SCALE VARIANCE -----\n",
    "        local_vol = vol_gpu[max(0,z-2):min(Z,z+3)]\n",
    "        local_std = float(xp.std(local_vol))\n",
    "\n",
    "        # ----- ULTRA-AGGRESSIVE WEIGHT DYNAMIC (FUSION SCORE IMPACT) -----\n",
    "        weight_base = 0.15\n",
    "        if ultra_aggressive:\n",
    "            weight = weight_base + 0.25*np.tanh(fusion_score_global)*np.tanh(local_std*2.0) \\\n",
    "                     + 0.1*np.tanh(local_std*3.0)\n",
    "        else:\n",
    "            weight = weight_base + 0.25*np.tanh(fusion_score_global)*np.tanh(local_std*2.0)\n",
    "        proj = proj + weight\n",
    "\n",
    "        # ----- SLICE-LOCAL AUTO THRESHOLD -----\n",
    "        proj_cpu = xp.asnumpy(proj)\n",
    "        p_hi, p_lo = slice_percentiles(proj_cpu)\n",
    "\n",
    "        mask_hi = proj > np.percentile(proj_cpu, p_hi)\n",
    "        mask_lo = proj > np.percentile(proj_cpu, p_lo)\n",
    "        w = xp.clip((proj - np.percentile(proj_cpu, p_lo)) /\n",
    "                    (np.percentile(proj_cpu, p_hi) - np.percentile(proj_cpu, p_lo) + 1e-6), 0.0, 1.0)\n",
    "        final = (w * xp.logical_and(mask_hi, mask_lo) +\n",
    "                 (1.0 - w) * xp.logical_or(mask_hi, mask_lo)) > 0.5\n",
    "        out.append(final.astype(xp.uint8))\n",
    "\n",
    "        latency = time.time_ns() - t0\n",
    "        # ----- ULTRA-DEBUG++ LOGGING -----\n",
    "        logger.slice_metric(\n",
    "            path.name, z, latency,\n",
    "            fusion_score=float(fusion_score_global),\n",
    "            weight=float(weight),\n",
    "            p_hi=p_hi,\n",
    "            p_lo=p_lo,\n",
    "            w=w\n",
    "        )\n",
    "\n",
    "    mask = xp.stack(out)\n",
    "    checksum = hashlib.sha256(vol.tobytes()).hexdigest()[:16]\n",
    "\n",
    "    logger.file_metric(path.name, checksum, Z)\n",
    "    logger.log(\"FILE_DONE\", {\"file\": path.name, \"checksum\": checksum, \"slices\": Z})\n",
    "\n",
    "        # NX47 v61.2: align to competitor-like binary uint8 domain (0/1) while preserving 3D multipage TIFF.\n",
    "    return xp.asnumpy(mask).astype(np.uint8)\n",
    "\n",
    "# ---------------------- RUN ALL ----------------------\n",
    "FILES = sorted(TEST_DIR.rglob(\"*.tif\"))\n",
    "if not FILES:\n",
    "    raise RuntimeError(\"NO TEST FILES FOUND\")\n",
    "\n",
    "logger.log(\"FILES_READY\", {\"count\": len(FILES)})\n",
    "\n",
    "with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_STORED) as zf:\n",
    "    for f in FILES:\n",
    "        m = process_file(f)  # ablation=None, ultra_aggressive=True\n",
    "        out = OUT / f.name\n",
    "        if m.ndim != 3:\n",
    "            raise RuntimeError(f\"Invalid NX47 output rank for {f.name}: {m.shape} (expected 3D Z,H,W)\")\n",
    "        tifffile.imwrite(out, m, compression=\"LZW\")\n",
    "        zf.write(out, arcname=f.name)\n",
    "        out.unlink()\n",
    "        gc.collect()\n",
    "\n",
    "# ---------------------- GLOBAL SUMMARY ----------------------\n",
    "df_slices = pd.DataFrame(logger.slice_rows)\n",
    "df_files  = pd.DataFrame(logger.file_rows)\n",
    "\n",
    "print(\"\\n===== SLICE SUMMARY (ALL FILES) =====\")\n",
    "print(df_slices.groupby(\"file\")[[\"latency_ms\",\"fusion_score\",\"weight\",\"p_hi\",\"p_lo\",\"w_mean\"]].agg([\"count\",\"mean\",\"min\",\"max\"]))\n",
    "\n",
    "print(\"\\n===== GLOBAL SLICE MEAN (ALL FILES) =====\")\n",
    "print(df_slices[\"latency_ms\"].mean(), \"ms\")\n",
    "\n",
    "print(\"\\n===== FILE CHECKSUMS =====\")\n",
    "print(df_files.to_string(index=False))\n",
    "\n",
    "logger.log(\"SUBMISSION_READY\", {\"zip\": str(ZIP_PATH)})\n",
    "logger.log(\"EXEC_COMPLETE\")\n",
    "for alias in [Path(\"/kaggle/working/nx47_vesuvius/submission.zip\"), Path(\"submission.zip\"), Path(\"nx47_vesuvius/submission.zip\")]:\n",
    "    alias.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if alias.resolve() != ZIP_PATH.resolve():\n",
    "        import shutil\n",
    "        shutil.copyfile(ZIP_PATH, alias)\n",
    "\n",
    "print(\"READY:\", ZIP_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15062069,
     "sourceId": 117682,
     "sourceType": "competition"
    },
    {
     "datasetId": 9431333,
     "sourceId": 14755914,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9462392,
     "sourceId": 14799025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9470090,
     "sourceId": 14809675,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.548218,
   "end_time": "2026-02-18T13:17:49.715065",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-18T13:17:27.166847",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
