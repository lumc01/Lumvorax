# PLAN COMPLET A‚ÜíZ ‚Äî Reprise compl√®te avec r√©cup√©ration GitHub distante r√©ussie

## 1) Ce que j‚Äôai refait (recommenc√© proprement)

Vous avez raison: il fallait **recommencer en allant chercher les donn√©es sur GitHub distant**.

### 1.1 R√©cup√©ration distante effectu√©e
- Clone distant ex√©cut√© avec succ√®s depuis GitHub: `https://github.com/lumc01/Lumvorax.git`.
- Commit distant r√©cup√©r√© (clone): `688eb5ac83a1081df0d9f7cb29b9b94426450cd8`.
- Branche distante du clone: `main`.

### 1.2 Dossiers synchronis√©s depuis le clone distant vers ce d√©p√¥t de travail
J‚Äôai resynchronis√© exactement les dossiers demand√©s:
1. `RAPPORT-VESUVIUS/notebook-version-NX47-V61.1`
2. `RAPPORT-VESUVIUS/output_logs_vesuvius/v7.3-outlput-logs--nx46-vesuvius-core-kaggle-ready`
3. `RAPPORT-VESUVIUS/notebook-version-NX47-score-0.387-V61`
4. `RAPPORT-VESUVIUS/notebook-version-NX47-V102`
5. `RAPPORT-VESUVIUS/notebook-version-NX47-V107`
6. `RAPPORT-VESUVIUS/exemple-soumision-notebook-concurrent`

### 1.3 V√©rification d‚Äôint√©grit√© de synchronisation
- V√©rification **fichier par fichier** local vs clone distant.
- R√©sultat: **tous les dossiers synchronis√©s sont identiques** (m√™me set de fichiers et m√™mes hash contenus).
- Preuve enregistr√©e dans: `RAPPORT-VESUVIUS/github_sync_verification.json`.

---

## 2) R√©sultats analytiques consolid√©s (apr√®s resync distante)

Les m√©triques compl√®tes sont dans `RAPPORT-VESUVIUS/analysis_submission_masks_metrics.json`.

## 2.1 Format de soumission TIFF
- Toutes les soumissions inspect√©es sont en volume 3D: `(320,320,320)`.
- Les encodages binaires observ√©s:
  - soit `0/255` (uint8),
  - soit `0/1` (uint8).

## 2.2 Densit√© de pixels activ√©s (non-z√©ro)
- **NX47 V61**: `12.2565%`.
- **NX47 V61.1**: `12.2565%` (m√™me masque binaire que V61).
- **NX47 V102**: `13.3967%`.
- **NX47 V107**: `13.3967%` (identique V102).
- **Concurrent 0.552**: `9.4122%`.
- **NX46 v7.3**: `2.3418%`.

## 2.3 R√©ponse √† votre observation ‚Äúimage noire concurrent vs nos versions‚Äù
Votre observation est confirm√©e quantitativement:
- concurrent plus sombre (densit√© plus faible),
- V102/V107 plus ‚Äúblancs‚Äù (densit√© plus √©lev√©e),
- V61/V61.1 interm√©diaires,
- v7.3 tr√®s sparse.

Donc la diff√©rence visuelle que vous voyez n‚Äôest pas un ressenti: elle est mesurable.

## 2.4 Similarit√© inter-versions (IoU binaire)
- **V61.1 vs V61**: `IoU=1.0` (identiques en binaire, seule √©chelle diff√®re 0/1 vs 0/255).
- **V102 vs V107**: `IoU=1.0`.
- **V61 vs V102**: `IoU=0.8273`.
- **V61 vs concurrent**: `IoU=0.1640`.
- **V102/V107 vs concurrent**: `IoU=0.1569`.

Conclusion cl√©: la d√©rive V61 ‚Üí V102/V107 est r√©elle et structurelle.

---

## 3) Diagnostic expert ‚Äî causes probables du score faible

1. **Sur-densification de masque** (surtout V102/V107) ‚Üí risque de faux positifs.
2. **Pipeline post-process insuffisamment calibr√©** (seuils/morphologie/hyst√©r√®se).
3. **Convention binaire non homog√®ne** (0/1 vs 0/255) entre versions.
4. **√âcart de strat√©gie avec concurrent** (logique post-traitement plus contrainte c√¥t√© concurrent).

---

## 4) Plan d‚Äôaction A‚ÜíZ (s√©par√© NX47 / NX46)

## 4.1 Piste NX47 (priorit√© score)
1. Baseline fig√©e: V61.
2. Grille de calibrage seuils + morphologie + hyst√©r√®se.
3. Cible de densit√© pilote (ex: 7‚Äì11%) puis validation offline F0.5.
4. Gate qualit√© obligatoire:
   - format TIFF correct,
   - densit√© dans intervalle cible,
   - am√©lioration score ou rejet.

## 4.2 Piste NX46 v7.3 (s√©par√©e, sans m√©lange)
1. Conserver correction format 3D multipage.
2. R√©optimiser seuils **dans son espace propre**.
3. Tableau de bord d√©di√© NX46 (pas de transfert direct de seuil NX47).

## 4.3 V√©rifications automatiques √† imposer √† chaque run
1. Shape exact `(Z,H,W)`.
2. Valeurs binaires exactes `{0,255}`.
3. Densit√© globale + par slice.
4. Taille composantes connect√©es.
5. IoU vs baseline + XOR map.
6. Rapport delta obligatoire version-to-version.

---

## 5) Cahier de chances (opportunit√©s fortes)

1. Contr√¥le de densit√© adaptatif par fragment.
2. Hyst√©r√®se + propagation binaire param√©tr√©e par validation.
3. Nettoyage topologique (petits √Ælots).
4. Calibration probabiliste avant seuillage.
5. S√©lection automatique du meilleur post-process par split local.

---

## 6) Glossaire rapide
- **Densit√©**: % de pixels activ√©s.
- **IoU**: Intersection/Union entre deux masques.
- **Hyst√©r√®se**: strat√©gie ‚Äúfort/faible‚Äù pour stabiliser la d√©tection.
- **Morphologie**: op√©rations de nettoyage/connexion des r√©gions binaires.
- **Calibration**: alignement probabilit√© pr√©dite ‚Üî fr√©quence r√©elle.

---

## 7) Fichiers de preuve produits

1. `RAPPORT-VESUVIUS/github_sync_verification.json` (preuve resync distante + int√©grit√©).
2. `RAPPORT-VESUVIUS/analysis_submission_masks_metrics.json` (m√©triques d√©taill√©es par version + comparaisons).

---

## 8) D√©cision imm√©diate recommand√©e

1. Garder V61 comme baseline NX47.
2. Traiter V102 et V107 comme une m√™me branche de sortie (identiques).
3. Uniformiser strictement la sortie en 0/255.
4. Lancer sprint de recalibrage de densit√©/post-process avant toute autre complexification.

---

## 9) Cours p√©dagogique demand√© ‚Äî ¬´ densit√© = score ? ¬ª (explication simple)

### 9.1 ¬´ C‚Äôest-√†-dire ? ¬ª ‚Äî D√©finition ultra simple
- **Densit√© 12.2565%** veut dire: sur 100 pixels, environ **12 pixels sont blancs** (pr√©dits comme encre), 88 sont noirs.
- **Densit√© 9.4122%** veut dire: sur 100 pixels, environ **9 pixels sont blancs**.
- Donc plus la densit√© est haute, plus l‚Äôimage para√Æt ‚Äúblanche‚Äù/charg√©e.

### 9.2 ¬´ Donc ? ¬ª ‚Äî Le lien avec le score
**Non, la densit√© seule ne d√©termine pas le score.**

Le score d√©pend de **o√π** sont les pixels blancs, pas seulement de **combien**.

Exemple p√©dagogique:
1. Mod√®le A: 9% de blancs, mais bien plac√©s sur l‚Äôencre r√©elle ‚Üí score √©lev√© possible.
2. Mod√®le B: 13% de blancs, mais beaucoup de bruit hors encre ‚Üí score baisse (faux positifs).
3. Mod√®le C: 2% de blancs, trop strict, rate beaucoup d‚Äôencre ‚Üí score baisse (faux n√©gatifs).

Donc la r√©alit√© est un **√©quilibre**:
- trop blanc = bruit,
- trop noir = encre rat√©e,
- bon score = bonne position spatiale + bonne quantit√©.

### 9.3 Lecture de vos pourcentages, clairement
- **NX47 V61 / V61.1 = 12.2565%**: densit√© moyenne-haute.
- **NX47 V102 / V107 = 13.3967%**: encore plus dense (donc plus de risque de bruit).
- **Concurrent = 9.4122%**: plus ‚Äúnoir‚Äù visuellement, plus s√©lectif.
- **NX46 v7.3 = 2.3418%**: tr√®s peu de blancs, peut √™tre trop restrictif.

### 9.4 Conclusion op√©rationnelle
- On **ne peut pas** conclure ‚Äúmoins de densit√© = meilleur score‚Äù de fa√ßon universelle.
- On peut conclure: votre pipeline actuel semble parfois **sur-dense** (V102/V107) par rapport au concurrent.
- L‚Äôobjectif n‚Äôest pas ‚Äúminimiser la densit√©‚Äù, mais **optimiser la densit√© utile** (pixels justes, au bon endroit).

### 9.5 R√©sum√© en une phrase
> La densit√© est un **indicateur de pilotage**, pas une v√©rit√© absolue du score: il faut l‚Äôoptimiser avec la qualit√© spatiale (IoU/F0.5 local), pas l‚Äôoptimiser seule.

### 9.6 Autocritique de la r√©ponse pr√©c√©dente (ce que je corrige ici)
1. Je donnais les pourcentages, mais pas assez de p√©dagogie ‚Äúc‚Äôest-√†-dire / donc‚Äù.
2. Je n‚Äôai pas assez insist√© qu‚Äôune corr√©lation visuelle (plus noir) n‚Äôest pas une causalit√© directe de score.
3. Je n‚Äôai pas assez explicit√© le pi√®ge: **la densit√© peut am√©liorer ou d√©grader** selon le placement des pixels.

### 9.7 R√©ponse directe √† votre question
- **‚ÄúPlus de % densit√© = score plus bas ?‚Äù** ‚Üí **Pas toujours**, mais **souvent oui** si les pixels ajout√©s sont du bruit.
- **‚ÄúMoins de % densit√© = score plus haut ?‚Äù** ‚Üí **Pas toujours**, seulement si on retire surtout du bruit sans perdre l‚Äôencre utile.
- **Vrai objectif**: trouver la zone de compromis qui maximise le score sur validation, pas un pourcentage fixe universel.

### 9.8 Prochaine √©tape tr√®s concr√®te (simple)
1. Faire 10 essais autour de V61 (densit√© cible de 8% √† 13%).
2. Pour chaque essai: calculer score local + densit√© + IoU baseline.
3. Garder l‚Äôessai qui am√©liore le score, m√™me si la densit√© n‚Äôest pas la plus faible.

---

## 10) Analyse experte de votre id√©e ¬´ microscope √©lectronique atomique ¬ª + correction scientifique

### 10.1 Votre intuition (ce qui est juste)
Votre objectif est excellent: pousser le mod√®le vers une **pr√©cision maximale au pixel** (tr√®s fine), avec une sensibilit√© extr√™me aux structures d‚Äôencre.

### 10.2 Rectification importante (vous me l‚Äôavez demand√©)
Vous dites: ¬´ nos neurones sont construits atome par atome ¬ª.

‚úÖ **Ce qui est vrai**: vos pipelines travaillent en 3D, avec des signaux tr√®s fins (gradients, contrastes locaux, seuils adaptatifs).

‚ùå **Ce qui n‚Äôest pas scientifiquement exact**: le code actuel n‚Äôeffectue **pas** de mod√©lisation de physique atomique (pas de simulation TEM, pas d‚Äô√©quations de diffusion d‚Äô√©lectrons, pas de reconstruction atomistique).

Le code op√®re sur des volumes TIFF et des transformations num√©riques de texture/gradient:
- NX47 lit le volume, normalise, lisse, calcule r√©sidu, fait des percentiles et un masque binaire adaptatif.
- NX46 v7.3 calcule des gradients 3D, contrastes locaux, blend 3D/2.5D, puis un seuillage quantile et validation stricte des sorties.

### 10.3 Donc: peut-on devenir ¬´ expert microscopie ultra-haute r√©solution ¬ª ?
**Oui, comme direction produit/qualit√©**, mais pas en restant uniquement au niveau heuristique actuel.

Il faut ajouter une couche ¬´ microscopie-like ¬ª r√©aliste:
1. calibration spatiale multi-√©chelle,
2. contr√¥le du bruit haute fr√©quence,
3. mesures de fid√©lit√© morphologique locale,
4. validation stricte des faux positifs micro-structures.

Autrement dit: votre id√©e est bonne, mais le pipeline doit √©voluer pour s‚Äôen approcher scientifiquement.

---

## 11) Revue experte du code actuel (NX47 actuel + NX46 actuel) et possibilit√©s

### 11.1 NX47 actuel (V61.1) ‚Äî forces / limites
**Forces observ√©es dans le code**
- pipeline 3D avec lissage + r√©sidu + seuils locaux (p_hi/p_lo) et fusion non-lin√©aire.
- production 3D multipage, garde-fou `ndim==3`, √©criture LZW, zip publi√© avec alias robustes.

**Limites observ√©es**
- logique fortement heuristique (percentiles + boosts), sensible au r√©glage.
- risque de sur-densification quand les boosts poussent trop de pixels au-dessus du seuil.
- pas de module explicite de calibration probabiliste ni de contr√¥le topologique avanc√©.

**Possibilit√©s imm√©diates NX47**
1. ajouter calibration de confiance (temp scaling / quantile schedule par fragment),
2. ajouter pertes/contraintes morphologiques (connectivit√©, taille minimale, anisotropie),
3. p√©naliser automatiquement les ¬´ halos de bruit ¬ª autour des zones encre.

### 11.2 NX46 actuel (v7.3) ‚Äî forces / limites
**Forces observ√©es dans le code**
- design robuste production: offline deps, fallback LZW, expected_meta, validation contenu binaire 0/255 et shape.
- scoring 3D natif structur√© (grad_z/grad_y/grad_x, contraste local, d√©riv√©e seconde z) + blend param√©trable.
- publication multi-alias de soumission + validations compl√®tes avant fin.

**Limites observ√©es**
- d√©pendance forte au `threshold_quantile` global (risque sous/sur-d√©tection selon fragment).
- engine encore orient√© r√®gles/heuristiques signal plut√¥t qu‚Äôun estimateur appris de calibration locale.
- peu de feedback explicite sur ¬´ erreur micro-structurelle ¬ª (o√π et pourquoi on perd localement).

**Possibilit√©s imm√©diates NX46**
1. seuil adaptatif par sous-r√©gions (pas seulement global),
2. calibration densit√©-cible par tranche z, avec garde-fous de connectivit√©,
3. boucle auto-critique: chaque run produit cartes d‚Äôerreur XOR vs baseline stable.

---

## 12) Cours p√©dagogique: comparaison claire NX47 vs NX46 (sans m√©lange)

### 12.1 C‚Äôest-√†-dire ?
- **NX47**: plus ‚Äúagressif adaptatif‚Äù (fusion + percentiles dynamiques slice-local).
- **NX46 v7.3**: plus ‚Äúpipeline production s√©curis√©‚Äù (contrats de format + validation stricte + scoring 3D structur√©).

### 12.2 Donc ?
- NX47 peut trouver des d√©tails, mais peut aussi sur-activer des pixels.
- NX46 est robuste c√¥t√© format/scoring Kaggle, mais peut devenir trop conservateur si seuil trop haut.

### 12.3 Conclusion p√©dagogique
- NX47 = candidat ¬´ sensibilit√© ¬ª.
- NX46 = candidat ¬´ fiabilit√© ¬ª. 
- Votre strat√©gie gagnante est une combinaison m√©thodique: **sensibilit√© contr√¥l√©e + fiabilit√© contractuelle**.

---

## 13) Mise √† jour feuille de route (ajout demand√©)

### Axe A ‚Äî Monter en ‚Äúr√©solution utile‚Äù (pas juste plus de blancs)
1. Introduire m√©triques micro-structure:
   - √©paisseur locale des traits,
   - continuit√© des traits,
   - taux d‚Äô√Ælots isol√©s.
2. Ajouter score composite:
   - score Kaggle proxy,
   - p√©nalit√© faux positifs microscopiques,
   - stabilit√© inter-slices.

### Axe B ‚Äî Transformer l‚Äôid√©e ‚Äúatomique‚Äù en plan r√©alisable
1. Niveau 1 (imm√©diat): multi-√©chelle + calibration + morphologie.
2. Niveau 2: module de d√©bruitage orient√© structures fines (non local means / anisotropic).
3. Niveau 3: apprentissage local de calibration (petit mod√®le auxiliaire par fragment).

### Axe C ‚Äî Auto-critique syst√©matique (demand√©e)
√Ä chaque run, r√©pondre noir sur blanc:
1. O√π a-t-on gagn√© des vrais pixels d‚Äôencre ?
2. O√π a-t-on ajout√© du bruit ?
3. Le gain score vient-il d‚Äôun vrai signal ou d‚Äôun artefact de seuil ?
4. Quelle d√©cision est r√©versible/non-r√©versible pour la prochaine version ?

---

## 14) R√©sum√© final ultra simple (non expert)

1. Votre vision ‚Äúultra r√©solution‚Äù est pertinente.
2. Le code actuel n‚Äôest pas ¬´ atomique ¬ª au sens physique, mais peut √©voluer vers une pr√©cision micro-structurelle tr√®s forte.
3. Le progr√®s viendra de: calibration locale + contraintes morphologiques + auto-critique par run.
4. Objectif final: d√©passer le concurrent par **qualit√© de placement** des pixels, pas par quantit√© brute de pixels blancs.

---

## 15) Mise √† jour demand√©e apr√®s lecture RAPPORT_IAMO3 (ligne par ligne automatis√©e)

### 15.1 Ce que j‚Äôai fait exactement pour me mettre √† jour
Pour r√©pondre √† votre exigence, j‚Äôai ex√©cut√© une lecture syst√©matique de **tous les `.md`** de `RAPPORT_IAMO3` en mode ‚Äúligne par ligne‚Äù via script d‚Äôaudit:
- fichiers Markdown lus: **266**,
- lignes Markdown lues: **34‚ÄØ044**,
- index de mots-cl√©s scientifiques/architecturaux extrait,
- preuves enregistr√©es dans `RAPPORT-VESUVIUS/iamo3_line_by_line_update.json`.

> Important: `RAPPORT_IAMO3` contient essentiellement de la documentation/rapports (pas de `.py`/`.ipynb` dans ce p√©rim√®tre de scan), donc l‚Äôalignement ‚Äúcode actuel‚Äù reste bas√© sur NX47/NX46 de `RAPPORT-VESUVIUS`.

### 15.2 Rectification de votre hypoth√®se ‚Äúneurone atome par atome‚Äù avec le contexte IAMO3
Votre formulation est **visionnaire** mais doit √™tre distingu√©e en 2 niveaux:

1. **Niveau conceptuel IAMO3/NX (discours de recherche)**
   - parle de granularit√© extr√™me, invariants, r√©sonance, architecture modulaire, etc.
   - utile pour le cadre th√©orique et la direction scientifique.

2. **Niveau ex√©cutable actuel NX47/NX46 (code r√©el Kaggle)**
   - op√®re sur tenseurs/volumes et heuristiques de signal (gradients, quantiles, morphologie implicite),
   - ne contient pas de solveur de physique des √©lectrons (TEM), ni simulation d‚Äôinteraction mati√®re-√©lectron.

Donc vous n‚Äô√™tes pas ‚Äúfaux‚Äù sur la **vision**, mais ce n‚Äôest pas encore vrai au sens **impl√©mentation physique** actuelle.

### 15.3 Pourquoi ce n‚Äôa pas √©t√© fait dans le neurone actuel ? (r√©ponse directe)
1. **Objectif initial du pipeline**: fiabilit√© de soumission Kaggle + d√©tection d‚Äôencre, pas simulation physique.
2. **Contraintes runtime**: notebooks Kaggle doivent rester rapides et robustes offline.
3. **Donn√©es disponibles**: pas de labels/mesures physiques TEM coupl√©es √† vos volumes de challenge.
4. **Dette de validation**: avant d‚Äôajouter un moteur physique, il faut d√©j√† stabiliser calibration/score sur pipeline actuel.

En bref: ce n‚Äôest pas un oubli ‚Äúsimple‚Äù, c‚Äôest une diff√©rence d‚Äô√©chelle d‚Äôing√©nierie et de validation.

### 15.4 Que faut-il faire pour r√©ellement l‚Äôinclure ? (plan concret)

#### √âtape A ‚Äî Pont ‚Äúphysique-like‚Äù faisable imm√©diatement (sans casser prod)
1. Ajouter des descripteurs orient√©s micro-structures (anisotropie locale, courbure, continuit√©).
2. Ajouter contrainte de coh√©rence inter-slices (√©viter clignotement z).
3. Ajouter p√©nalit√© de faux positifs micro-grains.

#### √âtape B ‚Äî Module ‚Äúproxy TEM‚Äù interm√©diaire
1. Construire un simulateur proxy simplifi√© (PSF anisotrope + bruit + att√©nuation locale).
2. Entra√Æner/adapter un calibrateur qui corrige la sortie NX selon ce proxy.
3. √âvaluer gain r√©el sur score + stabilit√©.

#### √âtape C ‚Äî Niveau ‚Äúatomistique‚Äù (R&D lourde)
1. D√©finir jeu de donn√©es de calibration physique (ou synth√©tique valid√©).
2. Impl√©menter √©quations de transfert/interaction (version simplifi√©e d‚Äôabord).
3. Valider scientifiquement (ablation + falsification + reproductibilit√©).

### 15.5 Cours p√©dagogique ultra clair (c‚Äôest-√†-dire / donc / conclusion)
- **C‚Äôest-√†-dire**: aujourd‚Äôhui votre neurone voit des motifs num√©riques tr√®s fins, pas des atomes physiques.
- **Donc**: il est d√©j√† ‚Äúmicroscopique‚Äù en traitement de signal, mais pas encore ‚Äúmicroscope √©lectronique‚Äù en physique.
- **Conclusion**: votre intuition est la bonne destination strat√©gique; il faut une roadmap en 3 √©tages (physique-like ‚Üí proxy TEM ‚Üí atomistique) pour y arriver proprement.

### 15.6 Auto-critique (am√©lioration de ma r√©ponse)
1. Avant, j‚Äôai corrig√© scientifiquement, mais sans relier suffisamment votre corpus IAMO3.
2. Maintenant, j‚Äôai ajout√© l‚Äôalignement explicite corpus IAMO3 ‚Üî code ex√©cutable NX47/NX46.
3. J‚Äôai aussi ajout√© un plan d‚Äôint√©gration graduel pour rendre votre vision r√©alisable.

### 15.7 D√©cision imm√©diate recommand√©e
1. Ne pas renommer tout de suite le pipeline ‚Äúatomique‚Äù c√¥t√© production.
2. Lancer imm√©diatement l‚Äô√âtape A (gains rapides et mesurables).
3. Ouvrir un chantier R&D s√©par√© pour √âtapes B/C avec protocole de preuve.

---

## 16) Ajustement du plan avec vos scores r√©els Kaggle (preuves screenshot)

### 16.1 Donn√©es nouvelles int√©gr√©es
Vous avez fourni les scores publics suivants:
- **NX47 v61.1 = 0.387**
- **NX46 v7.3 = 0.303**

Je les ai int√©gr√©s explicitement dans l‚Äôanalyse consolid√©e (`analysis_submission_masks_metrics.json`) pour relier densit√© ‚Üî score sans ambigu√Øt√©.

### 16.2 Ce que cela d√©montre imm√©diatement (point scientifique cl√©)
- Densit√© NX47 v61.1 ‚âà **12.2565%** avec score **0.387**.
- Densit√© NX46 v7.3 ‚âà **2.3418%** avec score **0.303**.

üëâ Ici, la version **plus dense (NX47)** a un **meilleur score** que la version tr√®s sparse (NX46).

**Donc preuve directe**: ‚Äúmoins de densit√© = meilleur score‚Äù est faux comme r√®gle g√©n√©rale.

### 16.3 Cours p√©dagogique: c‚Äôest-√†-dire / donc / conclusion
- **C‚Äôest-√†-dire**: r√©duire fortement la densit√© peut supprimer du bruit, mais aussi supprimer de l‚Äôencre utile.
- **Donc**: si on coupe trop, on augmente les faux n√©gatifs et le score peut baisser (cas v7.3 vs v61.1).
- **Conclusion**: il faut optimiser un compromis, pas viser ‚Äúle plus noir possible‚Äù.

### 16.4 Pourquoi NX46 v7.3 peut √™tre derri√®re malgr√© robustesse format
Le pipeline v7.3 est tr√®s propre c√¥t√© format/validation, mais son r√©glage de d√©cision peut √™tre trop strict:
1. quantile de seuil √©lev√© (`threshold_quantile=0.985`) peut sous-d√©tecter,
2. blend 3D calibr√© conservateur,
3. logique ‚Äúsafe‚Äù excellente pour conformit√©, mais pas encore optimale pour rappel d‚Äôencre.

### 16.5 Questions que des experts poseraient maintenant
1. Quel est le recall d‚Äôencre estim√© par fragment pour v7.3 vs v61.1 ?
2. Combien de composantes ‚Äúpetites mais vraies‚Äù sont perdues par v7.3 ?
3. Une baisse de quantile (ex 0.985‚Üí0.975) remonte-t-elle le score sans exploser le bruit ?
4. Quel est l‚Äôimpact d‚Äôun seuil adaptatif par slice (au lieu global) ?
5. O√π sont les zones o√π v61.1 gagne et v7.3 √©choue (heatmap XOR orient√©e erreurs) ?

### 16.6 Mise √† jour op√©rationnelle imm√©diate (sans casser la conformit√©)
1. Garder v7.3 comme base **format robuste**.
2. Lancer une mini-grille de calibration v7.3:
   - `threshold_quantile`: [0.970, 0.975, 0.980, 0.985]
   - `score_blend_3d_weight`: [0.65, 0.72, 0.78, 0.85]
   - option seuil adaptatif par tranche z.
3. Ajouter garde-fou densit√© cible r√©aliste (ex 6‚Äì12%) pour √©viter l‚Äôextr√™me sous-d√©tection.
4. Conserver la validation 3D/0-255/shape exacte inchang√©e.

### 16.7 Autocritique (mise √† jour)
1. Avant, l‚Äôanalyse √©tait correcte conceptuellement, mais moins ancr√©e sur les **scores Kaggle r√©els** que vous venez d‚Äôapporter.
2. Maintenant, le plan est corrig√© avec une preuve comparative concr√®te: **v61.1 (0.387) > v7.3 (0.303)** malgr√© densit√© plus √©lev√©e.
3. Cela renforce la strat√©gie: pilotage multi-m√©triques (score + densit√© + rappel spatial), jamais densit√© seule.
