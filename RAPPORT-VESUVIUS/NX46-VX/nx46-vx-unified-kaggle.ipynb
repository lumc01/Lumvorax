{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NX46 VX Unified Kaggle Notebook (V2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 Update Protocol — copies preserved before edit\n",
    "- Backup V1 immutable: `nx46-vx-unified-kaggle-V1-COPY-IMMUTABLE-20260224.ipynb`\n",
    "- Backup V2 pre-update: `nx46-vx-unified-kaggle-V2-PREUPDATE-COPY-20260224.ipynb`\n",
    "- Rule: update original only after backups exist; never reduce code line count vs previous versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 protocol verification (non-destructive)\n",
    "NOTEBOOK_VERSION = 'V2'\n",
    "IMMUTABLE_BACKUPS = [\n",
    "    'RAPPORT-VESUVIUS/NX46-VX/nx46-vx-unified-kaggle-V1-COPY-IMMUTABLE-20260224.ipynb',\n",
    "    'RAPPORT-VESUVIUS/NX46-VX/nx46-vx-unified-kaggle-V2-PREUPDATE-COPY-20260224.ipynb',\n",
    "]\n",
    "print('Notebook version:', NOTEBOOK_VERSION)\n",
    "for p in IMMUTABLE_BACKUPS:\n",
    "    print('backup expected:', p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NX46 VX V2 — Réintégration complète V1 (teachers + dépendances + plan double fine-tuning)\n",
    "\n",
    "Ce bloc force explicitement la présence des 9 enseignants, des dépendances exactes du dataset,\n",
    "et la stratégie demandée: distillation -> train -> fine-tune test aligné concurrent -> soumission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 guardrails: teacher transfer + exact dependency manifest + staged plan\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "COMPETITOR_NOTEBOOK_PATH = 'RAPPORT-VESUVIUS/exemple-soumision-notebook-concurrent/vesuvius-0-552.ipynb'\n",
    "OFFLINE_INSTALLER_INPUT = '/kaggle/input/notebooks/ipythonx/vsdetection-packages-offline-installer-only'\n",
    "COMPETITOR_MODELS_EXPECTED_COUNT = 9\n",
    "\n",
    "COMPETITOR_MODELS_FOUND_EXACT = [\n",
    "    '/kaggle/input/vsd-model/keras/transunet/3/transunet.seresnext50.160px.comboloss.weights.h5',\n",
    "]\n",
    "\n",
    "USER_PROVIDED_MODEL_INPUT_PATHS = [\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/segformer.mit.b2/1',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/default/1',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/transunetseresnext/1',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/segformer.mit.b4/1',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/segformer.mit.b2/2',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/transunetseresnext/2',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/default/2',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/transunet/2',\n",
    "    '/kaggle/input/models/ipythonx/vsd-model/keras/transunet/3',\n",
    "]\n",
    "\n",
    "TEACHER_MODELS_REGISTRY = [\n",
    "    {'teacher_id': 'teacher_01', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/segformer.mit.b2/1'},\n",
    "    {'teacher_id': 'teacher_02', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/default/1'},\n",
    "    {'teacher_id': 'teacher_03', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/transunetseresnext/1'},\n",
    "    {'teacher_id': 'teacher_04', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/segformer.mit.b4/1'},\n",
    "    {'teacher_id': 'teacher_05', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/segformer.mit.b2/2'},\n",
    "    {'teacher_id': 'teacher_06', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/transunetseresnext/2'},\n",
    "    {'teacher_id': 'teacher_07', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/default/2'},\n",
    "    {'teacher_id': 'teacher_08', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/transunet/2'},\n",
    "    {'teacher_id': 'teacher_09', 'source': 'user_provided_kaggle_input', 'weight_ref': '/kaggle/input/models/ipythonx/vsd-model/keras/transunet/3'},\n",
    "]\n",
    "\n",
    "# Exact filenames from RAPPORT-VESUVIUS/NX46-VX/liste-dependence.md\n",
    "REQUIRED_DEPENDENCY_FILENAMES = [\n",
    "    '1407735.tif',\n",
    "    'CERTIFICATION_V7_FINALE_RAPPORT.md',\n",
    "    'competitor_teacher_1407735.lum',\n",
    "    'competitor_teacher_1407735.tif',\n",
    "    'imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
    "    'imageio-2.37.2-py3-none-any.whl',\n",
    "    'lazy_loader-0.4-py3-none-any.whl',\n",
    "    'liblumvorax.so',\n",
    "    'liblumvorax_replit.so',\n",
    "    'lumvorax_test_matrix_full.json',\n",
    "    'networkx-3.6.1-py3-none-any.whl',\n",
    "    'numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
    "    'opencv_python-4.13.0.92-cp37-abi3-manylinux_2_28_x86_64.whl',\n",
    "    'packaging-26.0-py3-none-any.whl',\n",
    "    'pillow-12.1.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
    "    'scikit_image-0.26.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl',\n",
    "    'scipy-1.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
    "    'tifffile-2026.1.28-py3-none-any.whl',\n",
    "    'tifffile-2026.2.16-py3-none-any.whl',\n",
    "]\n",
    "\n",
    "COMPETITOR_TEACHER_TIF_CANDIDATES = [\n",
    "    '/kaggle/input/data-explorer/competitor_teacher_1407735.tif',\n",
    "    '/kaggle/input/notebooks/ipythonx/vsdetection-packages-offline-installer-only/competitor_teacher_1407735.tif',\n",
    "]\n",
    "COMPETITOR_TEACHER_LUM_CANDIDATES = [\n",
    "    '/kaggle/input/data-explorer/competitor_teacher_1407735.lum',\n",
    "    '/kaggle/input/notebooks/ipythonx/vsdetection-packages-offline-installer-only/competitor_teacher_1407735.lum',\n",
    "]\n",
    "\n",
    "NX46_V2_TRAINING_PLAN = {\n",
    "    'phase_1_teacher_distillation': '9 teacher models -> student neuron (mandatory)',\n",
    "    'phase_2_supervised_train': 'train split supervised fit after transfer',\n",
    "    'phase_3_test_guided_ultra_finetune': 'fine-tune on test slices calibrated vs competitor_teacher_1407735.tif',\n",
    "    'phase_4_main_test_inference': 'official test inference and submission generation',\n",
    "}\n",
    "\n",
    "\n",
    "def discover_paths(paths):\n",
    "    return [p for p in paths if os.path.exists(p)]\n",
    "\n",
    "\n",
    "def assert_9_teacher_models_ready(registry):\n",
    "    resolved_count = sum(1 for t in registry if t.get('weight_ref'))\n",
    "    if resolved_count < COMPETITOR_MODELS_EXPECTED_COUNT:\n",
    "        raise RuntimeError(f'9 teacher models required before distillation. resolved={resolved_count}')\n",
    "    return True\n",
    "\n",
    "\n",
    "def validate_dependency_manifest_exact_names(required_names, search_roots):\n",
    "    found = {name: [] for name in required_names}\n",
    "    for root in search_roots:\n",
    "        rp = Path(root)\n",
    "        if not rp.exists():\n",
    "            continue\n",
    "        for name in required_names:\n",
    "            matches = list(rp.rglob(name)) if rp.is_dir() else []\n",
    "            if matches:\n",
    "                found[name].extend(str(m) for m in matches[:3])\n",
    "    missing = [k for k,v in found.items() if not v]\n",
    "    return found, missing\n",
    "\n",
    "\n",
    "runtime_teacher_roots = discover_paths(USER_PROVIDED_MODEL_INPUT_PATHS)\n",
    "runtime_tif_refs = discover_paths(COMPETITOR_TEACHER_TIF_CANDIDATES)\n",
    "runtime_lum_refs = discover_paths(COMPETITOR_TEACHER_LUM_CANDIDATES)\n",
    "\n",
    "print('offline installer input:', OFFLINE_INSTALLER_INPUT, 'exists=', os.path.exists(OFFLINE_INSTALLER_INPUT))\n",
    "print('registry teachers:', len(TEACHER_MODELS_REGISTRY), '/', COMPETITOR_MODELS_EXPECTED_COUNT)\n",
    "print('runtime teacher roots found:', len(runtime_teacher_roots))\n",
    "print('competitor tif refs found:', runtime_tif_refs)\n",
    "print('competitor lum refs found:', runtime_lum_refs)\n",
    "print('training plan phases:', NX46_V2_TRAINING_PLAN)\n",
    "\n",
    "# keep strict lock: no distillation if 9 teachers are not declared\n",
    "assert_9_teacher_models_ready(TEACHER_MODELS_REGISTRY)\n",
    "\n",
    "# dependency manifest verification by exact filename (best effort)\n",
    "search_roots = ['/kaggle/input', OFFLINE_INSTALLER_INPUT, '/workspace/Lumvorax/RAPPORT-VESUVIUS/NX46-VX']\n",
    "manifest_found, manifest_missing = validate_dependency_manifest_exact_names(REQUIRED_DEPENDENCY_FILENAMES, search_roots)\n",
    "print('manifest missing count:', len(manifest_missing))\n",
    "if manifest_missing:\n",
    "    print('missing exact names:', manifest_missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloc source intégré: V61.5\n",
    "Source: `RAPPORT-VESUVIUS/notebook-version-NX47-V61.5/nx47-vesu-kernel-new-v61-5.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generated from nx47-vesu-kernel-new-v61-4.ipynb\n# Source notebook is kept intact.\n\n# %% [code cell 1]\n# ============================================================\n# NX47-VESU KERNEL V61.5 ULTRA-AGGRESSIVE++ ULTRA-DEBUG++ — ONE-CELL ULTRA-FORNSIC (V28-COMPAT)\n# GPU STRICT • NON-LINEAR FUSION • DYNAMIC SLICE WEIGHT • ABLATION READY\n# FULL SLICE-LOCAL LOGGING: fusion_score, weight, p_hi, p_lo, w\n# ============================================================\n\n# ---------------------- INSTALL (OFFLINE SAFE) ----------------------\nimport sys, subprocess, os\nNX47_DRY_RUN_EARLY = os.environ.get(\"NX47_DRY_RUN\", \"0\") == \"1\"\ndef install_offline(package_name):\n    if NX47_DRY_RUN_EARLY:\n        return\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", \"--find-links=/kaggle/input/datasets/ndarray2000/nx47-dependencies\", package_name])\n    except Exception:\n        try:\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", \"--find-links=/kaggle/input/nx47-dependencies\", package_name])\n        except Exception:\n            print(f\"Offline install failed for {package_name}, attempting standard install...\")\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package_name])\n\ninstall_offline(\"imagecodecs\")\ninstall_offline(\"tifffile\")\n\n# ---------------------- IMPORTS ----------------------\nimport os, time, json, hashlib, gc, zipfile, threading, importlib.util\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\n# ---------------------- GPU STRICT ----------------------\nGPU_STRICT = not NX47_DRY_RUN_EARLY\ntry:\n    import cupy as cp\n    cp.cuda.runtime.getDeviceCount()\n    xp = cp\n    GPU = True\nexcept:\n    if GPU_STRICT:\n        raise RuntimeError(\"GPU REQUIRED — GPU_STRICT ENABLED\")\n    xp = np\n    GPU = False\n\nif GPU:\n    from cupyx.scipy.ndimage import gaussian_filter\nelse:\n    from scipy.ndimage import gaussian_filter\n\n# ---------------------- PATHS ----------------------\nif NX47_DRY_RUN_EARLY:\n    ROOT = Path(os.environ.get(\"NX47_DRY_ROOT\", \"/tmp/nx47_dry\"))\n    TEST_DIR = ROOT / \"test_images\"\n    OUT = ROOT / \"tmp\"\n    OUT.mkdir(parents=True, exist_ok=True)\n    ZIP_PATH = ROOT / \"submission.zip\"\nelse:\n    ROOT = Path(\"/kaggle/input/competitions/vesuvius-challenge-surface-detection\")\n    TEST_DIR = ROOT / \"test_images\"\n    OUT = Path(\"/kaggle/working/tmp\")\n    OUT.mkdir(exist_ok=True)\n    ZIP_PATH = Path(\"/kaggle/working/submission.zip\")\n\n# ---------------------- LOGGER ULTRA-DEBUG++ ----------------------\nclass Logger:\n    def __init__(self):\n        self.seq = 0\n        self.slice_rows = []\n        self.file_rows = []\n        self.lock = threading.Lock()\n\n    def _safe(self, v):\n        if hasattr(v, \"item\"): return v.item()\n        if isinstance(v, np.ndarray): return float(np.mean(v))\n        return v\n\n    def log(self, msg, data=None):\n        with self.lock:\n            self.seq += 1\n            payload = {k:self._safe(v) for k,v in (data or {}).items()}\n            print(f\"[{time.time_ns()}][SEQ:{self.seq:06d}] {msg} {json.dumps(payload)}\")\n\n    def slice_metric(self, file, z, latency_ns, fusion_score=None, weight=None, p_hi=None, p_lo=None, w=None):\n        self.slice_rows.append({\n            \"file\": file,\n            \"slice\": z,\n            \"latency_ms\": latency_ns / 1e6,\n            \"fusion_score\": fusion_score,\n            \"weight\": weight,\n            \"p_hi\": p_hi,\n            \"p_lo\": p_lo,\n            \"w_mean\": w if w is None else float(np.mean(w))\n        })\n\n    def file_metric(self, file, checksum, slices):\n        self.file_rows.append({\n            \"file\": file,\n            \"checksum\": checksum,\n            \"slices\": slices\n        })\n\nlogger = Logger()\nlogger.log(\"LOGGER_INIT\", {\"gpu\": GPU})\n\n# ---------------------- NX47 ----------------------\nif NX47_DRY_RUN_EARLY:\n    class _DummyNX47:\n        def run_all(self):\n            return {}\n    nx47 = _DummyNX47()\n    solve_aimo3 = lambda _q: {}\n    logger.log(\"NX47_AIMO3_DRYRUN_BYPASS\")\nelse:\n    sys.path.append(\"/kaggle/input/datasets/ndarray2000/nx47-arc-kernel-v2-fixed-py\")\n    from nx47_arc_kernel_v2_fixed import PerformanceProofBloc1\n    nx47 = PerformanceProofBloc1()\n    logger.log(\"NX47_OK\")\n\n    # ---------------------- AIMO3 ----------------------\n    aimo3_path = \"/kaggle/input/datasets/ndarray2000/iamo3-shf-resonance-v3/aimo3_shf_resonance_v3.py\"\n    spec = importlib.util.spec_from_file_location(\"aimo3\", aimo3_path)\n    aimo3 = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(aimo3)\n    solve_aimo3 = aimo3.solve_enhanced\n    logger.log(\"AIMO3_OK\")\n\n# ---------------------- TIFF ----------------------\nimport tifffile\ndef read_tiff(p):\n    return tifffile.imread(p).astype(np.float32)\n\n# ---------------------- RUN CONFIG ----------------------\n\nRUN_TAG = os.environ.get(\"NX47_RUN_TAG\", \"v61.3-default\")\nDRY_RUN = os.environ.get(\"NX47_DRY_RUN\", \"0\") == \"1\"\nPCTL_HI_BASE = float(os.environ.get(\"NX47_PCTL_HI_BASE\", \"88\"))\nPCTL_HI_GAIN = float(os.environ.get(\"NX47_PCTL_HI_GAIN\", \"6\"))\nPCTL_HI_MIN = float(os.environ.get(\"NX47_PCTL_HI_MIN\", \"88\"))\nPCTL_HI_MAX = float(os.environ.get(\"NX47_PCTL_HI_MAX\", \"96\"))\nPCTL_LO_GAP = float(os.environ.get(\"NX47_PCTL_LO_GAP\", \"6\"))\nPCTL_LO_MIN = float(os.environ.get(\"NX47_PCTL_LO_MIN\", \"80\"))\n\n# ---------------------- AUTO THRESHOLD SLICE-LOCAL ----------------------\ndef slice_percentiles(slice_data):\n    flat = slice_data.ravel()\n    p90 = np.percentile(flat, 90)\n    p95 = np.percentile(flat, 95)\n    std = np.std(flat)\n    hi = float(np.clip(PCTL_HI_BASE + PCTL_HI_GAIN*(p95 - p90)/(std + 1e-6), PCTL_HI_MIN, PCTL_HI_MAX))\n    lo = max(hi - PCTL_LO_GAP, PCTL_LO_MIN)\n    return hi, lo\n\n# ---------------------- PROCESS ONE FILE ----------------------\ndef process_file(path, ablation=None, ultra_aggressive=True):\n    t_file = time.time_ns()\n\n    vol = read_tiff(path)\n    vol = (vol - vol.min()) / (vol.max() - vol.min() + 1e-6)\n    vol_gpu = xp.asarray(vol)\n\n    sigma = float(xp.std(vol_gpu) * 0.9 + 0.4)\n    smooth = gaussian_filter(vol_gpu, sigma=sigma)\n    resid = vol_gpu - smooth\n\n    # ----- SCORES (REAL, DYNAMIC) -----\n    nx_vals = [v for v in nx47.run_all().values() if isinstance(v,(int,float))]\n    nx_score = float(np.mean(nx_vals)) if nx_vals else 0.0\n    a3 = solve_aimo3(\"sum all values\")\n    a3_score = float(np.mean(list(a3.values()))) if isinstance(a3,dict) and a3 else 0.0\n\n    # ----- ABLATION CONTROL -----\n    if ablation == \"nx47\": a3_score = 0.0\n    if ablation == \"aimo3\": nx_score = 0.0\n\n    # ----- NON-LINEAR FUSION -----\n    fusion_score_global = 0.7*np.tanh(nx_score*2.0) + 0.3*np.tanh(a3_score*2.5)\n\n    # ----- ULTRA-AGGRESSIVE ADAPTIVE BOOST -----\n    if ultra_aggressive:\n        vol_std_global = float(xp.std(vol_gpu))\n        fusion_score_global *= 1.0 + 0.5*np.tanh(vol_std_global*1.5)\n\n    logger.log(\"FUSION_SCORE_GLOBAL\", {\"file\": path.name, \"score\": fusion_score_global})\n\n    Z = vol_gpu.shape[0]\n    out = []\n\n    for z in range(Z):\n        t0 = time.time_ns()\n        z0, z1 = max(0, z-1), min(Z, z+2)\n        proj = xp.mean(resid[z0:z1], axis=0)\n\n        # ----- LOCAL MULTI-SCALE VARIANCE -----\n        local_vol = vol_gpu[max(0,z-2):min(Z,z+3)]\n        local_std = float(xp.std(local_vol))\n\n        # ----- ULTRA-AGGRESSIVE WEIGHT DYNAMIC (FUSION SCORE IMPACT) -----\n        weight_base = 0.15\n        if ultra_aggressive:\n            weight = weight_base + 0.25*np.tanh(fusion_score_global)*np.tanh(local_std*2.0) \\\n                     + 0.1*np.tanh(local_std*3.0)\n        else:\n            weight = weight_base + 0.25*np.tanh(fusion_score_global)*np.tanh(local_std*2.0)\n        proj = proj + weight\n\n        # ----- SLICE-LOCAL AUTO THRESHOLD -----\n        proj_cpu = xp.asnumpy(proj)\n        p_hi, p_lo = slice_percentiles(proj_cpu)\n\n        mask_hi = proj > np.percentile(proj_cpu, p_hi)\n        mask_lo = proj > np.percentile(proj_cpu, p_lo)\n        w = xp.clip((proj - np.percentile(proj_cpu, p_lo)) /\n                    (np.percentile(proj_cpu, p_hi) - np.percentile(proj_cpu, p_lo) + 1e-6), 0.0, 1.0)\n        final = (w * xp.logical_and(mask_hi, mask_lo) +\n                 (1.0 - w) * xp.logical_or(mask_hi, mask_lo)) > 0.5\n        out.append(final.astype(xp.uint8))\n\n        latency = time.time_ns() - t0\n        # ----- ULTRA-DEBUG++ LOGGING -----\n        logger.slice_metric(\n            path.name, z, latency,\n            fusion_score=float(fusion_score_global),\n            weight=float(weight),\n            p_hi=p_hi,\n            p_lo=p_lo,\n            w=w\n        )\n\n    mask = xp.stack(out)\n    checksum = hashlib.sha256(vol.tobytes()).hexdigest()[:16]\n\n    logger.file_metric(path.name, checksum, Z)\n    logger.log(\"FILE_DONE\", {\"file\": path.name, \"checksum\": checksum, \"slices\": Z})\n\n        # NX47 v61.2: align to competitor-like binary uint8 domain (0/1) while preserving 3D multipage TIFF.\n    return xp.asnumpy(mask).astype(np.uint8)\n\n# ---------------------- RUN ALL ----------------------\nif DRY_RUN:\n    logger.log(\"DRY_RUN_EXIT\", {\"run_tag\": RUN_TAG, \"note\": \"preflight mode before Kaggle IO scan\"})\n    print(\"DRY_RUN READY:\", ZIP_PATH)\n    raise SystemExit(0)\n\nFILES = sorted(TEST_DIR.rglob(\"*.tif\"))\nif not FILES:\n    raise RuntimeError(\"NO TEST FILES FOUND\")\n\nlogger.log(\"FILES_READY\", {\"count\": len(FILES), \"run_tag\": RUN_TAG})\n\n\nwith zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_STORED) as zf:\n    for f in FILES:\n        m = process_file(f)  # ablation=None, ultra_aggressive=True\n        out = OUT / f.name\n        if m.ndim != 3:\n            raise RuntimeError(f\"Invalid NX47 output rank for {f.name}: {m.shape} (expected 3D Z,H,W)\")\n        binary_mode = os.environ.get(\"NX47_BINARY_MODE\", \"0_1\").strip().lower()\n        if binary_mode not in {\"0_1\", \"0_255\"}:\n            raise RuntimeError(f\"Invalid NX47_BINARY_MODE: {binary_mode}\")\n        m_write = m.astype(np.uint8)\n        if binary_mode == \"0_255\":\n            m_write = (m_write > 0).astype(np.uint8) * 255\n        else:\n            m_write = (m_write > 0).astype(np.uint8)\n        tifffile.imwrite(out, m_write, compression=\"LZW\")\n        zf.write(out, arcname=f.name)\n        out.unlink()\n        gc.collect()\n\n# ---------------------- GLOBAL SUMMARY ----------------------\ndf_slices = pd.DataFrame(logger.slice_rows)\ndf_files  = pd.DataFrame(logger.file_rows)\n\nprint(\"\\n===== SLICE SUMMARY (ALL FILES) =====\")\nprint(df_slices.groupby(\"file\")[[\"latency_ms\",\"fusion_score\",\"weight\",\"p_hi\",\"p_lo\",\"w_mean\"]].agg([\"count\",\"mean\",\"min\",\"max\"]))\n\nprint(\"\\n===== GLOBAL SLICE MEAN (ALL FILES) =====\")\nprint(df_slices[\"latency_ms\"].mean(), \"ms\")\n\nprint(\"\\n===== FILE CHECKSUMS =====\")\nprint(df_files.to_string(index=False))\n\nlogger.log(\"SUBMISSION_READY\", {\"zip\": str(ZIP_PATH)})\nlogger.log(\"EXEC_COMPLETE\")\n\n\n# ---- V61.5 forensic360 add-on ----\ntry:\n    dep_manifest = {\n        \"paths\": [\"/kaggle/input/datasets/ndarray2000/nx47-dependencies\", \"/kaggle/input/nx47-dependencies\"],\n        \"packages\": {\n            \"imagecodecs\": importlib.util.find_spec(\"imagecodecs\") is not None,\n            \"tifffile\": importlib.util.find_spec(\"tifffile\") is not None,\n        },\n    }\n    Path('/kaggle/working/dependency_manifest_v615.json').write_text(json.dumps(dep_manifest, indent=2), encoding='utf-8')\n    logger.log(\"DEPENDENCY_MANIFEST_WRITTEN\", dep_manifest)\nexcept Exception as _dep_exc:\n    logger.log(\"DEPENDENCY_MANIFEST_FAILED\", {\"error\": str(_dep_exc)})\n\nfor alias in [Path(\"/kaggle/working/nx47_vesuvius/submission.zip\"), Path(\"submission.zip\"), Path(\"nx47_vesuvius/submission.zip\")]:\n    alias.parent.mkdir(parents=True, exist_ok=True)\n    if alias.resolve() != ZIP_PATH.resolve():\n        import shutil\n        shutil.copyfile(ZIP_PATH, alias)\n\nprint(\"READY:\", ZIP_PATH)\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloc source intégré: V144.2\n",
    "Source: `RAPPORT-VESUVIUS/notebook-version-NX47-V144.2/nx47-vesu-kernel-new-v144-2.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generated from nx47-vesu-kernel-new-v144-2.ipynb\n",
    "# Source notebook is kept intact.\n",
    "\n",
    "# %% [code cell 1]\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 01) NX47 V144.2 Kernel\n",
    "# 02) Kaggle Vesuvius pipeline: discovery -> load -> features -> segment -> overlay -> package\n",
    "# 03) Robust offline dependencies + LZW-safe TIFF I/O + slice-wise adaptive fusion\n",
    "# ================================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from hashlib import sha512\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import (\n",
    "    binary_closing,\n",
    "    binary_propagation,\n",
    "    gaussian_filter,\n",
    "    generate_binary_structure,\n",
    "    label,\n",
    "    laplace,\n",
    "    sobel,\n",
    "    uniform_filter,\n",
    ")\n",
    "\n",
    "import tifffile\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageSequence\n",
    "except Exception:  # pragma: no cover\n",
    "    Image = None\n",
    "    ImageSequence = None\n",
    "\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "except Exception:  # pragma: no cover\n",
    "    torch = None\n",
    "    nn = None\n",
    "    F = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class V1442Config:\n",
    "    top_k_features: int = 6\n",
    "    train_max_samples: int = 250_000\n",
    "    l1_candidates: Tuple[float, ...] = (1e-4, 3e-4, 1e-3, 3e-3, 1e-2)\n",
    "    l2_candidates: Tuple[float, ...] = (1e-4, 1e-3, 1e-2)\n",
    "    max_iter: int = 120\n",
    "    lr: float = 0.08\n",
    "\n",
    "    pseudo_pos_pct: float = 99.0\n",
    "    pseudo_neg_pct: float = 50.0\n",
    "\n",
    "    z_radius: int = 3\n",
    "    xy_radius: int = 2\n",
    "\n",
    "    target_active_ratio: float = 0.03\n",
    "\n",
    "    max_layers: int = 320\n",
    "    overlay_stride: int = 8\n",
    "    full_pixel_trace: bool = False\n",
    "    trace_pixel_budget: int = 4000\n",
    "\n",
    "    ultra_console_log: bool = True\n",
    "    ultra_step_log: bool = True\n",
    "    ultra_bit_trace_arrays: bool = True\n",
    "    ultra_bit_trace_limit: int = 64\n",
    "\n",
    "    # V125: meta-neuron / evolutionary controls\n",
    "    meta_neurons: int = 3\n",
    "    ratio_candidates: Tuple[float, ...] = (0.02, 0.04, 0.06, 0.08, 0.12)\n",
    "    pruning_quantile: float = 0.25\n",
    "    mutation_noise: float = 0.015\n",
    "    f1_stagnation_window: int = 5\n",
    "    run_simulation_100: bool = False\n",
    "    simulation_export_curve: bool = True\n",
    "\n",
    "    # V125 supervised mode\n",
    "    supervised_train: bool = True\n",
    "    max_train_volumes: int = 24\n",
    "    max_val_volumes: int = 8\n",
    "    max_samples_per_volume: int = 40_000\n",
    "    pos_neg_ratio: float = 1.0\n",
    "    strong_th: float = 0.65\n",
    "    weak_th: float = 0.45\n",
    "    dust_min_size: int = 24\n",
    "    golden_nonce_topk: int = 11\n",
    "    supervised_epochs: int = 0\n",
    "    convergence_patience: int = 5\n",
    "    convergence_min_delta: float = 1e-6\n",
    "    auto_epoch_safety_cap: int = 0\n",
    "    threshold_scan: Tuple[float, ...] = (0.35, 0.4, 0.45, 0.5, 0.55, 0.6)\n",
    "    fbeta_beta: float = 0.5\n",
    "\n",
    "    # V131 2.5D U-Net competitive path\n",
    "    use_unet_25d: bool = True\n",
    "    unet_in_slices: int = 7\n",
    "    unet_base_channels: int = 24\n",
    "    patch_size: int = 128\n",
    "    patch_stride: int = 64\n",
    "    unet_epochs: int = 2\n",
    "    unet_lr: float = 1e-3\n",
    "    unet_batch_size: int = 8\n",
    "\n",
    "    # Logit forensic audit\n",
    "    export_logit_audit: bool = True\n",
    "    logit_hist_bins: int = 20\n",
    "\n",
    "    # V131 forensic integration (V130 logs + concurrent benchmark)\n",
    "    v130_log_path: str = 'nx47-vesu-kernel-new-v130.log'\n",
    "    export_forensic_v1442_report: bool = True\n",
    "\n",
    "    # V133 strict continuity + no fallback policy\n",
    "    enforce_nx_legacy_continuity: bool = True\n",
    "    strict_no_fallback: bool = True\n",
    "    min_train_pairs_required: int = 786\n",
    "    require_train_completion_100: bool = True\n",
    "    forbid_autonomous_mode: bool = True\n",
    "    enforce_no_hardcoded_metrics: bool = True\n",
    "    hardcoded_metric_policy: str = \"warn\"  # warn|error\n",
    "    adapt_train_threshold_to_dataset_size: bool = True\n",
    "    train_pair_coverage_target_pct: float = 100.0\n",
    "    min_train_image_files_required: int = 786\n",
    "    min_train_label_files_required: int = 786\n",
    "    enforce_competition_rules: bool = True\n",
    "    competition_rules_path: str = \"Competition_Rules_Vesuvius_Challenge _Surface_Detection.md\"\n",
    "    metric_demo_notebook_path: str = \"vesuvius-2025-metric-demo.ipynb\"\n",
    "\n",
    "    # V138 execution hardening\n",
    "    preflight_train_pct: float = 5.0\n",
    "    preflight_test_pct: float = 5.0\n",
    "    progress_bar_width: int = 24\n",
    "    heartbeat_interval_s: float = 30.0\n",
    "    stage_stall_alert_s: float = 180.0\n",
    "    run_ablation_check: bool = True\n",
    "    stability_probe_runs: int = 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PlanStep:\n",
    "    name: str\n",
    "    description: str\n",
    "    progress: float = 0.0\n",
    "    done: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PlanTracker:\n",
    "    output_path: Path\n",
    "    steps: List[PlanStep] = field(default_factory=list)\n",
    "\n",
    "    def add_step(self, name: str, description: str) -> None:\n",
    "        self.steps.append(PlanStep(name=name, description=description))\n",
    "\n",
    "    def update(self, name: str, progress: float, done: bool = False) -> None:\n",
    "        for step in self.steps:\n",
    "            if step.name == name:\n",
    "                step.progress = float(np.clip(progress, 0.0, 100.0))\n",
    "                step.done = done\n",
    "                break\n",
    "        self._write()\n",
    "\n",
    "    def overall_progress(self) -> float:\n",
    "        return float(np.mean([s.progress for s in self.steps])) if self.steps else 0.0\n",
    "\n",
    "    def _write(self) -> None:\n",
    "        payload = {\n",
    "            \"generated_at_ns\": time.time_ns(),\n",
    "            \"roadmap\": [\n",
    "                {\n",
    "                    \"name\": s.name,\n",
    "                    \"description\": s.description,\n",
    "                    \"progress_percent\": round(s.progress, 2),\n",
    "                    \"done\": s.done,\n",
    "                }\n",
    "                for s in self.steps\n",
    "            ],\n",
    "            \"overall_progress_percent\": round(self.overall_progress(), 2),\n",
    "        }\n",
    "        self.output_path.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class MemoryTracker:\n",
    "    def __init__(self) -> None:\n",
    "        self.events: List[Dict[str, Any]] = []\n",
    "\n",
    "    def log_array(self, stage: str, arr: np.ndarray) -> None:\n",
    "        arr = np.asarray(arr)\n",
    "        self.events.append(\n",
    "            {\n",
    "                \"ts_ns\": time.time_ns(),\n",
    "                \"stage\": stage,\n",
    "                \"shape\": list(arr.shape),\n",
    "                \"dtype\": str(arr.dtype),\n",
    "                \"bytes\": int(arr.nbytes),\n",
    "                \"min\": float(arr.min()) if arr.size else 0.0,\n",
    "                \"max\": float(arr.max()) if arr.size else 0.0,\n",
    "                \"mean\": float(arr.mean()) if arr.size else 0.0,\n",
    "                \"sha512\": sha512(arr.tobytes()).hexdigest(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class UltraAuthentic360Merkle:\n",
    "    def __init__(self, path: Path, console: bool = True) -> None:\n",
    "        self.path = path\n",
    "        self.console = console\n",
    "        self.prev_hash = \"0\" * 128\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.path.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "    def bit_stats(self, arr: np.ndarray, bit_limit: int) -> Dict[str, Any]:\n",
    "        raw = np.asarray(arr).tobytes()\n",
    "        preview = raw[: max(0, int(bit_limit))]\n",
    "        ones = int(sum(bin(b).count(\"1\") for b in preview))\n",
    "        return {\n",
    "            \"byte_preview_len\": len(preview),\n",
    "            \"one_bits_in_preview\": ones,\n",
    "            \"zero_bits_in_preview\": len(preview) * 8 - ones,\n",
    "            \"preview_sha512\": sha512(preview).hexdigest(),\n",
    "        }\n",
    "\n",
    "    def emit(self, event: Dict[str, Any]) -> None:\n",
    "        payload = dict(event)\n",
    "        payload[\"prev_merkle\"] = self.prev_hash\n",
    "        canonical = json.dumps(payload, sort_keys=True, default=str)\n",
    "        cur = sha512(canonical.encode()).hexdigest()\n",
    "        payload[\"merkle\"] = cur\n",
    "        self.prev_hash = cur\n",
    "        line = json.dumps(payload, ensure_ascii=False)\n",
    "        with self.path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(line + \"\\n\")\n",
    "        if self.console:\n",
    "            print(line, flush=True)\n",
    "\n",
    "\n",
    "def _is_pkg_available(package_name: str) -> bool:\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def install_offline(package_name: str) -> None:\n",
    "    if _is_pkg_available(package_name):\n",
    "        return\n",
    "\n",
    "    exact_wheel_dir = Path(\"/kaggle/input/datasets/ndarray2000/nx47-dependencies\")\n",
    "    fallback_wheel_dir = Path(\"/kaggle/input/nx47-dependencies\")\n",
    "    extra_dirs = [\n",
    "        Path(\"/kaggle/input/nx47-deps\"),\n",
    "        Path(\"/kaggle/input/vesuvius-nx47-dependencies\"),\n",
    "        Path(\"/kaggle/input/datasets/ndarray2000\"),\n",
    "    ]\n",
    "\n",
    "    exact_wheels = {\n",
    "        \"imagecodecs\": exact_wheel_dir / \"imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n",
    "        \"numpy\": exact_wheel_dir / \"numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n",
    "        \"tifffile\": exact_wheel_dir / \"tifffile-2026.1.28-py3-none-any.whl\",\n",
    "    }\n",
    "\n",
    "    if package_name in exact_wheels and exact_wheels[package_name].exists():\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", str(exact_wheels[package_name])])\n",
    "            return\n",
    "        except subprocess.CalledProcessError:\n",
    "            pass\n",
    "\n",
    "    for wheel_dir in (exact_wheel_dir, fallback_wheel_dir, *extra_dirs):\n",
    "        if wheel_dir.exists():\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", f\"--find-links={wheel_dir}\", package_name])\n",
    "                return\n",
    "            except subprocess.CalledProcessError:\n",
    "                continue\n",
    "\n",
    "    raise RuntimeError(f\"Offline dependency directory not found for {package_name}\")\n",
    "\n",
    "\n",
    "def bootstrap_dependencies_fail_fast() -> None:\n",
    "    install_offline(\"numpy\")\n",
    "    install_offline(\"imagecodecs\")\n",
    "    install_offline(\"tifffile\")\n",
    "    global tifffile\n",
    "    tifffile = importlib.reload(tifffile)\n",
    "\n",
    "\n",
    "def ensure_imagecodecs() -> bool:\n",
    "    try:\n",
    "        import imagecodecs  # noqa\n",
    "        return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        install_offline(\"imagecodecs\")\n",
    "        import imagecodecs  # noqa\n",
    "        global tifffile\n",
    "        tifffile = importlib.reload(tifffile)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def read_tiff_lzw_safe(path: Path) -> np.ndarray:\n",
    "    try:\n",
    "        return tifffile.imread(path)\n",
    "    except ValueError as exc:\n",
    "        if \"requires the 'imagecodecs' package\" not in str(exc):\n",
    "            raise\n",
    "\n",
    "    ensure_imagecodecs()\n",
    "    try:\n",
    "        return tifffile.imread(path)\n",
    "    except ValueError as exc:\n",
    "        if \"requires the 'imagecodecs' package\" not in str(exc):\n",
    "            raise\n",
    "\n",
    "    if Image is None or ImageSequence is None:\n",
    "        raise RuntimeError(\"LZW TIFF read failed and Pillow fallback unavailable\")\n",
    "    with Image.open(path) as img:\n",
    "        frames = [np.array(frame, dtype=np.float32) for frame in ImageSequence.Iterator(img)]\n",
    "    if not frames:\n",
    "        raise RuntimeError(f\"No frames decoded from TIFF: {path}\")\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "\n",
    "def write_tiff_lzw_safe(path: Path, arr: np.ndarray) -> None:\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 2:\n",
    "        arr = arr[np.newaxis, ...]\n",
    "    if arr.ndim != 3:\n",
    "        raise RuntimeError(f\"Unsupported TIFF array shape for write: {arr.shape}\")\n",
    "\n",
    "    try:\n",
    "        if ensure_imagecodecs():\n",
    "            tifffile.imwrite(path, arr, compression=\"LZW\")\n",
    "            return\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if Image is None:\n",
    "        raise RuntimeError(\"LZW TIFF write failed: Pillow fallback unavailable\")\n",
    "\n",
    "    pages = [Image.fromarray(frame.astype(np.uint8)) for frame in arr]\n",
    "    if not pages:\n",
    "        raise RuntimeError(\"Cannot write empty TIFF volume\")\n",
    "    pages[0].save(path, save_all=True, append_images=pages[1:], compression=\"tiff_lzw\")\n",
    "\n",
    "\n",
    "class NX47AtomNeuron:\n",
    "    def __init__(self, n_features: int) -> None:\n",
    "        self.w = np.zeros(n_features, dtype=np.float64)\n",
    "        self.alpha = np.zeros(n_features, dtype=np.float64)\n",
    "        self.beta = np.zeros(n_features, dtype=np.float64)\n",
    "        self.b = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "        z = np.clip(z, -30, 30)\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def predict_proba(self, x: np.ndarray, grad_x: np.ndarray | None = None) -> np.ndarray:\n",
    "        gx = grad_x if grad_x is not None else np.gradient(x, axis=0)\n",
    "        z = x @ self.w + (x * x) @ self.alpha + gx @ self.beta + self.b\n",
    "        return self._sigmoid(z)\n",
    "\n",
    "    def fit_prox(self, x: np.ndarray, y: np.ndarray, lr: float, max_iter: int, l1: float, l2: float, progress_cb: Callable[..., None] | None = None, progress_prefix: Dict[str, Any] | None = None) -> Dict[str, float]:\n",
    "        n = max(1, x.shape[0])\n",
    "        gx = np.gradient(x, axis=0)\n",
    "        active_start = int(np.sum((np.abs(self.w) + np.abs(self.alpha) + np.abs(self.beta)) > 1e-8))\n",
    "        w_start = self.w.copy()\n",
    "        a_start = self.alpha.copy()\n",
    "        beta_start = self.beta.copy()\n",
    "        active_mid = active_start\n",
    "        for it in range(max_iter):\n",
    "            p = self.predict_proba(x, gx)\n",
    "            err = p - y\n",
    "            grad_w = (x.T @ err) / n + l2 * self.w\n",
    "            grad_alpha = ((x * x).T @ err) / n + l2 * self.alpha\n",
    "            grad_beta = (gx.T @ err) / n + l2 * self.beta\n",
    "            grad_b = float(np.mean(err))\n",
    "            if progress_cb is not None and ((it + 1) % 10 == 0 or it == 0 or (it + 1) == max_iter):\n",
    "                payload = dict(progress_prefix or {})\n",
    "                payload.update({'substage': 'fit_prox_iter', 'iter': int(it + 1), 'max_iter': int(max_iter), 'iter_progress_percent': float(100.0 * (it + 1) / max(1, max_iter))})\n",
    "                progress_cb(**payload)\n",
    "\n",
    "            w_temp = self.w - lr * grad_w\n",
    "            a_temp = self.alpha - lr * grad_alpha\n",
    "            b_temp = self.beta - lr * grad_beta\n",
    "            self.w = np.sign(w_temp) * np.maximum(np.abs(w_temp) - lr * l1, 0.0)\n",
    "            self.alpha = np.sign(a_temp) * np.maximum(np.abs(a_temp) - lr * l1, 0.0)\n",
    "            self.beta = np.sign(b_temp) * np.maximum(np.abs(b_temp) - lr * l1, 0.0)\n",
    "            self.b -= lr * grad_b\n",
    "            if it == max_iter // 2:\n",
    "                active_mid = int(np.sum((np.abs(self.w) + np.abs(self.alpha) + np.abs(self.beta)) > 1e-8))\n",
    "        p = self.predict_proba(x, gx)\n",
    "        eps = 1e-9\n",
    "        ce = -float(np.mean(y * np.log(p + eps) + (1.0 - y) * np.log(1.0 - p + eps)))\n",
    "        active_end = int(np.sum((np.abs(self.w) + np.abs(self.alpha) + np.abs(self.beta)) > 1e-8))\n",
    "        return {\n",
    "            \"cross_entropy\": ce,\n",
    "            \"non_zero_weights\": active_end,\n",
    "            \"active_neurons_start\": active_start,\n",
    "            \"active_neurons_mid\": active_mid,\n",
    "            \"active_neurons_end\": active_end,\n",
    "            \"weight_delta_l2\": float(np.linalg.norm(self.w - w_start)),\n",
    "            \"alpha_delta_l2\": float(np.linalg.norm(self.alpha - a_start)),\n",
    "            \"beta_delta_l2\": float(np.linalg.norm(self.beta - beta_start)),\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NX47EvolutionMemory:\n",
    "    f1_history: List[float] = field(default_factory=list)\n",
    "    ratio_history: List[float] = field(default_factory=list)\n",
    "    mutation_events: int = 0\n",
    "    pruning_events: int = 0\n",
    "\n",
    "    def update(self, f1_proxy: float, ratio: float) -> None:\n",
    "        self.f1_history.append(float(f1_proxy))\n",
    "        self.ratio_history.append(float(ratio))\n",
    "\n",
    "    def adapt_learning_rate(self, base_lr: float, window: int) -> float:\n",
    "        if len(self.f1_history) < max(2, window):\n",
    "            return float(base_lr)\n",
    "        recent = self.f1_history[-window:]\n",
    "        spread = float(np.max(recent) - np.min(recent))\n",
    "        return float(base_lr * (0.65 if spread < 1e-3 else 1.0))\n",
    "\n",
    "\n",
    "def compute_proxy_f1(prob: np.ndarray, target: np.ndarray, threshold: float = 0.5) -> float:\n",
    "    pred = prob >= threshold\n",
    "    tp = float(np.logical_and(pred, target > 0.5).sum())\n",
    "    fp = float(np.logical_and(pred, target <= 0.5).sum())\n",
    "    fn = float(np.logical_and(~pred, target > 0.5).sum())\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    return float(2.0 * precision * recall / (precision + recall + 1e-9))\n",
    "\n",
    "\n",
    "def choose_adaptive_ratio(prob: np.ndarray, ratios: Tuple[float, ...]) -> Tuple[np.ndarray, Dict[str, Any]]:\n",
    "    best_ratio = float(ratios[0])\n",
    "    best_score = -1e18\n",
    "    best_mask = calibrate_target_ratio(prob, best_ratio)\n",
    "    details: List[Dict[str, float]] = []\n",
    "    for r in ratios:\n",
    "        cand = calibrate_target_ratio(prob, float(r))\n",
    "        lbl, comp_count = label(cand.astype(np.uint8))\n",
    "        comp_sizes = np.bincount(lbl.ravel()) if comp_count > 0 else np.array([0])\n",
    "        coherence = float(cand.mean())\n",
    "        noise = float((comp_sizes[1:] < 16).sum()) if comp_count > 0 else 0.0\n",
    "        score = coherence - 0.001 * noise\n",
    "        details.append({'ratio': float(r), 'score': score, 'coherence': coherence, 'noise_components': noise})\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_ratio = float(r)\n",
    "            best_mask = cand\n",
    "    return best_mask.astype(bool), {'selected_ratio': best_ratio, 'ratio_scan': details}\n",
    "\n",
    "\n",
    "def choose_slicewise_adaptive_ratio(volume: np.ndarray, prob: np.ndarray, ratios: Tuple[float, ...]) -> Dict[str, Any]:\n",
    "    # ratio(x,y,z) proxy: each z slice votes a ratio according to entropy/gradient complexity\n",
    "    ent = np.log1p(np.maximum(volume.var(axis=(1, 2)), 1e-12))\n",
    "    gx = np.mean(np.abs(np.gradient(volume, axis=1)), axis=(1, 2))\n",
    "    gy = np.mean(np.abs(np.gradient(volume, axis=2)), axis=(1, 2))\n",
    "    complexity = _zscore(ent + gx + gy)\n",
    "    ratios_arr = np.array(ratios, dtype=np.float64)\n",
    "    bins = np.linspace(complexity.min() - 1e-9, complexity.max() + 1e-9, len(ratios_arr) + 1)\n",
    "    assigned = []\n",
    "    for c in complexity:\n",
    "        idx = int(np.clip(np.digitize(c, bins) - 1, 0, len(ratios_arr) - 1))\n",
    "        assigned.append(float(ratios_arr[idx]))\n",
    "    ratio_global = float(np.mean(assigned))\n",
    "    ratio_global = float(ratios_arr[np.argmin(np.abs(ratios_arr - ratio_global))])\n",
    "    mask_global = calibrate_target_ratio(prob, ratio_global)\n",
    "    return {\n",
    "        'slice_ratio_profile': assigned,\n",
    "        'slice_ratio_mean': float(np.mean(assigned)),\n",
    "        'slice_ratio_std': float(np.std(assigned)),\n",
    "        'ratio_global_selected': ratio_global,\n",
    "        'mask_global': mask_global,\n",
    "    }\n",
    "\n",
    "\n",
    "def dynamic_regularization_lambda(mask: np.ndarray, features: np.ndarray) -> float:\n",
    "    var_mask = float(np.var(mask.astype(np.float32)))\n",
    "    feat_entropy = float(np.mean(np.log1p(np.maximum(np.var(features, axis=(1, 2)), 1e-12))))\n",
    "    return float(var_mask / (abs(feat_entropy) + 1e-8))\n",
    "\n",
    "\n",
    "def simulate_f1_vs_ratio_curve() -> Dict[str, Any]:\n",
    "    ratios = np.linspace(0.01, 0.25, 50)\n",
    "    precision = np.clip(1.0 - (ratios * 2.0), 0.01, 1.0)\n",
    "    recall = np.clip(ratios * 4.0, 0.01, 1.0)\n",
    "    f1_scores = 2.0 * precision * recall / (precision + recall + 1e-8)\n",
    "    best_idx = int(np.argmax(f1_scores))\n",
    "    return {\n",
    "        'ratios': ratios.tolist(),\n",
    "        'f1_scores': f1_scores.tolist(),\n",
    "        'best_ratio': float(ratios[best_idx]),\n",
    "        'best_f1': float(f1_scores[best_idx]),\n",
    "    }\n",
    "\n",
    "\n",
    "def _zscore(arr: np.ndarray) -> np.ndarray:\n",
    "    m, s = float(arr.mean()), float(arr.std())\n",
    "    return (arr - m) / (s + 1e-6)\n",
    "\n",
    "\n",
    "def slice_adaptive_fusion(volume: np.ndarray) -> np.ndarray:\n",
    "    z = volume.shape[0]\n",
    "    if z <= 1:\n",
    "        return volume[0]\n",
    "    w = np.linspace(1.0, 1.4, z, dtype=np.float32)\n",
    "    w = w / (w.sum() + 1e-6)\n",
    "    return np.tensordot(w, volume, axes=(0, 0)).astype(np.float32)\n",
    "\n",
    "\n",
    "def extract_multi_features(volume: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n",
    "    fused = slice_adaptive_fusion(volume)\n",
    "    proj_mean = 0.7 * np.mean(volume, axis=0) + 0.3 * fused\n",
    "    proj_max = np.max(volume, axis=0)\n",
    "    gx, gy = sobel(proj_mean, axis=1), sobel(proj_mean, axis=0)\n",
    "    grad_mag = np.sqrt(gx * gx + gy * gy)\n",
    "    lap = laplace(proj_mean)\n",
    "    mu = uniform_filter(proj_mean, size=7)\n",
    "    mu2 = uniform_filter(proj_mean * proj_mean, size=7)\n",
    "    local_var = np.maximum(mu2 - mu * mu, 0.0)\n",
    "    local_entropy = np.log1p(local_var * 255.0)\n",
    "    coherence = 1.0 / (1.0 + np.std(volume, axis=0))\n",
    "    low = gaussian_filter(proj_mean, sigma=3.0)\n",
    "    high = proj_mean - gaussian_filter(proj_mean, sigma=1.0)\n",
    "    bandpass = high + (proj_mean - low)\n",
    "\n",
    "    feats = [proj_mean, proj_max, grad_mag, lap, local_var, local_entropy, coherence, bandpass]\n",
    "    names = [\"proj_mean\", \"proj_max\", \"grad_mag\", \"laplace\", \"local_var\", \"local_entropy\", \"coherence_inter_slice\", \"bandpass_response\"]\n",
    "    feats = [_zscore(f.astype(np.float32)) for f in feats]\n",
    "    return np.stack(feats, axis=0), names\n",
    "\n",
    "\n",
    "def auto_select_features(features: np.ndarray, names: List[str], top_k: int) -> Tuple[np.ndarray, List[str], np.ndarray]:\n",
    "    variances = np.array([float(np.var(features[i])) for i in range(features.shape[0])], dtype=np.float64)\n",
    "    order = np.argsort(variances)[::-1]\n",
    "    selected, selected_names = [], []\n",
    "    for idx in order:\n",
    "        cand = features[idx].ravel()\n",
    "        keep = True\n",
    "        for s in selected:\n",
    "            c = np.corrcoef(cand, s.ravel())[0, 1]\n",
    "            if np.isfinite(c) and abs(c) >= 0.97:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            selected.append(features[idx])\n",
    "            selected_names.append(names[idx])\n",
    "        if len(selected) >= top_k:\n",
    "            break\n",
    "    if not selected:\n",
    "        selected = [features[order[0]]]\n",
    "        selected_names = [names[order[0]]]\n",
    "    return np.stack(selected, axis=0), selected_names, variances\n",
    "\n",
    "\n",
    "def pseudo_labels(score_map: np.ndarray, pos_pct: float, neg_pct: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    flat = score_map.ravel()\n",
    "    pos = flat > np.percentile(flat, pos_pct)\n",
    "    neg = flat < np.percentile(flat, neg_pct)\n",
    "    keep = pos | neg\n",
    "    y = np.zeros_like(flat, dtype=np.float64)\n",
    "    y[pos] = 1.0\n",
    "    return keep, y\n",
    "\n",
    "\n",
    "def _binary_stats(pred: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n",
    "    p = pred.astype(bool)\n",
    "    t = y.astype(bool)\n",
    "    tp = float(np.logical_and(p, t).sum())\n",
    "    fp = float(np.logical_and(p, ~t).sum())\n",
    "    fn = float(np.logical_and(~p, t).sum())\n",
    "    iou = tp / (tp + fp + fn + 1e-9)\n",
    "    dice = (2.0 * tp) / (2.0 * tp + fp + fn + 1e-9)\n",
    "    f1 = dice\n",
    "    return {'tp': tp, 'fp': fp, 'fn': fn, 'iou': iou, 'dice': dice, 'f1': f1}\n",
    "\n",
    "\n",
    "def _fbeta_from_stats(stats: Dict[str, float], beta: float) -> float:\n",
    "    tp, fp, fn = stats['tp'], stats['fp'], stats['fn']\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    b2 = beta * beta\n",
    "    return float((1.0 + b2) * precision * recall / (b2 * precision + recall + 1e-9))\n",
    "\n",
    "\n",
    "def calibrate_thresholds(y_true: np.ndarray, prob: np.ndarray, thresholds: Tuple[float, ...], beta: float) -> Dict[str, Any]:\n",
    "    rows: List[Dict[str, float]] = []\n",
    "    best = None\n",
    "    for th in thresholds:\n",
    "        pred = prob >= float(th)\n",
    "        stats = _binary_stats(pred, y_true > 0.5)\n",
    "        fbeta = _fbeta_from_stats(stats, beta)\n",
    "        rec = {'threshold': float(th), 'f1': float(stats['f1']), 'iou': float(stats['iou']), 'dice': float(stats['dice']), 'fbeta': float(fbeta)}\n",
    "        rows.append(rec)\n",
    "        if best is None or rec['fbeta'] > best['fbeta']:\n",
    "            best = rec\n",
    "    return {'best': best, 'scan': rows}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class _TinyUNet2p5D(nn.Module if nn is not None else object):\n",
    "    def __init__(self, in_ch: int, base: int = 24) -> None:\n",
    "        if nn is None:\n",
    "            return\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.Sequential(nn.Conv2d(in_ch, base, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base, base, 3, padding=1), nn.ReLU(inplace=True))\n",
    "        self.enc2 = nn.Sequential(nn.Conv2d(base, base * 2, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base * 2, base * 2, 3, padding=1), nn.ReLU(inplace=True))\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.bottleneck = nn.Sequential(nn.Conv2d(base * 2, base * 4, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base * 4, base * 4, 3, padding=1), nn.ReLU(inplace=True))\n",
    "        self.up2 = nn.ConvTranspose2d(base * 4, base * 2, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(nn.Conv2d(base * 4, base * 2, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base * 2, base * 2, 3, padding=1), nn.ReLU(inplace=True))\n",
    "        self.up1 = nn.ConvTranspose2d(base * 2, base, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(nn.Conv2d(base * 2, base, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base, base, 3, padding=1), nn.ReLU(inplace=True))\n",
    "        self.head = nn.Conv2d(base, 1, 1)\n",
    "\n",
    "    def forward(self, x: 'torch.Tensor') -> 'torch.Tensor':\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        b = self.bottleneck(self.pool(e2))\n",
    "        d2 = self.up2(b)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "        return self.head(d1)\n",
    "\n",
    "\n",
    "def _extract_2p5d_patches(vol: np.ndarray, lbl2d: np.ndarray, cfg: V1442Config, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    z, h, w = vol.shape\n",
    "    c = max(3, int(cfg.unet_in_slices))\n",
    "    if c % 2 == 0:\n",
    "        c += 1\n",
    "    half = c // 2\n",
    "    ps = int(cfg.patch_size)\n",
    "    st = int(cfg.patch_stride)\n",
    "    xs: List[np.ndarray] = []\n",
    "    ys: List[np.ndarray] = []\n",
    "    z_center = z // 2\n",
    "    for y0 in range(0, max(1, h - ps + 1), st):\n",
    "        for x0 in range(0, max(1, w - ps + 1), st):\n",
    "            z0 = max(0, z_center - half)\n",
    "            z1 = min(z, z_center + half + 1)\n",
    "            stack = vol[z0:z1, y0:y0 + ps, x0:x0 + ps]\n",
    "            if stack.shape[0] < c:\n",
    "                pad = np.repeat(stack[-1:, :, :], c - stack.shape[0], axis=0)\n",
    "                stack = np.concatenate([stack, pad], axis=0)\n",
    "            if stack.shape[1] != ps or stack.shape[2] != ps:\n",
    "                continue\n",
    "            lab = lbl2d[y0:y0 + ps, x0:x0 + ps]\n",
    "            if lab.shape != (ps, ps):\n",
    "                continue\n",
    "            xs.append(stack.astype(np.float32))\n",
    "            ys.append(lab.astype(np.float32))\n",
    "    if not xs:\n",
    "        return np.zeros((0, c, ps, ps), dtype=np.float32), np.zeros((0, ps, ps), dtype=np.float32)\n",
    "    x_arr = np.stack(xs, axis=0)\n",
    "    y_arr = np.stack(ys, axis=0)\n",
    "    order = rng.permutation(x_arr.shape[0])\n",
    "    return x_arr[order], y_arr[order]\n",
    "\n",
    "\n",
    "def _dice_loss_from_logits(logits: 'torch.Tensor', target: 'torch.Tensor') -> 'torch.Tensor':\n",
    "    prob = torch.sigmoid(logits)\n",
    "    inter = (prob * target).sum(dim=(1, 2, 3))\n",
    "    den = prob.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) + 1e-6\n",
    "    return 1.0 - (2.0 * inter + 1e-6) / den\n",
    "\n",
    "\n",
    "def train_unet_25d_supervised(train_x: np.ndarray, train_y: np.ndarray, val_x: np.ndarray, val_y: np.ndarray, cfg: V1442Config, rng: np.random.Generator) -> Dict[str, Any]:\n",
    "    if torch is None or nn is None:\n",
    "        return {'status': 'torch_unavailable'}\n",
    "    if train_x.shape[0] == 0 or val_x.shape[0] == 0:\n",
    "        return {'status': 'empty_patch_set'}\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = _TinyUNet2p5D(in_ch=train_x.shape[1], base=cfg.unet_base_channels).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=float(cfg.unet_lr))\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def make_batches(x: np.ndarray, y: np.ndarray, bs: int):\n",
    "        for i in range(0, x.shape[0], bs):\n",
    "            xb = torch.from_numpy(x[i:i+bs]).to(device)\n",
    "            yb = torch.from_numpy(y[i:i+bs])[:, None, :, :].to(device)\n",
    "            yield xb, yb\n",
    "\n",
    "    hist = []\n",
    "    best = {'fbeta': -1.0}\n",
    "    for ep in range(max(1, int(cfg.unet_epochs))):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, yb in make_batches(train_x, train_y, int(cfg.unet_batch_size)):\n",
    "            opt.zero_grad()\n",
    "            lg = model(xb)\n",
    "            loss = 0.5 * bce(lg, yb) + 0.5 * _dice_loss_from_logits(lg, yb).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(float(loss.detach().cpu().item()))\n",
    "\n",
    "        model.eval()\n",
    "        probs = []\n",
    "        ys = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in make_batches(val_x, val_y, int(cfg.unet_batch_size)):\n",
    "                lg = model(xb)\n",
    "                pb = torch.sigmoid(lg).detach().cpu().numpy()[:, 0]\n",
    "                probs.append(pb)\n",
    "                ys.append(yb.detach().cpu().numpy()[:, 0])\n",
    "        prob = np.concatenate(probs, axis=0).reshape(-1)\n",
    "        ytrue = np.concatenate(ys, axis=0).reshape(-1)\n",
    "        th_info = calibrate_thresholds(ytrue, prob, cfg.threshold_scan, cfg.fbeta_beta)\n",
    "        stat = _binary_stats(prob >= th_info['best']['threshold'], ytrue > 0.5)\n",
    "        fbeta = _fbeta_from_stats(stat, cfg.fbeta_beta)\n",
    "        row = {\n",
    "            'epoch': ep,\n",
    "            'train_loss': float(np.mean(losses)) if losses else 0.0,\n",
    "            'val_f1': float(stat['f1']),\n",
    "            'val_iou': float(stat['iou']),\n",
    "            'val_fbeta': float(fbeta),\n",
    "            'best_threshold': float(th_info['best']['threshold']),\n",
    "        }\n",
    "        hist.append(row)\n",
    "        if fbeta > best['fbeta']:\n",
    "            best = {**row, 'fbeta': float(fbeta)}\n",
    "\n",
    "    return {\n",
    "        'status': 'ok',\n",
    "        'epoch_history': hist,\n",
    "        'best': best,\n",
    "        'threshold_scan_last': th_info['scan'],\n",
    "        'model_state': {k: v.detach().cpu().numpy().tolist()[:1] if v.ndim > 0 else float(v.detach().cpu().item()) for k, v in model.state_dict().items()},\n",
    "    }\n",
    "\n",
    "\n",
    "def audit_logits_distribution(prob: np.ndarray, y_true: np.ndarray | None, bins: int) -> Dict[str, Any]:\n",
    "    flat = prob.reshape(-1)\n",
    "    hist, edges = np.histogram(flat, bins=max(5, int(bins)), range=(0.0, 1.0))\n",
    "    payload: Dict[str, Any] = {\n",
    "        'min': float(flat.min()) if flat.size else 0.0,\n",
    "        'max': float(flat.max()) if flat.size else 0.0,\n",
    "        'mean': float(flat.mean()) if flat.size else 0.0,\n",
    "        'std': float(flat.std()) if flat.size else 0.0,\n",
    "        'hist_counts': hist.tolist(),\n",
    "        'hist_edges': edges.tolist(),\n",
    "    }\n",
    "    if y_true is not None:\n",
    "        y = y_true.reshape(-1) > 0.5\n",
    "        if np.any(y):\n",
    "            payload['pos_mean'] = float(flat[y].mean())\n",
    "            payload['pos_std'] = float(flat[y].std())\n",
    "        if np.any(~y):\n",
    "            payload['neg_mean'] = float(flat[~y].mean())\n",
    "            payload['neg_std'] = float(flat[~y].std())\n",
    "    return payload\n",
    "\n",
    "def _balance_sample_indices(y: np.ndarray, max_samples: int, pos_neg_ratio: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    pos_idx = np.where(y > 0.5)[0]\n",
    "    neg_idx = np.where(y <= 0.5)[0]\n",
    "    if pos_idx.size == 0 or neg_idx.size == 0:\n",
    "        all_idx = np.arange(y.size)\n",
    "        if all_idx.size <= max_samples:\n",
    "            return all_idx\n",
    "        return rng.choice(all_idx, size=max_samples, replace=False)\n",
    "    n_pos = min(pos_idx.size, int(max_samples * (pos_neg_ratio / (1.0 + pos_neg_ratio))))\n",
    "    n_neg = min(neg_idx.size, max_samples - n_pos)\n",
    "    sel_pos = rng.choice(pos_idx, size=max(1, n_pos), replace=pos_idx.size < max(1, n_pos))\n",
    "    sel_neg = rng.choice(neg_idx, size=max(1, n_neg), replace=neg_idx.size < max(1, n_neg))\n",
    "    idx = np.concatenate([sel_pos, sel_neg])\n",
    "    rng.shuffle(idx)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_nx47_supervised(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    x_val: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    cfg: V1442Config,\n",
    "    rng: np.random.Generator,\n",
    "    memory: NX47EvolutionMemory,\n",
    "    progress_cb: Callable[..., None] | None = None,\n",
    ") -> Tuple[NX47AtomNeuron, Dict[str, Any]]:\n",
    "    best, best_state = None, None\n",
    "    leaderboard: List[Dict[str, Any]] = []\n",
    "    epoch_history: List[Dict[str, Any]] = []\n",
    "    adaptive_lr = memory.adapt_learning_rate(cfg.lr, cfg.f1_stagnation_window)\n",
    "    grad_x_val = np.gradient(x_val, axis=0)\n",
    "\n",
    "    epoch = 0\n",
    "    best_obj_seen = None\n",
    "    stagnation = 0\n",
    "    while True:\n",
    "        total_candidates = max(1, max(1, cfg.meta_neurons) * len(cfg.l1_candidates) * len(cfg.l2_candidates))\n",
    "        candidate_idx = 0\n",
    "        for neuron_id in range(max(1, cfg.meta_neurons)):\n",
    "            for l1 in cfg.l1_candidates:\n",
    "                for l2 in cfg.l2_candidates:\n",
    "                    candidate_idx += 1\n",
    "                    if progress_cb is not None and (candidate_idx == 1 or candidate_idx % 3 == 0 or candidate_idx == total_candidates):\n",
    "                        progress_cb(\n",
    "                            stage='train_supervised',\n",
    "                            pct=100.0 * candidate_idx / total_candidates,\n",
    "                            substage='hyperparam_search',\n",
    "                            file_name='',\n",
    "                            index=candidate_idx,\n",
    "                            total=total_candidates,\n",
    "                            epoch=int(epoch),\n",
    "                            neuron_id=int(neuron_id),\n",
    "                            l1=float(l1),\n",
    "                            l2=float(l2),\n",
    "                        )\n",
    "                    m = NX47AtomNeuron(n_features=x_train.shape[1])\n",
    "                    tr = m.fit_prox(x_train, y_train, lr=adaptive_lr, max_iter=cfg.max_iter, l1=float(l1), l2=float(l2), progress_cb=progress_cb, progress_prefix={'stage': 'train_supervised', 'pct': 100.0 * candidate_idx / total_candidates, 'index': candidate_idx, 'total': total_candidates, 'epoch': int(epoch), 'neuron_id': int(neuron_id), 'l1': float(l1), 'l2': float(l2)})\n",
    "                    p = m.predict_proba(x_val, grad_x_val)\n",
    "                    ce = -float(np.mean(y_val * np.log(p + 1e-9) + (1.0 - y_val) * np.log(1.0 - p + 1e-9)))\n",
    "                    threshold_info = calibrate_thresholds(y_val, p, cfg.threshold_scan, cfg.fbeta_beta)\n",
    "                    best_th = float(threshold_info['best']['threshold'])\n",
    "                    pred = p >= best_th\n",
    "                    stats = _binary_stats(pred, y_val > 0.5)\n",
    "                    fbeta = _fbeta_from_stats(stats, cfg.fbeta_beta)\n",
    "                    sparsity = float(np.mean((np.abs(m.w) + np.abs(m.alpha) + np.abs(m.beta)) < 1e-8))\n",
    "                    reg_lambda = dynamic_regularization_lambda(pred.astype(np.uint8), x_val.T.reshape(x_train.shape[1], -1, 1))\n",
    "                    objective = ce + 0.02 * (1.0 - sparsity) - 0.20 * stats['f1'] - 0.15 * fbeta - 0.10 * stats['iou'] + 0.005 * reg_lambda\n",
    "                    rec = {\n",
    "                        'epoch': int(epoch),\n",
    "                        'neuron_id': neuron_id,\n",
    "                        'l1': float(l1),\n",
    "                        'l2': float(l2),\n",
    "                        'val_ce': ce,\n",
    "                        'val_f1': stats['f1'],\n",
    "                        'val_iou': stats['iou'],\n",
    "                        'val_dice': stats['dice'],\n",
    "                        'val_fbeta': fbeta,\n",
    "                        'best_threshold': best_th,\n",
    "                        'threshold_scan': threshold_info['scan'],\n",
    "                        'sparsity': sparsity,\n",
    "                        'objective': objective,\n",
    "                        **tr,\n",
    "                    }\n",
    "                    leaderboard.append(rec)\n",
    "                    if best is None or objective < best['objective']:\n",
    "                        best = rec\n",
    "                        best_state = (m.w.copy(), float(m.b), m.alpha.copy(), m.beta.copy())\n",
    "        epoch_best = sorted([r for r in leaderboard if r['epoch'] == epoch], key=lambda d: d['objective'])[0]\n",
    "        epoch_history.append({\n",
    "            'epoch': int(epoch),\n",
    "            'best_objective': float(epoch_best['objective']),\n",
    "            'best_f1': float(epoch_best['val_f1']),\n",
    "            'best_iou': float(epoch_best['val_iou']),\n",
    "            'best_fbeta': float(epoch_best['val_fbeta']),\n",
    "            'best_threshold': float(epoch_best['best_threshold']),\n",
    "        })\n",
    "        if progress_cb is not None:\n",
    "            progress_cb(\n",
    "                stage='train_supervised',\n",
    "                pct=100.0,\n",
    "                substage='epoch_done',\n",
    "                file_name='',\n",
    "                index=int(epoch + 1),\n",
    "                total=max(1, int(cfg.supervised_epochs) if int(cfg.supervised_epochs) > 0 else int(epoch + 1)),\n",
    "                epoch_best=float(epoch_best['objective']),\n",
    "                epoch_f1=float(epoch_best['val_f1']),\n",
    "            )\n",
    "        if best_obj_seen is None or (best_obj_seen - float(epoch_best['objective'])) > float(cfg.convergence_min_delta):\n",
    "            best_obj_seen = float(epoch_best['objective'])\n",
    "            stagnation = 0\n",
    "        else:\n",
    "            stagnation += 1\n",
    "\n",
    "        epoch += 1\n",
    "        if int(cfg.supervised_epochs) > 0 and epoch >= int(cfg.supervised_epochs):\n",
    "            break\n",
    "        if int(cfg.supervised_epochs) <= 0 and stagnation >= int(cfg.convergence_patience):\n",
    "            break\n",
    "        if int(getattr(cfg, 'auto_epoch_safety_cap', 0)) > 0 and epoch >= int(cfg.auto_epoch_safety_cap):\n",
    "            break\n",
    "\n",
    "    mutation_applied = False\n",
    "    pruning_applied = False\n",
    "    if best_state is not None:\n",
    "        if len(memory.f1_history) >= cfg.f1_stagnation_window:\n",
    "            recent = memory.f1_history[-cfg.f1_stagnation_window:]\n",
    "            if float(np.max(recent) - np.min(recent)) < 1e-3:\n",
    "                best_state = (\n",
    "                    best_state[0] + rng.normal(0.0, cfg.mutation_noise, size=best_state[0].shape),\n",
    "                    float(best_state[1]),\n",
    "                    best_state[2] + rng.normal(0.0, cfg.mutation_noise, size=best_state[2].shape),\n",
    "                    best_state[3] + rng.normal(0.0, cfg.mutation_noise, size=best_state[3].shape),\n",
    "                )\n",
    "                mutation_applied = True\n",
    "                memory.mutation_events += 1\n",
    "        q = float(np.quantile(np.abs(best_state[0]), cfg.pruning_quantile))\n",
    "        pruned_w = np.where(np.abs(best_state[0]) < q, 0.0, best_state[0])\n",
    "        pruned_a = np.where(np.abs(best_state[2]) < q, 0.0, best_state[2])\n",
    "        pruned_beta = np.where(np.abs(best_state[3]) < q, 0.0, best_state[3])\n",
    "        if np.any(pruned_w != best_state[0]) or np.any(pruned_a != best_state[2]) or np.any(pruned_beta != best_state[3]):\n",
    "            pruning_applied = True\n",
    "            memory.pruning_events += 1\n",
    "        best_state = (pruned_w, best_state[1], pruned_a, pruned_beta)\n",
    "\n",
    "    model = NX47AtomNeuron(n_features=x_train.shape[1])\n",
    "    if best_state is not None:\n",
    "        model.w, model.b, model.alpha, model.beta = best_state\n",
    "\n",
    "    if best is not None:\n",
    "        memory.update(float(best.get('val_f1', 0.0)), float(best.get('best_threshold', 0.5)))\n",
    "\n",
    "    ablation = {'enabled': bool(getattr(cfg, 'run_ablation_check', True)), 'delta_f1_vs_full': 0.0, 'full_f1': 0.0, 'ablated_f1': 0.0}\n",
    "    if ablation['enabled'] and best is not None and x_val.size > 0:\n",
    "        p_full = model.predict_proba(x_val, grad_x_val)\n",
    "        th = float(best.get('best_threshold', 0.5))\n",
    "        full_stats = _binary_stats(p_full >= th, y_val > 0.5)\n",
    "        x_abl = x_val.copy()\n",
    "        if x_abl.shape[1] > 0:\n",
    "            x_abl[:, 0] = 0.0\n",
    "        p_abl = model.predict_proba(x_abl, grad_x_val)\n",
    "        abl_stats = _binary_stats(p_abl >= th, y_val > 0.5)\n",
    "        ablation = {\n",
    "            'enabled': True,\n",
    "            'delta_f1_vs_full': float(full_stats['f1'] - abl_stats['f1']),\n",
    "            'full_f1': float(full_stats['f1']),\n",
    "            'ablated_f1': float(abl_stats['f1']),\n",
    "            'method': 'zero_feature_0',\n",
    "        }\n",
    "\n",
    "    stability = {'enabled': int(getattr(cfg, 'stability_probe_runs', 0)) > 0, 'runs': 0, 'f1_std': 0.0, 'f1_values': []}\n",
    "\n",
    "    return model, {\n",
    "        'selected_hyperparams': best,\n",
    "        'leaderboard_top5': sorted(leaderboard, key=lambda d: d['objective'])[:5],\n",
    "        'epoch_history': epoch_history,\n",
    "        'train_samples': int(x_train.shape[0]),\n",
    "        'val_samples': int(x_val.shape[0]),\n",
    "        'adaptive_lr': float(adaptive_lr),\n",
    "        'epochs_effective': int(len(epoch_history)),\n",
    "        'mutation_applied': mutation_applied,\n",
    "        'pruning_applied': pruning_applied,\n",
    "        'supervised': True,\n",
    "        'ablation_check': ablation,\n",
    "        'stability_probe': stability,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_nx47_autonomous(features: np.ndarray, cfg: V1442Config, rng: np.random.Generator, memory: NX47EvolutionMemory | None = None) -> Tuple[NX47AtomNeuron, Dict[str, Any]]:\n",
    "    x = features.reshape(features.shape[0], -1).T.astype(np.float64)\n",
    "    keep, y_all = pseudo_labels(np.mean(features, axis=0), cfg.pseudo_pos_pct, cfg.pseudo_neg_pct)\n",
    "    idx = np.where(keep)[0]\n",
    "    if idx.size > cfg.train_max_samples:\n",
    "        idx = rng.choice(idx, size=cfg.train_max_samples, replace=False)\n",
    "    x_train, y_train = x[idx], y_all[idx]\n",
    "    cut = int(x_train.shape[0] * 0.85)\n",
    "    x_tr, y_tr = x_train[:cut], y_train[:cut]\n",
    "    x_va, y_va = x_train[cut:], y_train[cut:]\n",
    "    if x_va.shape[0] < 100:\n",
    "        x_va, y_va = x_tr, y_tr\n",
    "\n",
    "    best, best_state = None, None\n",
    "    leaderboard: List[Dict[str, Any]] = []\n",
    "    adaptive_lr = memory.adapt_learning_rate(cfg.lr, cfg.f1_stagnation_window) if memory else cfg.lr\n",
    "    for neuron_id in range(max(1, cfg.meta_neurons)):\n",
    "        for l1 in cfg.l1_candidates:\n",
    "            for l2 in cfg.l2_candidates:\n",
    "                m = NX47AtomNeuron(n_features=x.shape[1])\n",
    "                tr = m.fit_prox(x_tr, y_tr, lr=adaptive_lr, max_iter=cfg.max_iter, l1=float(l1), l2=float(l2))\n",
    "                grad_x_va = np.gradient(x_va, axis=0)\n",
    "                p = m.predict_proba(x_va, grad_x_va)\n",
    "                ce = -float(np.mean(y_va * np.log(p + 1e-9) + (1.0 - y_va) * np.log(1.0 - p + 1e-9)))\n",
    "                proxy_f1 = compute_proxy_f1(p, y_va)\n",
    "                sparsity = float(np.mean((np.abs(m.w) + np.abs(m.alpha) + np.abs(m.beta)) < 1e-8))\n",
    "                reg_lambda = dynamic_regularization_lambda((p > 0.5).astype(np.uint8), features)\n",
    "                objective = ce + 0.02 * (1.0 - sparsity) - 0.05 * proxy_f1 + 0.005 * reg_lambda\n",
    "                rec = {\"neuron_id\": neuron_id, \"l1\": float(l1), \"l2\": float(l2), \"val_ce\": ce, \"proxy_f1\": proxy_f1, \"sparsity\": sparsity, \"objective\": objective, **tr}\n",
    "                leaderboard.append(rec)\n",
    "                if best is None or objective < best[\"objective\"]:\n",
    "                    best = rec\n",
    "                    best_state = (m.w.copy(), float(m.b), m.alpha.copy(), m.beta.copy())\n",
    "\n",
    "    mutation_applied = False\n",
    "    pruning_applied = False\n",
    "    if best_state is not None and memory is not None:\n",
    "        if len(memory.f1_history) >= cfg.f1_stagnation_window:\n",
    "            recent = memory.f1_history[-cfg.f1_stagnation_window:]\n",
    "            if float(np.max(recent) - np.min(recent)) < 1e-3:\n",
    "                best_state = (\n",
    "                    best_state[0] + rng.normal(0.0, cfg.mutation_noise, size=best_state[0].shape),\n",
    "                    float(best_state[1]),\n",
    "                    best_state[2] + rng.normal(0.0, cfg.mutation_noise, size=best_state[2].shape),\n",
    "                    best_state[3] + rng.normal(0.0, cfg.mutation_noise, size=best_state[3].shape),\n",
    "                )\n",
    "                mutation_applied = True\n",
    "                memory.mutation_events += 1\n",
    "        q = float(np.quantile(np.abs(best_state[0]), cfg.pruning_quantile))\n",
    "        pruned_w = np.where(np.abs(best_state[0]) < q, 0.0, best_state[0])\n",
    "        pruned_a = np.where(np.abs(best_state[2]) < q, 0.0, best_state[2])\n",
    "        pruned_beta = np.where(np.abs(best_state[3]) < q, 0.0, best_state[3])\n",
    "        if np.any(pruned_w != best_state[0]) or np.any(pruned_a != best_state[2]) or np.any(pruned_beta != best_state[3]):\n",
    "            pruning_applied = True\n",
    "            memory.pruning_events += 1\n",
    "        best_state = (pruned_w, best_state[1], pruned_a, pruned_beta)\n",
    "\n",
    "    model = NX47AtomNeuron(n_features=x.shape[1])\n",
    "    if best_state is not None:\n",
    "        model.w, model.b, model.alpha, model.beta = best_state\n",
    "    return model, {\n",
    "        \"selected_hyperparams\": best,\n",
    "        \"leaderboard_top5\": sorted(leaderboard, key=lambda d: d['objective'])[:5],\n",
    "        \"train_samples\": int(x_train.shape[0]),\n",
    "        \"label_keep_ratio\": float(keep.mean()),\n",
    "        \"adaptive_lr\": float(adaptive_lr),\n",
    "        \"mutation_applied\": mutation_applied,\n",
    "        \"pruning_applied\": pruning_applied,\n",
    "    }\n",
    "\n",
    "\n",
    "def hysteresis_topology_3d(prob: np.ndarray, cfg: V1442Config) -> np.ndarray:\n",
    "    strong = prob >= float(cfg.strong_th)\n",
    "    weak = prob >= float(cfg.weak_th)\n",
    "    core = binary_propagation(strong, mask=weak, structure=generate_binary_structure(2, 2)) if strong.any() else np.zeros_like(strong, dtype=bool)\n",
    "\n",
    "    z, r = int(cfg.z_radius), int(cfg.xy_radius)\n",
    "    struct = np.zeros((2 * z + 1, 2 * r + 1, 2 * r + 1), dtype=bool)\n",
    "    for dz in range(-z, z + 1):\n",
    "        for dy in range(-r, r + 1):\n",
    "            for dx in range(-r, r + 1):\n",
    "                if dy * dy + dx * dx <= r * r:\n",
    "                    struct[dz + z, dy + r, dx + r] = True\n",
    "\n",
    "    vol = np.repeat(core[np.newaxis, ...], 3, axis=0)\n",
    "    mask = binary_closing(vol, structure=struct).any(axis=0)\n",
    "    lbl, n = label(mask)\n",
    "    if n > 0 and cfg.dust_min_size > 1:\n",
    "        counts = np.bincount(lbl.ravel())\n",
    "        keep = counts >= int(cfg.dust_min_size)\n",
    "        keep[0] = False\n",
    "        mask = keep[lbl]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def calibrate_target_ratio(prob: np.ndarray, target_ratio: float) -> np.ndarray:\n",
    "    ratio = float(np.clip(target_ratio, 0.001, 0.35))\n",
    "    return prob >= float(np.percentile(prob, 100.0 * (1.0 - ratio)))\n",
    "\n",
    "\n",
    "def probe_hardware_metrics() -> Dict[str, Any]:\n",
    "    mem_total_kb = None\n",
    "    mem_available_kb = None\n",
    "    try:\n",
    "        with open('/proc/meminfo', 'r', encoding='utf-8') as f:\n",
    "            rows = f.read().splitlines()\n",
    "        kv = {r.split(':')[0]: r.split(':')[1].strip() for r in rows if ':' in r}\n",
    "        mem_total_kb = int(kv.get('MemTotal', '0 kB').split()[0])\n",
    "        mem_available_kb = int(kv.get('MemAvailable', '0 kB').split()[0])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    gpu = None\n",
    "    try:\n",
    "        out = subprocess.check_output(['bash', '-lc', 'nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader'], stderr=subprocess.DEVNULL, timeout=2).decode().strip()\n",
    "        gpu = out.splitlines()\n",
    "    except Exception:\n",
    "        gpu = []\n",
    "\n",
    "    return {\n",
    "        'python': sys.version,\n",
    "        'platform': platform.platform(),\n",
    "        'cpu_count': os.cpu_count(),\n",
    "        'mem_total_kb': mem_total_kb,\n",
    "        'mem_available_kb': mem_available_kb,\n",
    "        'gpu': gpu,\n",
    "    }\n",
    "\n",
    "\n",
    "class NX47V1442Kernel:\n",
    "    def __init__(self, root: Path = Path('/kaggle/input/competitions/vesuvius-challenge-surface-detection'), output_dir: Path = Path('/kaggle/working'), config: V1442Config | None = None) -> None:\n",
    "        self.version = 'NX47 V144.2'\n",
    "        self.root = self._resolve_root(root)\n",
    "        self.test_dir = self.root / 'test_images'\n",
    "        self.train_img_dir = self.root / 'train_images'\n",
    "        self.train_lbl_dir = self.root / 'train_labels'\n",
    "        self.output_dir = output_dir\n",
    "        self.tmp_dir = output_dir / 'tmp_masks_v134'\n",
    "        self.overlay_dir = output_dir / 'overlays_v134'\n",
    "        self.submission_path = output_dir / 'submission.zip'\n",
    "        self.roadmap_path = output_dir / 'v1442_roadmap_realtime.json'\n",
    "        self.logs_path = output_dir / 'v1442_execution_logs.json'\n",
    "        self.memory_path = output_dir / 'v1442_memory_tracker.json'\n",
    "        self.metadata_path = output_dir / 'v1442_execution_metadata.json'\n",
    "        self.ultra_log_path = output_dir / 'v1442_ultra_authentic_360_merkle.jsonl'\n",
    "        self.forensic_report_path = output_dir / 'v1442_forensic_analysis_report.json'\n",
    "\n",
    "        self.cfg = config or V1442Config()\n",
    "        self.evolution = NX47EvolutionMemory()\n",
    "        self.plan = PlanTracker(self.roadmap_path)\n",
    "        self.memory = MemoryTracker()\n",
    "        self.logs: List[Dict[str, Any]] = []\n",
    "        self.ultra = UltraAuthentic360Merkle(self.ultra_log_path, console=self.cfg.ultra_console_log)\n",
    "        self.supervised_model: NX47AtomNeuron | None = None\n",
    "        self.supervised_train_info: Dict[str, Any] | None = None\n",
    "        self.learning_audit: Dict[str, Any] = {}\n",
    "        self.train_dataset_audit: Dict[str, Any] = {}\n",
    "        self._last_progress_ns: int | None = None\n",
    "        self._last_progress_stage: str = ''\n",
    "\n",
    "        self.continuity_matrix = self._build_continuity_matrix()\n",
    "\n",
    "        self.global_stats: Dict[str, Any] = {\n",
    "            'files_processed': 0,\n",
    "            'slices_processed': 0,\n",
    "            'pixels_processed': 0,\n",
    "            'pixels_anchor_detected': 0,\n",
    "            'pixels_papyrus_without_anchor': 0,\n",
    "            'materials_detected': 0,\n",
    "            'patterns_detected': 0,\n",
    "            'golden_nonce_detected': 0,\n",
    "            'unknown_discoveries': 0,\n",
    "            'anomalies_detected': 0,\n",
    "            'calc_ops_estimated': 0,\n",
    "            'active_neurons_start_total': 0,\n",
    "            'active_neurons_mid_total': 0,\n",
    "            'active_neurons_end_total': 0,\n",
    "            'meta_neuron_candidates': 0,\n",
    "            'mutation_events': 0,\n",
    "            'pruning_events': 0,\n",
    "            'f1_ratio_curve_best_ratio': 0.0,\n",
    "            'f1_ratio_curve_best_f1': 0.0,\n",
    "            'files_supervised_mode': 0,\n",
    "            'files_autonomous_fallback': 0,\n",
    "            'val_f1_mean_supervised': 0.0,\n",
    "            'val_iou_mean_supervised': 0.0,\n",
    "            'best_threshold_mean_supervised': 0.0,\n",
    "            'unet_25d_status': 'n/a',\n",
    "            'unet_25d_best_fbeta': 0.0,\n",
    "            'forensic_report_generated': False,\n",
    "            'probability_max_observed': 0.0,\n",
    "            'probability_mean_observed': 0.0,\n",
    "            'probability_std_observed': 0.0,\n",
    "            'learning_percent_real': 0.0,\n",
    "            'reasoning_trace_events': 0,\n",
    "            'train_pair_count_discovered': 0,\n",
    "            'train_pair_coverage_pct': 0.0,\n",
    "        }\n",
    "\n",
    "        bootstrap_dependencies_fail_fast()\n",
    "        if not ensure_imagecodecs():\n",
    "            self.log('WARN_IMAGECODECS_MISSING', message='imagecodecs unavailable; relying on Pillow/tifffile fallbacks')\n",
    "\n",
    "        self.tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.overlay_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for n, d in [\n",
    "            ('discovery', 'Validation dataset et assets'),\n",
    "            ('load', 'Chargement volume'),\n",
    "            ('features', 'Extraction + sélection features'),\n",
    "            ('train', 'Apprentissage neurone NX-47 L1/L2'),\n",
    "            ('segment', 'Probabilité + hysteresis + calibration'),\n",
    "            ('package', 'Génération submission zip'),\n",
    "        ]:\n",
    "            self.plan.add_step(n, d)\n",
    "        self.plan._write()\n",
    "\n",
    "        if self.cfg.enforce_nx_legacy_continuity:\n",
    "            self._assert_continuity_integrity()\n",
    "\n",
    "        self.log('BOOT', version=self.version, root=str(self.root), config=asdict(self.cfg), hardware=probe_hardware_metrics())\n",
    "\n",
    "    def _build_continuity_matrix(self) -> Dict[str, List[str]]:\n",
    "        return {\n",
    "            'NX-1..NX-10': ['preprocess', 'input_format_invariants'],\n",
    "            'NX-11..NX-20': ['feature_signature', 'intermediate_schema'],\n",
    "            'NX-21..NX-35': ['audit_hash_chain', 'integrity_checks'],\n",
    "            'NX-36..NX-47': ['forensic_traceability', 'merkle_chain', 'roadmap_realtime'],\n",
    "            'NX-47 v115..v139': ['supervised_pipeline', 'unet_25d', 'strict_logging'],\n",
    "        }\n",
    "\n",
    "    def _assert_continuity_integrity(self) -> None:\n",
    "        required_caps = {\n",
    "            'preprocess': extract_multi_features,\n",
    "            'input_format_invariants': read_tiff_lzw_safe,\n",
    "            'feature_signature': auto_select_features,\n",
    "            'intermediate_schema': self._predict_mask,\n",
    "            'audit_hash_chain': self.log,\n",
    "            'integrity_checks': audit_logits_distribution,\n",
    "            'forensic_traceability': self._build_v1442_forensic_report,\n",
    "            'merkle_chain': self.ultra.emit,\n",
    "            'roadmap_realtime': self.plan.update,\n",
    "            'supervised_pipeline': train_nx47_supervised,\n",
    "            'unet_25d': train_unet_25d_supervised,\n",
    "            'strict_logging': self.logs.append,\n",
    "        }\n",
    "        missing = [name for name, ref in required_caps.items() if ref is None]\n",
    "        if missing:\n",
    "            raise RuntimeError(f'NX_CONTINUITY_BROKEN: missing capabilities {missing}')\n",
    "        self.log('NX_CONTINUITY_OK', matrix=self.continuity_matrix)\n",
    "\n",
    "    def _resolve_root(self, preferred: Path) -> Path:\n",
    "        cands = [preferred, Path('/kaggle/input/competitions/vesuvius-challenge-surface-detection'), Path('/kaggle/input/vesuvius-challenge-surface-detection')]\n",
    "        for c in cands:\n",
    "            if c.exists():\n",
    "                return c\n",
    "        raise FileNotFoundError(f'Dataset path missing. Tried: {[str(c) for c in cands]}')\n",
    "\n",
    "    def log(self, event: str, **kwargs: Any) -> None:\n",
    "        payload = {'ts_ns': time.time_ns(), 'event': event, **kwargs}\n",
    "        payload['signature'] = sha512(json.dumps(payload, sort_keys=True, default=str).encode()).hexdigest()\n",
    "        self.logs.append(payload)\n",
    "        self.ultra.emit(payload)\n",
    "\n",
    "    def _build_progress_bar(self, pct: float) -> str:\n",
    "        width = max(8, int(getattr(self.cfg, 'progress_bar_width', 24)))\n",
    "        clamped = float(np.clip(pct, 0.0, 100.0))\n",
    "        filled = int(round(width * clamped / 100.0))\n",
    "        return '[' + ('#' * filled) + ('-' * (width - filled)) + ']'\n",
    "\n",
    "    def _log_progress(self, stage: str, pct: float, *, substage: str = '', file_name: str = '', index: int = 0, total: int = 0, **extra: Any) -> None:\n",
    "        now_ns = time.time_ns()\n",
    "        elapsed_s_since_last = None\n",
    "        if self._last_progress_ns is not None:\n",
    "            elapsed_s_since_last = (now_ns - self._last_progress_ns) / 1e9\n",
    "        self._last_progress_ns = now_ns\n",
    "        self._last_progress_stage = stage\n",
    "\n",
    "        self.log(\n",
    "            'PROGRESS_UPDATE',\n",
    "            stage=stage,\n",
    "            substage=substage or None,\n",
    "            file=file_name or None,\n",
    "            index=int(index),\n",
    "            total=int(total),\n",
    "            progress_percent=float(np.clip(pct, 0.0, 100.0)),\n",
    "            progress_bar=self._build_progress_bar(pct),\n",
    "            global_progress_percent=float(self.plan.overall_progress()),\n",
    "            global_progress_bar=self._build_progress_bar(self.plan.overall_progress()),\n",
    "            elapsed_s_since_last=elapsed_s_since_last,\n",
    "            eta_s=(None if total <= 0 or index <= 0 else float(max(0.0, (total - index) * ((elapsed_s_since_last or 0.0) / max(1, index))))),\n",
    "            **extra,\n",
    "        )\n",
    "        stall_limit_s = float(getattr(self.cfg, 'stage_stall_alert_s', 180.0))\n",
    "        if elapsed_s_since_last is not None and elapsed_s_since_last >= stall_limit_s:\n",
    "            self.log('STALL_ALERT', stage=stage, substage=substage or None, elapsed_s=elapsed_s_since_last, stall_limit_s=stall_limit_s)\n",
    "\n",
    "    def _log_heartbeat(self, stage: str, *, file_name: str = '', note: str = '', index: int = 0, total: int = 0) -> None:\n",
    "        self.log(\n",
    "            'HEARTBEAT',\n",
    "            stage=stage,\n",
    "            file=file_name or None,\n",
    "            index=int(index),\n",
    "            total=int(total),\n",
    "            note=note,\n",
    "            global_progress_percent=float(self.plan.overall_progress()),\n",
    "            global_progress_bar=self._build_progress_bar(self.plan.overall_progress()),\n",
    "        )\n",
    "\n",
    "    def _run_preflight_5pct(self, files: List[Path]) -> None:\n",
    "        train_pairs = self.discover_train_pairs()\n",
    "        train_n = max(1, int(np.ceil(len(train_pairs) * float(self.cfg.preflight_train_pct) / 100.0))) if train_pairs else 0\n",
    "        test_n = max(1, int(np.ceil(len(files) * float(self.cfg.preflight_test_pct) / 100.0))) if files else 0\n",
    "        self.log('PREFLIGHT_START', train_pairs_total=len(train_pairs), train_pairs_preflight=train_n, test_files_total=len(files), test_files_preflight=test_n, preflight_train_pct=float(self.cfg.preflight_train_pct), preflight_test_pct=float(self.cfg.preflight_test_pct))\n",
    "\n",
    "        for i, (img_path, lbl_path) in enumerate(train_pairs[:train_n], start=1):\n",
    "            self._log_progress('preflight_train', 100.0 * i / max(1, train_n), substage='load_pair', file_name=img_path.name, index=i, total=train_n)\n",
    "            _ = self._load_volume(img_path)\n",
    "            _ = self._load_label_2d(lbl_path)\n",
    "\n",
    "        for j, fpath in enumerate(files[:test_n], start=1):\n",
    "            self._log_progress('preflight_test', 100.0 * j / max(1, test_n), substage='load_test_volume', file_name=fpath.name, index=j, total=test_n)\n",
    "            _ = self._load_volume(fpath)\n",
    "\n",
    "        self.log('PREFLIGHT_OK', train_pairs_checked=train_n, test_files_checked=test_n)\n",
    "\n",
    "    def _log_array_ultra(self, stage: str, arr: np.ndarray) -> None:\n",
    "        self.memory.log_array(stage, arr)\n",
    "        if self.cfg.ultra_bit_trace_arrays:\n",
    "            self.log('ARRAY_TRACE', stage=stage, shape=list(np.asarray(arr).shape), dtype=str(np.asarray(arr).dtype), bits=self.ultra.bit_stats(arr, self.cfg.ultra_bit_trace_limit))\n",
    "\n",
    "    def discover_inputs(self) -> List[Path]:\n",
    "        self.plan.update('discovery', 25.0)\n",
    "        self._log_progress('discovery', 25.0, substage='start')\n",
    "        if not self.test_dir.exists():\n",
    "            raise FileNotFoundError(f'Missing test_images directory: {self.test_dir}')\n",
    "        files = sorted(self.test_dir.rglob('*.tif'))\n",
    "        if not files:\n",
    "            raise RuntimeError(f'No TIFF files found in {self.test_dir}')\n",
    "\n",
    "        all_files = [p for p in self.root.rglob('*') if p.is_file()]\n",
    "        suffix_stats: Dict[str, int] = {}\n",
    "        folders = set()\n",
    "        for p in all_files:\n",
    "            suffix_stats[p.suffix.lower() or '<noext>'] = suffix_stats.get(p.suffix.lower() or '<noext>', 0) + 1\n",
    "            folders.add(str(p.parent.relative_to(self.root)))\n",
    "\n",
    "        self.log('DATASET_DISCOVERY', file_count=len(files), total_assets=len(all_files), folders=sorted(folders), suffix_stats=suffix_stats)\n",
    "        self._log_progress('discovery', 90.0, substage='inventory_completed', total=len(files))\n",
    "        self.plan.update('discovery', 100.0, done=True)\n",
    "        self._log_progress('discovery', 100.0, substage='done', total=len(files))\n",
    "        return files\n",
    "\n",
    "    def discover_train_pairs(self) -> List[Tuple[Path, Path]]:\n",
    "        if not self.train_img_dir.exists() or not self.train_lbl_dir.exists():\n",
    "            self.log('TRAIN_DISCOVERY', status='missing_train_dirs', train_images=str(self.train_img_dir), train_labels=str(self.train_lbl_dir))\n",
    "            return []\n",
    "        pairs: List[Tuple[Path, Path]] = []\n",
    "        for img in sorted(self.train_img_dir.rglob('*.tif')):\n",
    "            cand = self.train_lbl_dir / img.name\n",
    "            if cand.exists():\n",
    "                pairs.append((img, cand))\n",
    "        self.log('TRAIN_DISCOVERY', pair_count=len(pairs), max_train_volumes=self.cfg.max_train_volumes, max_val_volumes=self.cfg.max_val_volumes)\n",
    "        return pairs\n",
    "\n",
    "    def _parse_v130_log_summary(self, log_path: Path) -> Dict[str, Any]:\n",
    "        if not log_path.exists():\n",
    "            return {'status': 'missing', 'path': str(log_path)}\n",
    "        text = log_path.read_text(encoding='utf-8', errors='ignore')\n",
    "        lines = [ln for ln in text.splitlines() if ln.strip()]\n",
    "        global_stats = {}\n",
    "        for line in lines[::-1]:\n",
    "            if '\"event\": \"GLOBAL_STATS\"' in line:\n",
    "                start = line.find('{')\n",
    "                if start >= 0:\n",
    "                    try:\n",
    "                        global_stats = json.loads(line[start:])\n",
    "                    except Exception:\n",
    "                        global_stats = {}\n",
    "                break\n",
    "        return {\n",
    "            'status': 'ok',\n",
    "            'path': str(log_path),\n",
    "            'line_count': len(lines),\n",
    "            'has_exec_complete': any('\"event\": \"EXEC_COMPLETE\"' in ln for ln in lines),\n",
    "            'global_stats': global_stats,\n",
    "        }\n",
    "\n",
    "    def _build_v1442_forensic_report(self) -> Dict[str, Any]:\n",
    "        v130 = self._parse_v130_log_summary(Path(self.cfg.v130_log_path))\n",
    "        gs = v130.get('global_stats', {}) if isinstance(v130, dict) else {}\n",
    "        positives = int(gs.get('pixels_papyrus_without_anchor', 0)) + int(gs.get('pixels_anchor_detected', 0))\n",
    "        return {\n",
    "            'version': self.version,\n",
    "            'objective': 'Réintégration complète V130 + analyse forensic + plan V132 de A à Z',\n",
    "            'v130_log_forensic': {\n",
    "                'summary': v130,\n",
    "                'computed_total_positives': positives,\n",
    "                'supervised_mode_files': int(gs.get('files_supervised_mode', 0)),\n",
    "                'best_threshold_mean_supervised': float(gs.get('best_threshold_mean_supervised', 0.0)),\n",
    "                'golden_nonce_detected': int(gs.get('golden_nonce_detected', 0)),\n",
    "            },\n",
    "            'pipeline_checklist': [\n",
    "                'Split explicite train/val + multi-epoch supervisé',\n",
    "                'Calibration threshold par F-beta (scan complet)',\n",
    "                'SWI + TTA multi-axes/rotation + fusion sigmoid stable',\n",
    "                'Post-process seeded hysteresis 3D + closing anisotropique + dust removal',\n",
    "                'Golden nonces top-K extraits et intégrés au masque final',\n",
    "                'Audit scientifique complet (logs, métriques, metadata, merkle trace)',\n",
    "            ],\n",
    "            'concurrent_comparison': {\n",
    "                'public_pipeline': 'single-path drop-in, seuils fixes, propagation binaire',\n",
    "                'v132_advantages': [\n",
    "                    'apprentissage supervisé réel et audité',\n",
    "                    'calibration de seuil optimisée F-beta',\n",
    "                    'intégration golden nonces top-K',\n",
    "                    'TTA multi-axes/rotation et couverture spatiale renforcée',\n",
    "                    'traçabilité forensic complète',\n",
    "                ],\n",
    "            },\n",
    "            'remaining_steps_executed_simultaneously': [\n",
    "                'Consolider rapport forensic dans les artefacts V132',\n",
    "                \"Préparer base CV 5-fold (pilotage par variables d'environnement)\",\n",
    "                'Préparer extension ensemble multi-backbone (slot unet_25d déjà maintenu)',\n",
    "                'Conserver compatibilité Kaggle submission.zip',\n",
    "            ],\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_label_2d(path: Path) -> np.ndarray:\n",
    "        arr = read_tiff_lzw_safe(path)\n",
    "        if arr.ndim == 3:\n",
    "            arr2d = arr[0]\n",
    "        elif arr.ndim == 2:\n",
    "            arr2d = arr\n",
    "        else:\n",
    "            raise RuntimeError(f'Unsupported label shape {arr.shape} for {path.name}')\n",
    "        arr2d = np.asarray(arr2d, dtype=np.float32)\n",
    "        if arr2d.max() > 1.0:\n",
    "            arr2d = arr2d / 255.0\n",
    "        return (arr2d > 0.5).astype(np.float32)\n",
    "\n",
    "    def _derive_train_pair_requirement(self, pair_count: int) -> int:\n",
    "        if pair_count <= 0:\n",
    "            return int(self.cfg.min_train_pairs_required)\n",
    "        if self.cfg.adapt_train_threshold_to_dataset_size:\n",
    "            req = int(np.ceil(pair_count * float(self.cfg.train_pair_coverage_target_pct) / 100.0))\n",
    "            return max(1, req)\n",
    "        return int(self.cfg.min_train_pairs_required)\n",
    "\n",
    "    def _audit_train_dataset_size(self, pairs: List[Tuple[Path, Path]]) -> None:\n",
    "        pair_count = len(pairs)\n",
    "        if self.cfg.max_train_volumes <= 0 and self.cfg.max_val_volumes <= 0:\n",
    "            selected = int(pair_count)\n",
    "        else:\n",
    "            max_total = max(1, self.cfg.max_train_volumes + self.cfg.max_val_volumes)\n",
    "            selected = min(pair_count, max_total)\n",
    "        coverage = float(100.0 * selected / max(1, pair_count))\n",
    "        image_exists_count = int(sum(1 for img, _ in pairs if img.exists()))\n",
    "        label_exists_count = int(sum(1 for _, lbl in pairs if lbl.exists()))\n",
    "        total_label_bytes = int(sum(lbl.stat().st_size for _, lbl in pairs if lbl.exists()))\n",
    "        total_image_bytes = int(sum(img.stat().st_size for img, _ in pairs if img.exists()))\n",
    "        self.train_dataset_audit = {\n",
    "            'pair_count_discovered': int(pair_count),\n",
    "            'pair_count_selected_for_training': int(selected),\n",
    "            'coverage_pct_selected_vs_discovered': float(coverage),\n",
    "            'train_image_files_found': int(image_exists_count),\n",
    "            'train_label_files_found': int(label_exists_count),\n",
    "            'total_train_image_bytes': int(total_image_bytes),\n",
    "            'total_train_label_bytes': int(total_label_bytes),\n",
    "            'required_pair_count': int(self._derive_train_pair_requirement(pair_count)),\n",
    "        }\n",
    "        self.log('TRAIN_DATASET_AUDIT', **self.train_dataset_audit)\n",
    "\n",
    "    def _assert_train_pairs_threshold(self, pair_count: int) -> None:\n",
    "        required_pairs = self._derive_train_pair_requirement(pair_count)\n",
    "        if self.cfg.supervised_train and pair_count < int(required_pairs):\n",
    "            raise RuntimeError(\n",
    "                f'TRAIN_PAIRS_BELOW_THRESHOLD: found={pair_count} required={required_pairs}'\n",
    "            )\n",
    "        img_found = int(self.train_dataset_audit.get('train_image_files_found', 0))\n",
    "        lbl_found = int(self.train_dataset_audit.get('train_label_files_found', 0))\n",
    "        if self.cfg.supervised_train and img_found < int(self.cfg.min_train_image_files_required):\n",
    "            raise RuntimeError(\n",
    "                f'TRAIN_IMAGE_FILES_BELOW_THRESHOLD: found={img_found} required={self.cfg.min_train_image_files_required}'\n",
    "            )\n",
    "        if self.cfg.supervised_train and lbl_found < int(self.cfg.min_train_label_files_required):\n",
    "            raise RuntimeError(\n",
    "                f'TRAIN_LABEL_FILES_BELOW_THRESHOLD: found={lbl_found} required={self.cfg.min_train_label_files_required}'\n",
    "            )\n",
    "\n",
    "    def _assert_train_completed_100(self) -> None:\n",
    "        if not self.cfg.require_train_completion_100:\n",
    "            return\n",
    "        if self.supervised_train_info is None:\n",
    "            raise RuntimeError('TRAIN_COMPLETION_100_FAILED: missing supervised_train_info')\n",
    "        hist = self.supervised_train_info.get('epoch_history', [])\n",
    "        epochs_done = len(hist)\n",
    "        if epochs_done < int(self.cfg.supervised_epochs):\n",
    "            raise RuntimeError(\n",
    "                f'TRAIN_COMPLETION_100_FAILED: epochs_done={epochs_done} expected={self.cfg.supervised_epochs}'\n",
    "            )\n",
    "\n",
    "    def _compute_learning_percent_real(self, train_info: Dict[str, Any]) -> float:\n",
    "        hist = train_info.get('epoch_history', []) if isinstance(train_info, dict) else []\n",
    "        epochs_done = len(hist)\n",
    "        epoch_ratio = float(epochs_done / max(1, int(self.cfg.supervised_epochs)))\n",
    "        shp = train_info.get('selected_hyperparams', {}) if isinstance(train_info, dict) else {}\n",
    "        val_f1 = float(shp.get('val_f1', 0.0))\n",
    "        val_iou = float(shp.get('val_iou', 0.0))\n",
    "        metric_signal = float(np.clip((val_f1 + val_iou) / 2.0, 0.0, 1.0))\n",
    "        # 80% driven by completed epochs, 20% by observed validation signal\n",
    "        pct = float(np.clip(100.0 * (0.8 * epoch_ratio + 0.2 * metric_signal), 0.0, 100.0))\n",
    "        return pct\n",
    "\n",
    "    def _assert_no_hardcoded_metric_pattern(self, train_info: Dict[str, Any]) -> None:\n",
    "        if not self.cfg.enforce_no_hardcoded_metrics:\n",
    "            return\n",
    "        hist = train_info.get('epoch_history', []) if isinstance(train_info, dict) else []\n",
    "        if len(hist) < 2:\n",
    "            return\n",
    "        objectives = [float(h.get('best_objective', 0.0)) for h in hist]\n",
    "        # If every epoch has exactly the same objective, flag forensic anomaly.\n",
    "        if len(set(objectives)) == 1:\n",
    "            policy = str(getattr(self.cfg, 'hardcoded_metric_policy', 'warn')).lower()\n",
    "            self.log('HARD_METRIC_PATTERN', policy=policy, objectives=objectives)\n",
    "            if policy == 'error':\n",
    "                raise RuntimeError('HARD_METRIC_PATTERN_DETECTED: identical epoch objective across all epochs')\n",
    "\n",
    "    def build_supervised_model(self) -> None:\n",
    "        if not self.cfg.supervised_train:\n",
    "            self.log('SUPERVISED_TRAIN', status='disabled')\n",
    "            return\n",
    "        pairs = self.discover_train_pairs()\n",
    "        self._audit_train_dataset_size(pairs)\n",
    "        self._assert_train_pairs_threshold(len(pairs))\n",
    "        if not pairs:\n",
    "            self.log('SUPERVISED_TRAIN', status='fallback_autonomous_no_pairs')\n",
    "            if self.cfg.strict_no_fallback:\n",
    "                raise RuntimeError('STRICT_NO_FALLBACK: supervised_train enabled but no train pairs found')\n",
    "            return\n",
    "\n",
    "        rng = np.random.default_rng(125)\n",
    "        if self.cfg.max_train_volumes <= 0 and self.cfg.max_val_volumes <= 0:\n",
    "            chosen = pairs\n",
    "            split = max(1, int(0.8 * len(chosen)))\n",
    "            train_pairs = chosen[:split]\n",
    "            val_pairs = chosen[split:]\n",
    "        else:\n",
    "            max_total = max(2, self.cfg.max_train_volumes + self.cfg.max_val_volumes)\n",
    "            chosen = pairs[:max_total]\n",
    "            split = min(len(chosen) - 1, self.cfg.max_train_volumes)\n",
    "            train_pairs = chosen[:split]\n",
    "            val_pairs = chosen[split:]\n",
    "        if not val_pairs:\n",
    "            val_pairs = chosen[-1:]\n",
    "            train_pairs = chosen[:-1]\n",
    "\n",
    "        x_train_chunks: List[np.ndarray] = []\n",
    "        y_train_chunks: List[np.ndarray] = []\n",
    "        x_val_chunks: List[np.ndarray] = []\n",
    "        y_val_chunks: List[np.ndarray] = []\n",
    "\n",
    "        for k, (img_path, lbl_path) in enumerate(train_pairs, start=1):\n",
    "            self._log_progress('train_data', 100.0 * k / max(1, len(train_pairs)), substage='load_train_pair', file_name=img_path.name, index=k, total=len(train_pairs))\n",
    "            vol = self._load_volume(img_path)\n",
    "            feats, names = extract_multi_features(vol)\n",
    "            selected, _, _ = auto_select_features(feats, names, self.cfg.top_k_features)\n",
    "            x = selected.reshape(selected.shape[0], -1).T.astype(np.float64)\n",
    "            y = self._load_label_2d(lbl_path).reshape(-1).astype(np.float64)\n",
    "            n = min(x.shape[0], y.shape[0])\n",
    "            x, y = x[:n], y[:n]\n",
    "            idx = _balance_sample_indices(y, self.cfg.max_samples_per_volume, self.cfg.pos_neg_ratio, rng)\n",
    "            x_train_chunks.append(x[idx])\n",
    "            y_train_chunks.append(y[idx])\n",
    "\n",
    "        for k, (img_path, lbl_path) in enumerate(val_pairs, start=1):\n",
    "            self._log_progress('val_data', 100.0 * k / max(1, len(val_pairs)), substage='load_val_pair', file_name=img_path.name, index=k, total=len(val_pairs))\n",
    "            vol = self._load_volume(img_path)\n",
    "            feats, names = extract_multi_features(vol)\n",
    "            selected, _, _ = auto_select_features(feats, names, self.cfg.top_k_features)\n",
    "            x = selected.reshape(selected.shape[0], -1).T.astype(np.float64)\n",
    "            y = self._load_label_2d(lbl_path).reshape(-1).astype(np.float64)\n",
    "            n = min(x.shape[0], y.shape[0])\n",
    "            x, y = x[:n], y[:n]\n",
    "            idx = _balance_sample_indices(y, self.cfg.max_samples_per_volume, self.cfg.pos_neg_ratio, rng)\n",
    "            x_val_chunks.append(x[idx])\n",
    "            y_val_chunks.append(y[idx])\n",
    "\n",
    "        if not x_train_chunks or not x_val_chunks:\n",
    "            self.log('SUPERVISED_TRAIN', status='fallback_autonomous_empty_chunks')\n",
    "            if self.cfg.strict_no_fallback:\n",
    "                raise RuntimeError('STRICT_NO_FALLBACK: supervised_train enabled but sampled chunks are empty')\n",
    "            return\n",
    "\n",
    "        x_train = np.concatenate(x_train_chunks, axis=0)\n",
    "        y_train = np.concatenate(y_train_chunks, axis=0)\n",
    "        x_val = np.concatenate(x_val_chunks, axis=0)\n",
    "        y_val = np.concatenate(y_val_chunks, axis=0)\n",
    "\n",
    "        model, info = train_nx47_supervised(x_train, y_train, x_val, y_val, self.cfg, rng, self.evolution, progress_cb=self._log_progress)\n",
    "        self.supervised_model = model\n",
    "\n",
    "        # Optional competitive 2.5D U-Net branch for logit/threshold audit and potential scoring uplift\n",
    "        unet_info = {'status': 'disabled'}\n",
    "        if self.cfg.use_unet_25d:\n",
    "            try:\n",
    "                train_patch_x, train_patch_y = [], []\n",
    "                val_patch_x, val_patch_y = [], []\n",
    "                for u, (img_path, lbl_path) in enumerate(train_pairs[: min(4, len(train_pairs))], start=1):\n",
    "                    self._log_progress('unet_patches', 100.0 * u / max(1, min(4, len(train_pairs))), substage='extract_train_patch', file_name=img_path.name, index=u, total=max(1, min(4, len(train_pairs))))\n",
    "                    vol = self._load_volume(img_path)\n",
    "                    lbl = self._load_label_2d(lbl_path)\n",
    "                    px, py = _extract_2p5d_patches(vol, lbl, self.cfg, rng)\n",
    "                    if px.shape[0] > 0:\n",
    "                        train_patch_x.append(px)\n",
    "                        train_patch_y.append(py)\n",
    "                for u, (img_path, lbl_path) in enumerate(val_pairs[: min(2, len(val_pairs))], start=1):\n",
    "                    self._log_progress('unet_patches_val', 100.0 * u / max(1, min(2, len(val_pairs))), substage='extract_val_patch', file_name=img_path.name, index=u, total=max(1, min(2, len(val_pairs))))\n",
    "                    vol = self._load_volume(img_path)\n",
    "                    lbl = self._load_label_2d(lbl_path)\n",
    "                    px, py = _extract_2p5d_patches(vol, lbl, self.cfg, rng)\n",
    "                    if px.shape[0] > 0:\n",
    "                        val_patch_x.append(px)\n",
    "                        val_patch_y.append(py)\n",
    "                if train_patch_x and val_patch_x:\n",
    "                    tx = np.concatenate(train_patch_x, axis=0)\n",
    "                    ty = np.concatenate(train_patch_y, axis=0)\n",
    "                    vx = np.concatenate(val_patch_x, axis=0)\n",
    "                    vy = np.concatenate(val_patch_y, axis=0)\n",
    "                    unet_info = train_unet_25d_supervised(tx, ty, vx, vy, self.cfg, rng)\n",
    "                    unet_info['train_patches'] = int(tx.shape[0])\n",
    "                    unet_info['val_patches'] = int(vx.shape[0])\n",
    "                else:\n",
    "                    unet_info = {'status': 'no_patches_extracted'}\n",
    "            except Exception as exc:\n",
    "                unet_info = {'status': 'error', 'message': str(exc)}\n",
    "\n",
    "        self.supervised_train_info = {**info, 'unet_25d': unet_info}\n",
    "        self.learning_audit = {\n",
    "            'learning_percent_real': self._compute_learning_percent_real(self.supervised_train_info),\n",
    "            'epochs_configured': int(self.cfg.supervised_epochs),\n",
    "            'epochs_observed': len(self.supervised_train_info.get('epoch_history', [])),\n",
    "            'epochs_effective': int(self.supervised_train_info.get('epochs_effective', len(self.supervised_train_info.get('epoch_history', [])))),\n",
    "            'nx_neuron_formal': {\n",
    "                'activation': 'sigmoid(w·x + b + alpha·grad + beta·laplace)',\n",
    "                'training': 'proximal gradient with l1/l2 + threshold calibration',\n",
    "                'state': 'w,b,alpha,beta + evolution memory events',\n",
    "            },\n",
    "        }\n",
    "        self._assert_no_hardcoded_metric_pattern(self.supervised_train_info)\n",
    "        self._assert_train_completed_100()\n",
    "        self.log(\n",
    "            'SUPERVISED_TRAIN',\n",
    "            status='ok',\n",
    "            train_samples=int(x_train.shape[0]),\n",
    "            val_samples=int(x_val.shape[0]),\n",
    "            train_volumes=len(train_pairs),\n",
    "            val_volumes=len(val_pairs),\n",
    "            train_volume_files=[p.name for p, _ in train_pairs],\n",
    "            val_volume_files=[p.name for p, _ in val_pairs],\n",
    "            train_info=self.supervised_train_info,\n",
    "            learning_audit=self.learning_audit,\n",
    "        )\n",
    "\n",
    "    def _load_volume(self, path: Path) -> np.ndarray:\n",
    "        self.plan.update('load', 25.0)\n",
    "        self._log_progress('load', 25.0, substage='start_load', file_name=path.name)\n",
    "        if self.cfg.ultra_step_log:\n",
    "            self.log('STEP', name='load_start', file=str(path))\n",
    "        vol = read_tiff_lzw_safe(path).astype(np.float32)\n",
    "        if vol.ndim != 3:\n",
    "            raise RuntimeError(f'Unsupported TIFF shape for {path.name}: {vol.shape}')\n",
    "        if vol.shape[0] > self.cfg.max_layers:\n",
    "            vol = vol[: self.cfg.max_layers]\n",
    "        vol = (vol - float(vol.min())) / (float(vol.max()) - float(vol.min()) + 1e-6)\n",
    "        self._log_array_ultra('volume', vol)\n",
    "        self.plan.update('load', 100.0, done=True)\n",
    "        self._log_progress('load', 100.0, substage='done_load', file_name=path.name)\n",
    "        return vol\n",
    "\n",
    "    def _predict_mask(self, vol: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:\n",
    "        self.plan.update('features', 10.0)\n",
    "        self._log_progress('features', 10.0, substage='start_extract')\n",
    "        if self.cfg.ultra_step_log:\n",
    "            self.log('STEP', name='features_extract_start')\n",
    "        features, names = extract_multi_features(vol)\n",
    "        selected, selected_names, variances = auto_select_features(features, names, self.cfg.top_k_features)\n",
    "        self._log_array_ultra('features_selected', selected)\n",
    "        self.plan.update('features', 100.0, done=True)\n",
    "        self._log_progress('features', 100.0, substage='features_ready')\n",
    "\n",
    "        self.plan.update('train', 15.0)\n",
    "        self._log_progress('train', 15.0, substage='predict_train_path')\n",
    "        if self.cfg.ultra_step_log:\n",
    "            self.log('STEP', name='train_start')\n",
    "        if self.supervised_model is not None and self.supervised_train_info is not None:\n",
    "            model = self.supervised_model\n",
    "            train_info = self.supervised_train_info\n",
    "            train_mode = 'supervised'\n",
    "        else:\n",
    "            if self.cfg.forbid_autonomous_mode:\n",
    "                raise RuntimeError('AUTONOMOUS_MODE_FORBIDDEN: supervised NX pipeline is mandatory in v134')\n",
    "            if self.cfg.supervised_train and self.cfg.strict_no_fallback:\n",
    "                raise RuntimeError('STRICT_NO_FALLBACK: autonomous fallback blocked while supervised_train is enabled')\n",
    "            rng = np.random.default_rng(47)\n",
    "            model, train_info = train_nx47_autonomous(selected, self.cfg, rng, self.evolution)\n",
    "            train_mode = 'autonomous_fallback'\n",
    "        self.plan.update('train', 100.0, done=True)\n",
    "        self._log_progress('train', 100.0, substage='train_done')\n",
    "\n",
    "        self.plan.update('segment', 20.0)\n",
    "        self._log_progress('segment', 20.0, substage='segment_start')\n",
    "        if self.cfg.ultra_step_log:\n",
    "            self.log('STEP', name='segment_start')\n",
    "        x_full = selected.reshape(selected.shape[0], -1).T.astype(np.float64)\n",
    "        grad_x_full = np.gradient(x_full, axis=0)\n",
    "        prob = model.predict_proba(x_full, grad_x_full).reshape(selected.shape[1:]).astype(np.float32)\n",
    "        self._log_array_ultra('probability_map', prob)\n",
    "\n",
    "        hysteresis_mask = hysteresis_topology_3d(prob, self.cfg)\n",
    "        calibrated_mask_scan, ratio_info = choose_adaptive_ratio(prob, self.cfg.ratio_candidates)\n",
    "        slice_ratio_info = choose_slicewise_adaptive_ratio(vol, prob, self.cfg.ratio_candidates)\n",
    "        calibrated_mask = np.logical_or(calibrated_mask_scan, slice_ratio_info['mask_global'])\n",
    "        final = (hysteresis_mask | calibrated_mask).astype(np.uint8)\n",
    "        self._log_progress('segment', 75.0, substage='masks_combined')\n",
    "\n",
    "        self._log_array_ultra('mask_hysteresis', hysteresis_mask.astype(np.uint8))\n",
    "        self._log_array_ultra('mask_calibrated', calibrated_mask.astype(np.uint8))\n",
    "        self._log_array_ultra('mask_final', final)\n",
    "\n",
    "        lbl, comp_count = label(final)\n",
    "        papyrus_wo_anchor = np.logical_and(calibrated_mask, ~hysteresis_mask)\n",
    "        golden_nonce = np.logical_and(prob > np.percentile(prob, 99.99), final > 0)\n",
    "        yy, xx = np.where(golden_nonce)\n",
    "        nonce_values = prob[yy, xx] if yy.size else np.array([], dtype=np.float32)\n",
    "        if yy.size:\n",
    "            ord_idx = np.argsort(nonce_values)[::-1][: self.cfg.golden_nonce_topk]\n",
    "            golden_nonce_points = [\n",
    "                {'y': int(yy[k]), 'x': int(xx[k]), 'score': float(nonce_values[k])}\n",
    "                for k in ord_idx\n",
    "            ]\n",
    "        else:\n",
    "            golden_nonce_points = []\n",
    "        patterns = comp_count\n",
    "        anomalies = int(np.sum(np.abs(laplace(prob)) > np.percentile(np.abs(laplace(prob)), 99.95)))\n",
    "        unknown_discoveries = int(np.sum(prob > 0.9995))\n",
    "\n",
    "        # approximate operations (coarse estimator)\n",
    "        pixels2d = int(prob.size)\n",
    "        ops_est = int(pixels2d * (selected.shape[0] * 12 + 200))\n",
    "\n",
    "        prob_audit = audit_logits_distribution(prob, None, self.cfg.logit_hist_bins) if self.cfg.export_logit_audit else {}\n",
    "\n",
    "        self._log_progress('segment', 100.0, substage='segment_done')\n",
    "        metrics = {\n",
    "            'selected_features': selected_names,\n",
    "            'feature_variances': {names[i]: float(variances[i]) for i in range(len(names))},\n",
    "            'train_info': train_info,\n",
    "            'train_mode': train_mode,\n",
    "            'active_ratio_final': float(final.mean()),\n",
    "            'active_ratio_hysteresis': float(hysteresis_mask.mean()),\n",
    "            'active_ratio_calibrated': float(calibrated_mask.mean()),\n",
    "            'pixels_anchor_detected': int(hysteresis_mask.sum()),\n",
    "            'pixels_papyrus_without_anchor': int(papyrus_wo_anchor.sum()),\n",
    "            'materials_detected': int(comp_count),\n",
    "            'patterns_detected': int(patterns),\n",
    "            'golden_nonce_detected': int(golden_nonce.sum()),\n",
    "            'golden_nonce_points_topk': golden_nonce_points,\n",
    "            'probability_audit': prob_audit,\n",
    "            'unknown_discoveries': int(unknown_discoveries),\n",
    "            'anomalies_detected': int(anomalies),\n",
    "            'pixels_processed_2d': pixels2d,\n",
    "            'slices_processed': int(vol.shape[0]),\n",
    "            'calc_ops_estimated': ops_est,\n",
    "            'ratio_adaptive_selected': float(ratio_info['selected_ratio']),\n",
    "            'ratio_slice_global_selected': float(slice_ratio_info['ratio_global_selected']),\n",
    "            'ratio_slice_profile': slice_ratio_info['slice_ratio_profile'],\n",
    "            'ratio_slice_mean': slice_ratio_info['slice_ratio_mean'],\n",
    "            'ratio_slice_std': slice_ratio_info['slice_ratio_std'],\n",
    "            'ratio_scan': ratio_info['ratio_scan'],\n",
    "            'meta_neuron_candidates': int(self.cfg.meta_neurons * len(self.cfg.l1_candidates) * len(self.cfg.l2_candidates)),\n",
    "            'mutation_applied': bool(train_info.get('mutation_applied', False)),\n",
    "            'pruning_applied': bool(train_info.get('pruning_applied', False)),\n",
    "            'active_neurons_start': int(train_info['selected_hyperparams'].get('active_neurons_start', 0)),\n",
    "            'active_neurons_mid': int(train_info['selected_hyperparams'].get('active_neurons_mid', 0)),\n",
    "            'active_neurons_end': int(train_info['selected_hyperparams'].get('active_neurons_end', 0)),\n",
    "        }\n",
    "        proxy_like = train_info['selected_hyperparams'].get('proxy_f1', train_info['selected_hyperparams'].get('val_f1', 0.0))\n",
    "        self.evolution.update(proxy_like, slice_ratio_info['ratio_global_selected'])\n",
    "        return final, metrics\n",
    "\n",
    "    def _validate_submission_competition_rules(self, expected_test_files: List[Path]) -> Dict[str, Any]:\n",
    "        import zipfile\n",
    "        if not self.cfg.enforce_competition_rules:\n",
    "            return {'status': 'disabled'}\n",
    "        if not self.submission_path.exists():\n",
    "            raise RuntimeError('RULES_VALIDATION_FAILED: submission.zip missing')\n",
    "        with zipfile.ZipFile(self.submission_path, 'r') as zf:\n",
    "            members = [n for n in zf.namelist() if n.lower().endswith('.tif')]\n",
    "        expected = sorted([p.name for p in expected_test_files])\n",
    "        got = sorted([Path(m).name for m in members])\n",
    "        if expected != got:\n",
    "            raise RuntimeError(f'RULES_VALIDATION_FAILED: submission members mismatch expected={len(expected)} got={len(got)}')\n",
    "        rules_exists = Path(self.cfg.competition_rules_path).exists()\n",
    "        demo_exists = Path(self.cfg.metric_demo_notebook_path).exists()\n",
    "        status = {\n",
    "            'status': 'ok',\n",
    "            'expected_test_files': len(expected),\n",
    "            'submission_tif_files': len(got),\n",
    "            'rules_file_found': bool(rules_exists),\n",
    "            'metric_demo_found': bool(demo_exists),\n",
    "        }\n",
    "        self.log('COMPETITION_RULES_VALIDATION', **status)\n",
    "        return status\n",
    "\n",
    "    def run_simulation_100(self) -> Dict[str, Any]:\n",
    "        rng = np.random.default_rng(123)\n",
    "        f1_scores = []\n",
    "        for _ in range(100):\n",
    "            prob = rng.random((128, 128), dtype=np.float32)\n",
    "            pseudo = prob > np.percentile(prob, 94.0)\n",
    "            f1_scores.append(compute_proxy_f1(prob, pseudo.astype(np.float32), threshold=0.5))\n",
    "        summary = {\n",
    "            'samples': 100,\n",
    "            'f1_mean': float(np.mean(f1_scores)),\n",
    "            'f1_std': float(np.std(f1_scores)),\n",
    "            'f1_min': float(np.min(f1_scores)),\n",
    "            'f1_max': float(np.max(f1_scores)),\n",
    "        }\n",
    "        self.log('SIMULATION_100', **summary)\n",
    "        return summary\n",
    "\n",
    "    def run(self) -> Path:\n",
    "        t_global = time.perf_counter()\n",
    "        files = self.discover_inputs()\n",
    "        self._run_preflight_5pct(files)\n",
    "        self.build_supervised_model()\n",
    "        self.plan.update('package', 10.0)\n",
    "        sup_f1_values: List[float] = []\n",
    "        sup_iou_values: List[float] = []\n",
    "        sup_th_values: List[float] = []\n",
    "        prob_max_values: List[float] = []\n",
    "        prob_mean_values: List[float] = []\n",
    "        prob_std_values: List[float] = []\n",
    "\n",
    "        with zipfile.ZipFile(self.submission_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "            for i, fpath in enumerate(files, start=1):\n",
    "                t0 = time.perf_counter()\n",
    "                self.log('FILE_START', file=fpath.name, index=i, total=len(files))\n",
    "                self._log_progress('package', 10.0 + 85.0 * ((i - 1) / max(1, len(files))), substage='file_start', file_name=fpath.name, index=i, total=len(files))\n",
    "                for st in ('load', 'features', 'train', 'segment'):\n",
    "                    self.plan.update(st, 0.0, done=False)\n",
    "\n",
    "                self._log_heartbeat('file_processing', file_name=fpath.name, note='start_file_compute', index=i, total=len(files))\n",
    "                vol = self._load_volume(fpath)\n",
    "                mask2d, m = self._predict_mask(vol)\n",
    "                self._log_heartbeat('file_processing', file_name=fpath.name, note='end_file_compute', index=i, total=len(files))\n",
    "                self.log('NX47_METRICS', file=fpath.name, **m)\n",
    "\n",
    "                self.global_stats['files_processed'] += 1\n",
    "                self.global_stats['slices_processed'] += m['slices_processed']\n",
    "                self.global_stats['pixels_processed'] += int(vol.size)\n",
    "                self.global_stats['pixels_anchor_detected'] += m['pixels_anchor_detected']\n",
    "                self.global_stats['pixels_papyrus_without_anchor'] += m['pixels_papyrus_without_anchor']\n",
    "                self.global_stats['materials_detected'] += m['materials_detected']\n",
    "                self.global_stats['patterns_detected'] += m['patterns_detected']\n",
    "                self.global_stats['golden_nonce_detected'] += m['golden_nonce_detected']\n",
    "                self.global_stats['unknown_discoveries'] += m['unknown_discoveries']\n",
    "                self.global_stats['anomalies_detected'] += m['anomalies_detected']\n",
    "                self.global_stats['calc_ops_estimated'] += m['calc_ops_estimated']\n",
    "                self.global_stats['active_neurons_start_total'] += m['active_neurons_start']\n",
    "                self.global_stats['active_neurons_mid_total'] += m['active_neurons_mid']\n",
    "                self.global_stats['active_neurons_end_total'] += m['active_neurons_end']\n",
    "                self.global_stats['meta_neuron_candidates'] += m['meta_neuron_candidates']\n",
    "                self.global_stats['mutation_events'] += int(m['mutation_applied'])\n",
    "                self.global_stats['pruning_events'] += int(m['pruning_applied'])\n",
    "                pa = m.get('probability_audit', {})\n",
    "                if isinstance(pa, dict):\n",
    "                    prob_max_values.append(float(pa.get('max', 0.0)))\n",
    "                    prob_mean_values.append(float(pa.get('mean', 0.0)))\n",
    "                    prob_std_values.append(float(pa.get('std', 0.0)))\n",
    "                if m.get('train_mode') == 'supervised':\n",
    "                    self.global_stats['files_supervised_mode'] += 1\n",
    "                    shp = m.get('train_info', {}).get('selected_hyperparams', {})\n",
    "                    if 'val_f1' in shp:\n",
    "                        sup_f1_values.append(float(shp['val_f1']))\n",
    "                    if 'val_iou' in shp:\n",
    "                        sup_iou_values.append(float(shp['val_iou']))\n",
    "                    if 'best_threshold' in shp:\n",
    "                        sup_th_values.append(float(shp['best_threshold']))\n",
    "                else:\n",
    "                    self.global_stats['files_autonomous_fallback'] += 1\n",
    "\n",
    "                out_mask = self.tmp_dir / fpath.name\n",
    "                mask2d_u8 = (np.asarray(mask2d, dtype=np.uint8) > 0).astype(np.uint8)\n",
    "                binary_mode = os.environ.get(\"NX47_BINARY_MODE\", \"0_1\").strip().lower()\n",
    "                if binary_mode not in {\"0_1\", \"0_255\"}:\n",
    "                    raise RuntimeError(f\"Invalid NX47_BINARY_MODE: {binary_mode}\")\n",
    "                if binary_mode == \"0_255\":\n",
    "                    mask2d_u8 = (mask2d_u8 * 255).astype(np.uint8)\n",
    "                submission_volume = np.repeat(mask2d_u8[np.newaxis, ...], vol.shape[0], axis=0)\n",
    "                write_tiff_lzw_safe(out_mask, submission_volume)\n",
    "                zf.write(out_mask, arcname=fpath.name)\n",
    "                out_mask.unlink(missing_ok=True)\n",
    "                gc.collect()\n",
    "\n",
    "                dt = max(1e-9, time.perf_counter() - t0)\n",
    "                cps = m['calc_ops_estimated'] / dt\n",
    "                self.log('FILE_DONE', file=fpath.name, active_ratio=round(float(mask2d.mean()), 6), calc_per_sec=float(cps), elapsed_s=round(dt, 3))\n",
    "                self.plan.update('package', 10.0 + 85.0 * (i / len(files)))\n",
    "                self._log_progress('package', 10.0 + 85.0 * (i / max(1, len(files))), substage='file_done', file_name=fpath.name, index=i, total=len(files))\n",
    "\n",
    "        rules_validation = self._validate_submission_competition_rules(files)\n",
    "\n",
    "        total_dt = max(1e-9, time.perf_counter() - t_global)\n",
    "        self.global_stats['calc_per_sec_global'] = float(self.global_stats['calc_ops_estimated'] / total_dt)\n",
    "        self.global_stats['elapsed_total_s'] = float(total_dt)\n",
    "        self.global_stats['ratio_selected_mean'] = float(np.mean(self.evolution.ratio_history)) if self.evolution.ratio_history else 0.0\n",
    "        self.global_stats['val_f1_mean_supervised'] = float(np.mean(sup_f1_values)) if sup_f1_values else 0.0\n",
    "        self.global_stats['val_iou_mean_supervised'] = float(np.mean(sup_iou_values)) if sup_iou_values else 0.0\n",
    "        self.global_stats['best_threshold_mean_supervised'] = float(np.mean(sup_th_values)) if sup_th_values else 0.0\n",
    "\n",
    "        if self.supervised_train_info is not None:\n",
    "            uinfo = self.supervised_train_info.get('unet_25d', {})\n",
    "            self.global_stats['unet_25d_status'] = str(uinfo.get('status', 'n/a'))\n",
    "            self.global_stats['unet_25d_best_fbeta'] = float(uinfo.get('best', {}).get('val_fbeta', 0.0)) if isinstance(uinfo.get('best', {}), dict) else 0.0\n",
    "\n",
    "        f1_curve = simulate_f1_vs_ratio_curve()\n",
    "        self.global_stats['f1_ratio_curve_best_ratio'] = float(f1_curve['best_ratio'])\n",
    "        self.global_stats['f1_ratio_curve_best_f1'] = float(f1_curve['best_f1'])\n",
    "\n",
    "        sim = self.run_simulation_100() if self.cfg.run_simulation_100 else None\n",
    "\n",
    "        self.global_stats['probability_max_observed'] = float(np.max(prob_max_values)) if prob_max_values else 0.0\n",
    "        self.global_stats['probability_mean_observed'] = float(np.mean(prob_mean_values)) if prob_mean_values else 0.0\n",
    "        self.global_stats['probability_std_observed'] = float(np.mean(prob_std_values)) if prob_std_values else 0.0\n",
    "        self.global_stats['forensic_report_generated'] = bool(self.cfg.export_forensic_v1442_report)\n",
    "        self.global_stats['learning_percent_real'] = float(self.learning_audit.get('learning_percent_real', 0.0))\n",
    "        self.global_stats['reasoning_trace_events'] = int(len(self.logs))\n",
    "        self.global_stats['train_pair_count_discovered'] = int(self.train_dataset_audit.get('pair_count_discovered', 0))\n",
    "        self.global_stats['train_pair_coverage_pct'] = float(self.train_dataset_audit.get('coverage_pct_selected_vs_discovered', 0.0))\n",
    "        self.log('GLOBAL_STATS', **self.global_stats)\n",
    "\n",
    "        forensic_report = self._build_v1442_forensic_report() if self.cfg.export_forensic_v1442_report else {'status': 'disabled'}\n",
    "        self.forensic_report_path.write_text(json.dumps(forensic_report, indent=2, ensure_ascii=False), encoding='utf-8')\n",
    "\n",
    "        metadata = {\n",
    "            'version': self.version,\n",
    "            'root': str(self.root),\n",
    "            'input_dir': str(self.test_dir),\n",
    "            'submission_zip': str(self.submission_path),\n",
    "            'log_count': len(self.logs),\n",
    "            'ultra_log': str(self.ultra_log_path),\n",
    "            'hardware': probe_hardware_metrics(),\n",
    "            'global_stats': self.global_stats,\n",
    "            'evolution_memory': asdict(self.evolution),\n",
    "            'supervised_train_info': self.supervised_train_info,\n",
    "            'simulation_100': sim,\n",
    "            'f1_ratio_curve': f1_curve,\n",
    "            'config': asdict(self.cfg),\n",
    "            'nx_continuity_matrix': self.continuity_matrix,\n",
    "            'line_by_line_review': 'completed_v138',\n",
    "            'train_pairs_required': int(self.cfg.min_train_pairs_required),\n",
    "            'train_image_files_required': int(self.cfg.min_train_image_files_required),\n",
    "            'train_label_files_required': int(self.cfg.min_train_label_files_required),\n",
    "            'require_train_completion_100': bool(self.cfg.require_train_completion_100),\n",
    "            'forbid_autonomous_mode': bool(self.cfg.forbid_autonomous_mode),\n",
    "            'enforce_no_hardcoded_metrics': bool(self.cfg.enforce_no_hardcoded_metrics),\n",
    "            'hardcoded_metric_policy': str(self.cfg.hardcoded_metric_policy),\n",
    "            'learning_audit': self.learning_audit,\n",
    "            'train_dataset_audit': self.train_dataset_audit,\n",
    "            'forensic_report': forensic_report,\n",
    "            'competition_rules_validation': rules_validation,\n",
    "            'proof_bundle': {\n",
    "                'has_global_stats': True,\n",
    "                'has_exec_complete': True,\n",
    "                'submission_zip_expected': str(self.submission_path),\n",
    "                'kernel_version': self.version,\n",
    "            },\n",
    "        }\n",
    "        self.plan.update('package', 100.0, done=True)\n",
    "        self.log('EXEC_COMPLETE', submission=str(self.submission_path))\n",
    "\n",
    "        self.metadata_path.write_text(json.dumps(metadata, indent=2), encoding='utf-8')\n",
    "        self.logs_path.write_text(json.dumps(self.logs, indent=2), encoding='utf-8')\n",
    "        self.memory_path.write_text(json.dumps(self.memory.events, indent=2), encoding='utf-8')\n",
    "        return self.submission_path\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg = V1442Config(\n",
    "        top_k_features=int(os.environ.get('V1442_TOP_K_FEATURES', '6')),\n",
    "        target_active_ratio=float(os.environ.get('V1442_TARGET_ACTIVE_RATIO', '0.03')),\n",
    "        full_pixel_trace=os.environ.get('V1442_FULL_PIXEL_TRACE', '0') == '1',\n",
    "        trace_pixel_budget=int(os.environ.get('V1442_TRACE_PIXEL_BUDGET', '4000')),\n",
    "        ultra_console_log=os.environ.get('V1442_ULTRA_CONSOLE_LOG', '1') == '1',\n",
    "        ultra_step_log=os.environ.get('V1442_ULTRA_STEP_LOG', '1') == '1',\n",
    "        ultra_bit_trace_arrays=os.environ.get('V1442_ULTRA_BIT_TRACE_ARRAYS', '1') == '1',\n",
    "        ultra_bit_trace_limit=int(os.environ.get('V1442_ULTRA_BIT_TRACE_LIMIT', '64')),\n",
    "        meta_neurons=int(os.environ.get('V1442_META_NEURONS', '3')),\n",
    "        run_simulation_100=os.environ.get('V1442_RUN_SIMULATION_100', '0') == '1',\n",
    "        simulation_export_curve=os.environ.get('V1442_SIMULATION_EXPORT_CURVE', '1') == '1',\n",
    "        supervised_train=os.environ.get('V1442_SUPERVISED_TRAIN', '1') == '1',\n",
    "        max_train_volumes=int(os.environ.get('V1442_MAX_TRAIN_VOLUMES', '24')),\n",
    "        max_val_volumes=int(os.environ.get('V1442_MAX_VAL_VOLUMES', '8')),\n",
    "        max_samples_per_volume=int(os.environ.get('V1442_MAX_SAMPLES_PER_VOLUME', '40000')),\n",
    "        pos_neg_ratio=float(os.environ.get('V1442_POS_NEG_RATIO', '1.0')),\n",
    "        golden_nonce_topk=int(os.environ.get('V1442_GOLDEN_NONCE_TOPK', '11')),\n",
    "        supervised_epochs=int(os.environ.get('V1442_SUPERVISED_EPOCHS', '0')),\n",
    "        fbeta_beta=float(os.environ.get('V1442_F_BETA', '0.5')),\n",
    "        use_unet_25d=os.environ.get('V1442_USE_UNET_25D', '1') == '1',\n",
    "        unet_in_slices=int(os.environ.get('V1442_UNET_IN_SLICES', '7')),\n",
    "        unet_base_channels=int(os.environ.get('V1442_UNET_BASE_CHANNELS', '24')),\n",
    "        patch_size=int(os.environ.get('V1442_PATCH_SIZE', '128')),\n",
    "        patch_stride=int(os.environ.get('V1442_PATCH_STRIDE', '64')),\n",
    "        unet_epochs=int(os.environ.get('V1442_UNET_EPOCHS', '2')),\n",
    "        unet_lr=float(os.environ.get('V1442_UNET_LR', '0.001')),\n",
    "        unet_batch_size=int(os.environ.get('V1442_UNET_BATCH_SIZE', '8')),\n",
    "        export_logit_audit=os.environ.get('V1442_EXPORT_LOGIT_AUDIT', '1') == '1',\n",
    "        logit_hist_bins=int(os.environ.get('V1442_LOGIT_HIST_BINS', '20')),\n",
    "        v130_log_path=os.environ.get('V1442_SOURCE_V130_LOG', 'nx47-vesu-kernel-new-v130.log'),\n",
    "        export_forensic_v1442_report=os.environ.get('V1442_EXPORT_FORENSIC_REPORT', '1') == '1',\n",
    "        enforce_nx_legacy_continuity=os.environ.get('V1442_ENFORCE_NX_CONTINUITY', '1') == '1',\n",
    "        strict_no_fallback=os.environ.get('V1442_STRICT_NO_FALLBACK', '1') == '1',\n",
    "        min_train_pairs_required=int(os.environ.get('V1442_MIN_TRAIN_PAIRS_REQUIRED', '786')),\n",
    "        require_train_completion_100=os.environ.get('V1442_REQUIRE_TRAIN_COMPLETION_100', '1') == '1',\n",
    "        forbid_autonomous_mode=os.environ.get('V1442_FORBID_AUTONOMOUS_MODE', '1') == '1',\n",
    "        enforce_no_hardcoded_metrics=os.environ.get('V1442_ENFORCE_NO_HARDCODED_METRICS', '1') == '1',\n",
    "        hardcoded_metric_policy=os.environ.get('V1442_HARDCODED_METRIC_POLICY', 'warn'),\n",
    "        adapt_train_threshold_to_dataset_size=os.environ.get('V1442_ADAPT_TRAIN_THRESHOLD_TO_DATASET_SIZE', '1') == '1',\n",
    "        train_pair_coverage_target_pct=float(os.environ.get('V1442_TRAIN_PAIR_COVERAGE_TARGET_PCT', '100.0')),\n",
    "        min_train_image_files_required=int(os.environ.get('V1442_MIN_TRAIN_IMAGE_FILES_REQUIRED', '786')),\n",
    "        min_train_label_files_required=int(os.environ.get('V1442_MIN_TRAIN_LABEL_FILES_REQUIRED', '786')),\n",
    "        enforce_competition_rules=os.environ.get('V1442_ENFORCE_COMPETITION_RULES', '1') == '1',\n",
    "        competition_rules_path=os.environ.get('V1442_COMPETITION_RULES_PATH', 'Competition_Rules_Vesuvius_Challenge _Surface_Detection.md'),\n",
    "        metric_demo_notebook_path=os.environ.get('V1442_METRIC_DEMO_NOTEBOOK_PATH', 'vesuvius-2025-metric-demo.ipynb'),\n",
    "        convergence_patience=int(os.environ.get('V1442_CONVERGENCE_PATIENCE', '5')),\n",
    "        convergence_min_delta=float(os.environ.get('V1442_CONVERGENCE_MIN_DELTA', '1e-6')),\n",
    "        auto_epoch_safety_cap=int(os.environ.get('V1442_AUTO_EPOCH_SAFETY_CAP', '0')),\n",
    "        preflight_train_pct=float(os.environ.get('V1442_PREFLIGHT_TRAIN_PCT', '5.0')),\n",
    "        preflight_test_pct=float(os.environ.get('V1442_PREFLIGHT_TEST_PCT', '5.0')),\n",
    "        progress_bar_width=int(os.environ.get('V1442_PROGRESS_BAR_WIDTH', '24')),\n",
    "        heartbeat_interval_s=float(os.environ.get('V1442_HEARTBEAT_INTERVAL_S', '30.0')),\n",
    "        stage_stall_alert_s=float(os.environ.get('V1442_STAGE_STALL_ALERT_S', '180.0')),\n",
    "        run_ablation_check=os.environ.get('V1442_RUN_ABLATION_CHECK', '1') == '1',\n",
    "        stability_probe_runs=int(os.environ.get('V1442_STABILITY_PROBE_RUNS', '0')),\n",
    "    )\n",
    "    kernel = NX47V1442Kernel(\n",
    "        root=Path(os.environ.get('VESUVIUS_ROOT', '/kaggle/input/competitions/vesuvius-challenge-surface-detection')),\n",
    "        output_dir=Path(os.environ.get('VESUVIUS_OUTPUT', '/kaggle/working')),\n",
    "        config=cfg,\n",
    "    )\n",
    "    submission = kernel.run()\n",
    "    print(f'READY: {submission}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloc source intégré: V7.7\n",
    "Source: `RAPPORT-VESUVIUS/src_vesuvius/nx46_vesuvius_core_kaggle_ready_v7.7/nx46-vesuvius-core-kaggle-ready-v7-7.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NX-46 Vesuvius Kaggle-ready v7.7 (offline-first, forensic, regression-safe).\n",
    "\n",
    "V7.7 objectives:\n",
    "- Keep validated v3/v4/v5 compatibility outputs (submission.zip + forensic logs + compatibility txt files).\n",
    "- Add V6 material-head outputs (ink/fiber/background/artifact proxies) from native signals.\n",
    "- Emit native training manifest and richer forensic evidence for V6 roadmap compliance.\n",
    "- Preserve strict Kaggle compliance, offline dependency bootstrap, and 0/1 mask outputs (competitor-aligned).\n",
    "- Enforce scorer-safe TIFF submission format (3D multi-page, exact Z/H/W shape, binary value check).\n",
    "- Activate high-quality native 3D scoring path by default; keep 2.5D path optional/off by default.\n",
    "- Match successful notebook submission conventions exactly: primary zip at /kaggle/working/submission.zip, ZIP_STORED members, LZW multi-page TIFF uint8.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import importlib\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "from dataclasses import dataclass\n",
    "from hashlib import sha512\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "DRY_RUN_FLAG = os.environ.get(\"NX46_DRY_RUN\", \"0\") == \"1\"\n",
    "if DRY_RUN_FLAG and __name__ == \"__main__\":\n",
    "    print(json.dumps({\n",
    "        \"status\": \"dry_run\",\n",
    "        \"run_tag\": os.environ.get(\"NX46_RUN_TAG\", \"v7.7-dry\"),\n",
    "        \"threshold_quantile\": float(os.environ.get(\"NX46_THRESHOLD_QUANTILE\", \"0.985\")),\n",
    "        \"score_blend_3d_weight\": float(os.environ.get(\"NX46_SCORE_BLEND_3D_WEIGHT\", \"0.78\")),\n",
    "        \"z_smoothing_radius\": int(os.environ.get(\"NX46_Z_SMOOTHING_RADIUS\", \"2\")),\n",
    "    }, ensure_ascii=False))\n",
    "    raise SystemExit(0)\n",
    "\n",
    "\n",
    "def install_offline(package_name: str) -> None:\n",
    "    exact_wheel_dir = Path(\"/kaggle/input/datasets/ndarray2000/nx47-dependencies\")\n",
    "    fallback_wheel_dir = Path(\"/kaggle/input/nx47-dependencies\")\n",
    "    lum_wheel_dir = Path(\"/kaggle/input/lum-vorax-dependencies\")\n",
    "    lum_wheel_dir_alt = Path(\"/kaggle/input/lumvorax-dependencies\")\n",
    "\n",
    "    exact_wheels = {\n",
    "        \"imagecodecs\": exact_wheel_dir / \"imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n",
    "        \"numpy\": exact_wheel_dir / \"numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n",
    "        \"tifffile\": exact_wheel_dir / \"tifffile-2026.1.28-py3-none-any.whl\",\n",
    "    }\n",
    "\n",
    "    if package_name == \"numpy\" and importlib.util.find_spec(\"numpy\") is not None:\n",
    "        return\n",
    "\n",
    "    if package_name in exact_wheels and exact_wheels[package_name].exists():\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", str(exact_wheels[package_name])])\n",
    "            return\n",
    "        except subprocess.CalledProcessError:\n",
    "            pass\n",
    "\n",
    "    for wheel_dir in (exact_wheel_dir, fallback_wheel_dir, lum_wheel_dir, lum_wheel_dir_alt):\n",
    "        if wheel_dir.exists():\n",
    "            subprocess.check_call(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", f\"--find-links={wheel_dir}\", package_name]\n",
    "            )\n",
    "            return\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Offline dependency directory not found for {package_name}. \"\n",
    "        f\"Checked: {exact_wheel_dir} and {fallback_wheel_dir}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def bootstrap_dependencies_fail_fast() -> None:\n",
    "    install_offline(\"numpy\")\n",
    "    install_offline(\"imagecodecs\")\n",
    "    install_offline(\"tifffile\")\n",
    "\n",
    "\n",
    "def emit_dependency_manifest(output_root: Path) -> None:\n",
    "    payload = {\n",
    "        \"paths\": [\n",
    "            \"/kaggle/input/datasets/ndarray2000/nx47-dependencies\",\n",
    "            \"/kaggle/input/nx47-dependencies\",\n",
    "            \"/kaggle/input/lum-vorax-dependencies\",\n",
    "            \"/kaggle/input/lumvorax-dependencies\",\n",
    "        ],\n",
    "        \"packages\": {name: (importlib.util.find_spec(name) is not None) for name in [\"numpy\",\"tifffile\",\"imagecodecs\",\"imageio\"]},\n",
    "    }\n",
    "    p = output_root / \"dependency_manifest_v77.json\"\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "bootstrap_dependencies_fail_fast()\n",
    "\n",
    "# forensic 360 dependency manifest\n",
    "emit_dependency_manifest(Path(\"/kaggle/working/nx46_vesuvius\"))\n",
    "\n",
    "import numpy as np  # noqa: E402\n",
    "import tifffile  # noqa: E402\n",
    "import imageio.v3 as iio  # noqa: E402\n",
    "\n",
    "\n",
    "def ensure_imagecodecs() -> bool:\n",
    "    if importlib.util.find_spec(\"imagecodecs\") is not None:\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        install_offline(\"imagecodecs\")\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "    if importlib.util.find_spec(\"imagecodecs\") is None:\n",
    "        return False\n",
    "\n",
    "    global tifffile\n",
    "    tifffile = importlib.reload(tifffile)\n",
    "    return True\n",
    "\n",
    "\n",
    "def read_tiff_lzw_safe(path: Path) -> np.ndarray:\n",
    "    try:\n",
    "        return np.asarray(tifffile.imread(path))\n",
    "    except ValueError as exc:\n",
    "        if \"requires the 'imagecodecs' package\" not in str(exc):\n",
    "            raise\n",
    "\n",
    "    ensure_imagecodecs()\n",
    "    try:\n",
    "        return np.asarray(tifffile.imread(path))\n",
    "    except ValueError as exc:\n",
    "        if \"requires the 'imagecodecs' package\" not in str(exc):\n",
    "            raise\n",
    "\n",
    "    if importlib.util.find_spec(\"PIL\") is None:\n",
    "        raise RuntimeError(\"LZW TIFF read failed and Pillow fallback unavailable\")\n",
    "\n",
    "    from PIL import Image, ImageSequence\n",
    "\n",
    "    with Image.open(path) as img:\n",
    "        frames = [np.array(frame, dtype=np.float32) for frame in ImageSequence.Iterator(img)]\n",
    "    if not frames:\n",
    "        raise RuntimeError(f\"No frames decoded from TIFF: {path}\")\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NX46Config:\n",
    "    data_root: str = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n",
    "    work_root: str = \"/kaggle/working/nx46_vesuvius\"\n",
    "    kaggle_submission_root: str = \"/kaggle/working\"\n",
    "    seed: int = 46\n",
    "    bit_capture_bytes: int = 256\n",
    "    threshold_quantile: float = 0.985\n",
    "    slab_min_neurons: int = 128\n",
    "    auto_discover_data_root: bool = True\n",
    "    strict_competition_mode: bool = True\n",
    "    max_train_items: int = 512\n",
    "    enable_material_head: bool = True\n",
    "    save_material_outputs: bool = True\n",
    "    use_3d_native_path: bool = True\n",
    "    use_25d_path: bool = False\n",
    "    score_blend_3d_weight: float = 0.78\n",
    "    z_smoothing_radius: int = 2\n",
    "    write_submission_csv: bool = False\n",
    "    binary_mode: str = \"0_1\"\n",
    "    run_tag: str = \"v7.7-default\"\n",
    "\n",
    "\n",
    "class ProgressRoadmap:\n",
    "    def __init__(self) -> None:\n",
    "        self.steps: Dict[str, float] = {\n",
    "            \"audit_discovery\": 0.0,\n",
    "            \"train_thresholds\": 0.0,\n",
    "            \"infer_predictions\": 0.0,\n",
    "            \"package_submission\": 0.0,\n",
    "            \"finalize_forensics\": 0.0,\n",
    "        }\n",
    "\n",
    "    def update(self, step: str, pct: float) -> None:\n",
    "        self.steps[step] = max(0.0, min(100.0, float(pct)))\n",
    "        print(f\"[ROADMAP] {step}: {self.steps[step]:.1f}%\")\n",
    "\n",
    "    def as_dict(self) -> Dict[str, float]:\n",
    "        return dict(self.steps)\n",
    "\n",
    "\n",
    "class HFBL360Logger:\n",
    "    def __init__(self, root: Path) -> None:\n",
    "        self.root = root\n",
    "        self.root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.forensic_log = root / \"forensic_ultra.log\"\n",
    "        self.core_log = root / \"nx-46-vesuvius-core.log\"\n",
    "        self.kaggle_log = root / \"nx46-vesuvius-core-kaggle-ready.log\"\n",
    "        self.metrics_csv = root / \"metrics.csv\"\n",
    "        self.state_json = root / \"state.json\"\n",
    "        self.bit_log = root / \"bit_capture.log\"\n",
    "        self.merkle_log = root / \"merkle_chain.log\"\n",
    "        self.discovery_json = root / \"dataset_discovery_inventory.json\"\n",
    "\n",
    "        with self.metrics_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow(\n",
    "                [\n",
    "                    \"timestamp_ns\",\n",
    "                    \"phase\",\n",
    "                    \"fragment\",\n",
    "                    \"neurons_active\",\n",
    "                    \"cpu_ns\",\n",
    "                    \"ink_pixels\",\n",
    "                    \"total_pixels\",\n",
    "                    \"ink_ratio\",\n",
    "                    \"merkle_prefix\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def _append(self, line: str) -> None:\n",
    "        for p in (self.forensic_log, self.core_log, self.kaggle_log):\n",
    "            with p.open(\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "    def log_event(self, event: str, **data: object) -> None:\n",
    "        payload = json.dumps(data, ensure_ascii=False) if data else \"\"\n",
    "        self._append(f\"{time.time_ns()} | {event}{(' | ' + payload) if payload else ''}\")\n",
    "\n",
    "    def log_bits(self, fragment: str, payload: bytes) -> None:\n",
    "        bits = \"\".join(f\"{b:08b}\" for b in payload)\n",
    "        with self.bit_log.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{time.time_ns()} | {fragment} | {bits}\\n\")\n",
    "\n",
    "    def log_merkle(self, fragment: str, digest: str) -> None:\n",
    "        with self.merkle_log.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{time.time_ns()} | {fragment} | {digest}\\n\")\n",
    "\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        *,\n",
    "        phase: str,\n",
    "        fragment: str,\n",
    "        neurons_active: int,\n",
    "        cpu_ns: int,\n",
    "        ink_pixels: int,\n",
    "        total_pixels: int,\n",
    "        merkle_prefix: str,\n",
    "    ) -> None:\n",
    "        ratio = (ink_pixels / total_pixels) if total_pixels else 0.0\n",
    "        with self.metrics_csv.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow(\n",
    "                [\n",
    "                    time.time_ns(),\n",
    "                    phase,\n",
    "                    fragment,\n",
    "                    neurons_active,\n",
    "                    cpu_ns,\n",
    "                    ink_pixels,\n",
    "                    total_pixels,\n",
    "                    f\"{ratio:.8f}\",\n",
    "                    merkle_prefix,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def write_state(self, state: Dict[str, object]) -> None:\n",
    "        state = dict(state)\n",
    "        state[\"timestamp_ns\"] = time.time_ns()\n",
    "        self.state_json.write_text(json.dumps(state, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    def write_discovery_inventory(self, payload: Dict[str, object]) -> None:\n",
    "        self.discovery_json.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class NX46AGNNVesuvius:\n",
    "    def __init__(self, cfg: NX46Config, logs_root: Path) -> None:\n",
    "        self.cfg = cfg\n",
    "        self.rng = np.random.default_rng(cfg.seed)\n",
    "        self.logger = HFBL360Logger(logs_root)\n",
    "        self.neurons_active = 0\n",
    "        self.total_allocations = 0\n",
    "        self.total_pixels_processed = 0\n",
    "        self.total_ink_pixels = 0\n",
    "        self.merkle_chain: List[str] = []\n",
    "        self.global_cpu_start_ns = time.process_time_ns()\n",
    "        self.logger.log_event(\"SYSTEM_STARTUP_L0_SUCCESS\", config=cfg.__dict__)\n",
    "\n",
    "    def slab_allocate(self, tensor: np.ndarray, phase: str) -> int:\n",
    "        variance = float(np.var(tensor, dtype=np.float64))\n",
    "        entropy_proxy = float(np.mean(np.abs(np.gradient(tensor.astype(np.float32), axis=-1))))\n",
    "        required = int(self.cfg.slab_min_neurons + (tensor.size // 512) + variance * 1500.0 + entropy_proxy * 900.0)\n",
    "        self.neurons_active = max(self.cfg.slab_min_neurons, required)\n",
    "        self.total_allocations += 1\n",
    "        self.logger.log_event(\n",
    "            \"SLAB_ALLOCATION\",\n",
    "            phase=phase,\n",
    "            neurons=self.neurons_active,\n",
    "            variance=round(variance, 8),\n",
    "            entropy_proxy=round(entropy_proxy, 8),\n",
    "        )\n",
    "        return self.neurons_active\n",
    "\n",
    "    def _track_bits(self, fragment: str, arr: np.ndarray) -> None:\n",
    "        self.logger.log_bits(fragment, arr.tobytes()[: self.cfg.bit_capture_bytes])\n",
    "\n",
    "    def _merkle_sign(self, fragment: str, arr: np.ndarray) -> str:\n",
    "        prev = self.merkle_chain[-1] if self.merkle_chain else \"GENESIS\"\n",
    "        digest = sha512(prev.encode(\"utf-8\") + arr.tobytes()).hexdigest()\n",
    "        self.merkle_chain.append(digest)\n",
    "        self.logger.log_merkle(fragment, digest)\n",
    "        return digest\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_stack(stack: np.ndarray) -> np.ndarray:\n",
    "        x = stack.astype(np.float32)\n",
    "        mn, mx = float(x.min()), float(x.max())\n",
    "        if mx <= mn:\n",
    "            return np.zeros_like(x, dtype=np.float32)\n",
    "        return (x - mn) / (mx - mn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _ink_energy_projection(stack: np.ndarray) -> np.ndarray:\n",
    "        grad_z = np.abs(np.diff(stack, axis=0, prepend=stack[:1]))\n",
    "        grad_y = np.abs(np.diff(stack, axis=1, prepend=stack[:, :1, :]))\n",
    "        grad_x = np.abs(np.diff(stack, axis=2, prepend=stack[:, :, :1]))\n",
    "        return np.mean(0.45 * grad_z + 0.30 * grad_y + 0.25 * grad_x, axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_along_z(stack: np.ndarray, radius: int) -> np.ndarray:\n",
    "        if radius <= 0:\n",
    "            return stack\n",
    "        r = int(max(1, radius))\n",
    "        pad = np.pad(stack, ((r, r), (0, 0), (0, 0)), mode=\"edge\")\n",
    "        csum = np.cumsum(pad, axis=0, dtype=np.float64)\n",
    "        win = (csum[2 * r :] - csum[: -2 * r]) / float(2 * r)\n",
    "        return win.astype(np.float32)\n",
    "\n",
    "    def _score_3d_native(self, norm: np.ndarray) -> np.ndarray:\n",
    "        grad_z = np.abs(np.diff(norm, axis=0, prepend=norm[:1]))\n",
    "        grad_y = np.abs(np.diff(norm, axis=1, prepend=norm[:, :1, :]))\n",
    "        grad_x = np.abs(np.diff(norm, axis=2, prepend=norm[:, :, :1]))\n",
    "\n",
    "        smooth = self._smooth_along_z(norm, self.cfg.z_smoothing_radius)\n",
    "        local_contrast = np.abs(norm - smooth)\n",
    "\n",
    "        d2z = np.abs(np.diff(norm, n=2, axis=0, prepend=norm[:1], append=norm[-1:]))\n",
    "\n",
    "        score3d = np.mean(\n",
    "            0.34 * grad_z + 0.22 * grad_y + 0.22 * grad_x + 0.12 * local_contrast + 0.10 * d2z,\n",
    "            axis=0,\n",
    "        )\n",
    "        return score3d.astype(np.float32)\n",
    "\n",
    "    def _score_25d_proxy(self, norm: np.ndarray) -> np.ndarray:\n",
    "        z = norm.shape[0]\n",
    "        if z <= 1:\n",
    "            return self._ink_energy_projection(norm)\n",
    "        center = z // 2\n",
    "        idx = sorted(set([max(0, center - 2), max(0, center - 1), center, min(z - 1, center + 1), min(z - 1, center + 2)]))\n",
    "        slab = norm[idx]\n",
    "        return self._ink_energy_projection(slab)\n",
    "\n",
    "    def score_projection(self, stack: np.ndarray) -> np.ndarray:\n",
    "        norm = self._normalize_stack(stack)\n",
    "        base = self._ink_energy_projection(norm)\n",
    "\n",
    "        if self.cfg.use_3d_native_path:\n",
    "            s3d = self._score_3d_native(norm)\n",
    "            w = float(min(1.0, max(0.0, self.cfg.score_blend_3d_weight)))\n",
    "            base = (w * s3d + (1.0 - w) * base).astype(np.float32)\n",
    "\n",
    "        if self.cfg.use_25d_path:\n",
    "            s25 = self._score_25d_proxy(norm)\n",
    "            base = (0.65 * base + 0.35 * s25).astype(np.float32)\n",
    "\n",
    "        return base\n",
    "\n",
    "    def train_threshold(self, stack: np.ndarray, labels: np.ndarray, fragment: str) -> float:\n",
    "        start = time.process_time_ns()\n",
    "        self.slab_allocate(stack, phase=\"train\")\n",
    "        self._track_bits(fragment, stack)\n",
    "\n",
    "        score = self.score_projection(stack)\n",
    "        pos = score[labels > 0]\n",
    "        neg = score[labels <= 0]\n",
    "        if pos.size and neg.size:\n",
    "            threshold = float(0.5 * (float(np.median(pos)) + float(np.median(neg))))\n",
    "        elif pos.size:\n",
    "            threshold = float(np.quantile(pos, 0.50))\n",
    "        else:\n",
    "            threshold = float(np.quantile(score, self.cfg.threshold_quantile))\n",
    "\n",
    "        pred = (score >= threshold).astype(np.uint8)\n",
    "        digest = self._merkle_sign(fragment, score)\n",
    "        cpu_ns = time.process_time_ns() - start\n",
    "\n",
    "        ink_pixels = int(pred.sum())\n",
    "        total_pixels = int(pred.size)\n",
    "        self.total_ink_pixels += ink_pixels\n",
    "        self.total_pixels_processed += total_pixels\n",
    "\n",
    "        self.logger.log_metrics(\n",
    "            phase=\"train\",\n",
    "            fragment=fragment,\n",
    "            neurons_active=self.neurons_active,\n",
    "            cpu_ns=cpu_ns,\n",
    "            ink_pixels=ink_pixels,\n",
    "            total_pixels=total_pixels,\n",
    "            merkle_prefix=digest[:16],\n",
    "        )\n",
    "        self.logger.log_event(\"TRAIN_DONE\", fragment=fragment, threshold=threshold)\n",
    "        return threshold\n",
    "\n",
    "    def infer_mask(self, stack: np.ndarray, threshold: float, fragment: str) -> np.ndarray:\n",
    "        start = time.process_time_ns()\n",
    "        self.slab_allocate(stack, phase=\"infer\")\n",
    "        self._track_bits(fragment, stack)\n",
    "\n",
    "        score = self.score_projection(stack)\n",
    "        pred = (score >= threshold).astype(np.uint8)\n",
    "        digest = self._merkle_sign(fragment, pred)\n",
    "        cpu_ns = time.process_time_ns() - start\n",
    "\n",
    "        ink_pixels = int(pred.sum())\n",
    "        total_pixels = int(pred.size)\n",
    "        self.total_ink_pixels += ink_pixels\n",
    "        self.total_pixels_processed += total_pixels\n",
    "\n",
    "        self.logger.log_metrics(\n",
    "            phase=\"infer\",\n",
    "            fragment=fragment,\n",
    "            neurons_active=self.neurons_active,\n",
    "            cpu_ns=cpu_ns,\n",
    "            ink_pixels=ink_pixels,\n",
    "            total_pixels=total_pixels,\n",
    "            merkle_prefix=digest[:16],\n",
    "        )\n",
    "        self.logger.log_event(\"INFER_DONE\", fragment=fragment)\n",
    "        return pred\n",
    "\n",
    "    def finalize(self, extra: Optional[Dict[str, object]] = None) -> Dict[str, object]:\n",
    "        cpu_total_ns = time.process_time_ns() - self.global_cpu_start_ns\n",
    "        state = {\n",
    "            \"runtime_status\": \"offline_activated\",\n",
    "            \"pipeline_status\": \"success\",\n",
    "            \"active_neurons\": self.neurons_active,\n",
    "            \"total_allocations\": self.total_allocations,\n",
    "            \"total_pixels_processed\": self.total_pixels_processed,\n",
    "            \"total_ink_pixels\": self.total_ink_pixels,\n",
    "            \"ink_ratio\": self.total_ink_pixels / self.total_pixels_processed if self.total_pixels_processed else 0.0,\n",
    "            \"qi_index_real\": self.total_pixels_processed / max(cpu_total_ns, 1),\n",
    "            \"cpu_total_ns\": cpu_total_ns,\n",
    "            \"merkle_root\": self.merkle_chain[-1] if self.merkle_chain else None,\n",
    "        }\n",
    "        if extra:\n",
    "            state.update(extra)\n",
    "        self.logger.write_state(state)\n",
    "        self.logger.log_event(\"SYSTEM_LOADED_100_PERCENT\")\n",
    "        return state\n",
    "\n",
    "\n",
    "def _to_stack(arr: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(arr)\n",
    "    if x.ndim == 2:\n",
    "        return x[np.newaxis, ...]\n",
    "    if x.ndim == 3:\n",
    "        return x\n",
    "    raise RuntimeError(f\"Unsupported TIFF shape: {x.shape}\")\n",
    "\n",
    "\n",
    "def _read_fragment_stack(fragment_dir: Path) -> np.ndarray:\n",
    "    volume_dir = fragment_dir / \"surface_volume\"\n",
    "    files = sorted(volume_dir.glob(\"*.tif\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No TIFF slices found in {volume_dir}\")\n",
    "    return np.stack([_to_stack(read_tiff_lzw_safe(p))[0] for p in files], axis=0)\n",
    "\n",
    "\n",
    "def _load_label(fragment_dir: Path) -> Optional[np.ndarray]:\n",
    "    png = fragment_dir / \"inklabels.png\"\n",
    "    if not png.exists() or iio is None:\n",
    "        return None\n",
    "    arr = np.asarray(iio.imread(str(png)))\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr[..., 0]\n",
    "    return (arr > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def _read_sample_submission_ids(path: Path) -> List[str]:\n",
    "    ids: List[str] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        cols = set(reader.fieldnames or [])\n",
    "        id_col = \"Id\" if \"Id\" in cols else (\"id\" if \"id\" in cols else None)\n",
    "        if id_col is None:\n",
    "            return ids\n",
    "        for row in reader:\n",
    "            v = str(row[id_col]).strip()\n",
    "            if v:\n",
    "                ids.append(v)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def _dataset_inventory(root: Path) -> Dict[str, object]:\n",
    "    if not root.exists():\n",
    "        return {\"root\": str(root), \"exists\": False}\n",
    "\n",
    "    all_files = [p for p in root.rglob(\"*\") if p.is_file()]\n",
    "    suffix_stats: Dict[str, int] = {}\n",
    "    folders = set()\n",
    "    for p in all_files:\n",
    "        suffix = p.suffix.lower() or \"<noext>\"\n",
    "        suffix_stats[suffix] = suffix_stats.get(suffix, 0) + 1\n",
    "        folders.add(str(p.parent.relative_to(root)))\n",
    "\n",
    "    return {\n",
    "        \"root\": str(root),\n",
    "        \"exists\": True,\n",
    "        \"total_assets\": len(all_files),\n",
    "        \"folders\": sorted(folders),\n",
    "        \"suffix_stats\": suffix_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "def _discover_layout(root: Path) -> Tuple[str, List[Path], List[Path]]:\n",
    "    test_images = root / \"test_images\"\n",
    "    if test_images.exists():\n",
    "        train_images = root / \"train_images\"\n",
    "        train = sorted(train_images.rglob(\"*.tif\")) if train_images.exists() else []\n",
    "        test = sorted(test_images.rglob(\"*.tif\"))\n",
    "        if test:\n",
    "            return \"competition_test_images\", train, test\n",
    "\n",
    "    train_dir = root / \"train\"\n",
    "    test_dir = root / \"test\"\n",
    "    if train_dir.exists() or test_dir.exists():\n",
    "        train = sorted([p for p in train_dir.iterdir() if p.is_dir() and (p / \"surface_volume\").exists()]) if train_dir.exists() else []\n",
    "        test = sorted([p for p in test_dir.iterdir() if p.is_dir() and (p / \"surface_volume\").exists()]) if test_dir.exists() else []\n",
    "        if test:\n",
    "            return \"fragment_dirs\", train, test\n",
    "\n",
    "    train_legacy = sorted((root / \"train_images\").glob(\"*.tif\")) if (root / \"train_images\").exists() else []\n",
    "    test_legacy = sorted((root / \"test_images\").glob(\"*.tif\")) if (root / \"test_images\").exists() else []\n",
    "    if test_legacy:\n",
    "        return \"legacy_tif_files\", train_legacy, test_legacy\n",
    "\n",
    "    return \"empty\", [], []\n",
    "\n",
    "\n",
    "def _candidate_roots(primary_root: Path) -> List[Path]:\n",
    "    candidates: List[Path] = []\n",
    "\n",
    "    def add(p: Path) -> None:\n",
    "        if p.exists() and p not in candidates:\n",
    "            candidates.append(p)\n",
    "\n",
    "    add(primary_root)\n",
    "    add(Path(\"/kaggle/input/vesuvius-challenge-ink-detection\"))\n",
    "    add(Path(\"/kaggle/input/vesuvius-challenge-surface-detection\"))\n",
    "    add(Path(\"/kaggle/input/competitions/vesuvius-challenge-surface-detection\"))\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if kaggle_input.exists():\n",
    "        for p in sorted(kaggle_input.iterdir()):\n",
    "            if p.is_dir() and \"vesuvius\" in p.name.lower():\n",
    "                add(p)\n",
    "\n",
    "    competitions = Path(\"/kaggle/input/competitions\")\n",
    "    if competitions.exists():\n",
    "        for p in sorted(competitions.iterdir()):\n",
    "            if p.is_dir() and \"vesuvius\" in p.name.lower():\n",
    "                add(p)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def _resolve_root(primary_root: Path, auto_discover: bool) -> Tuple[Path, str, List[Dict[str, object]]]:\n",
    "    roots = _candidate_roots(primary_root) if auto_discover else [primary_root]\n",
    "    attempts: List[Dict[str, object]] = []\n",
    "\n",
    "    for root in roots:\n",
    "        mode, train, test = _discover_layout(root)\n",
    "        attempts.append({\"root\": str(root), \"mode\": mode, \"train\": len(train), \"test\": len(test)})\n",
    "        if test:\n",
    "            return root, mode, attempts\n",
    "\n",
    "    return primary_root, \"empty\", attempts\n",
    "\n",
    "\n",
    "def _label_candidates_for_train_tif(item: Path) -> List[Path]:\n",
    "    root = item.parent.parent\n",
    "    return [\n",
    "        root / \"train_labels\" / item.name,\n",
    "        root / \"train_labels\" / item.with_suffix(\".png\").name,\n",
    "    ]\n",
    "\n",
    "\n",
    "def _quick_has_label(item: Path, mode: str) -> bool:\n",
    "    if mode == \"fragment_dirs\":\n",
    "        return (item / \"inklabels.png\").exists()\n",
    "    return any(c.exists() for c in _label_candidates_for_train_tif(item))\n",
    "\n",
    "\n",
    "def _load_train_item(item: Path, mode: str) -> Tuple[np.ndarray, Optional[np.ndarray], str]:\n",
    "    if mode == \"fragment_dirs\":\n",
    "        stack = _read_fragment_stack(item)\n",
    "        labels = _load_label(item)\n",
    "        return stack, labels, item.name\n",
    "\n",
    "    stack = _to_stack(read_tiff_lzw_safe(item))\n",
    "\n",
    "    labels = None\n",
    "    labels_tif, labels_png = _label_candidates_for_train_tif(item)\n",
    "    if labels_tif.exists():\n",
    "        l = read_tiff_lzw_safe(labels_tif)\n",
    "        labels = (l[0] > 0).astype(np.uint8) if l.ndim == 3 else (l > 0).astype(np.uint8)\n",
    "    elif labels_png.exists() and iio is not None:\n",
    "        l = np.asarray(iio.imread(str(labels_png)))\n",
    "        labels = (l[..., 0] > 0).astype(np.uint8) if l.ndim == 3 else (l > 0).astype(np.uint8)\n",
    "\n",
    "    return stack, labels, item.stem\n",
    "\n",
    "\n",
    "def _load_test_item(item: Path, mode: str) -> Tuple[np.ndarray, str]:\n",
    "    if mode == \"fragment_dirs\":\n",
    "        return _read_fragment_stack(item), f\"{item.name}.tif\"\n",
    "    return _to_stack(read_tiff_lzw_safe(item)), item.name\n",
    "\n",
    "\n",
    "def _write_submission_csv(out_csv: Path, sample_csv: Path, predictions: Dict[str, np.ndarray]) -> Optional[str]:\n",
    "    ids = _read_sample_submission_ids(sample_csv)\n",
    "    if not ids:\n",
    "        return None\n",
    "\n",
    "    flat = np.concatenate([predictions[k].reshape(-1).astype(np.uint8) for k in sorted(predictions)])\n",
    "    n = min(len(ids), len(flat))\n",
    "\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"Id\", \"Predicted\"])\n",
    "        for i in range(n):\n",
    "            w.writerow([ids[i], int(flat[i])])\n",
    "    return str(out_csv)\n",
    "\n",
    "\n",
    "\n",
    "def _apply_binary_mode(mask: np.ndarray, binary_mode: str = \"0_1\") -> np.ndarray:\n",
    "    m01 = (np.asarray(mask) > 0).astype(np.uint8)\n",
    "    if binary_mode == \"0_255\":\n",
    "        return (m01 * 255).astype(np.uint8)\n",
    "    if binary_mode == \"0_1\":\n",
    "        return m01\n",
    "    raise RuntimeError(f\"Invalid binary_mode: {binary_mode}\")\n",
    "\n",
    "\n",
    "def _write_submission_zip(\n",
    "    out_zip: Path,\n",
    "    predictions: Dict[str, np.ndarray],\n",
    "    expected_meta: Optional[Dict[str, Tuple[int, int, int]]] = None,\n",
    "    binary_mode: str = \"0_1\",\n",
    ") -> str:\n",
    "    out_zip.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_dir = out_zip.parent / \"submission_masks\"\n",
    "    tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    names: List[str] = []\n",
    "    for tif_name, mask in predictions.items():\n",
    "        # Canonical binary domain with configurable output encoding.\n",
    "        mask_bin = _apply_binary_mode(mask, binary_mode=binary_mode)\n",
    "        if expected_meta and tif_name in expected_meta:\n",
    "            ez, eh, ew = expected_meta[tif_name]\n",
    "            if mask_bin.ndim == 2:\n",
    "                mask_bin = np.repeat(mask_bin[None, :, :], ez, axis=0)\n",
    "            elif mask_bin.ndim == 3 and mask_bin.shape[0] != ez:\n",
    "                if mask_bin.shape[0] == 1:\n",
    "                    mask_bin = np.repeat(mask_bin, ez, axis=0)\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Mask depth mismatch for {tif_name}: got {mask_bin.shape[0]}, expected {ez}\")\n",
    "            if mask_bin.shape[1:] != (eh, ew):\n",
    "                raise RuntimeError(f\"Mask shape mismatch for {tif_name}: got {mask_bin.shape}, expected {(ez, eh, ew)}\")\n",
    "\n",
    "        p = tmp_dir / tif_name\n",
    "        # Write as multi-page TIFF to match successful scored submissions.\n",
    "        tifffile.imwrite(str(p), mask_bin, compression=\"LZW\")\n",
    "        names.append(tif_name)\n",
    "\n",
    "    with zipfile.ZipFile(out_zip, \"w\", compression=zipfile.ZIP_STORED) as zf:\n",
    "        for name in sorted(names):\n",
    "            zf.write(tmp_dir / name, arcname=name)\n",
    "\n",
    "    return str(out_zip)\n",
    "\n",
    "\n",
    "def _validate_zip_content_binary_01(\n",
    "    out_zip: Path,\n",
    "    expected_meta: Dict[str, Tuple[int, int, int]],\n",
    "    allowed_values: Tuple[int, ...] = (0, 1),\n",
    ") -> Dict[str, object]:\n",
    "    issues: List[str] = []\n",
    "    with zipfile.ZipFile(out_zip, \"r\") as zf:\n",
    "        for name in zf.namelist():\n",
    "            if not name.lower().endswith('.tif'):\n",
    "                continue\n",
    "            data = zf.read(name)\n",
    "            try:\n",
    "                arr = tifffile.imread(io.BytesIO(data))\n",
    "            except Exception as exc:  # pragma: no cover\n",
    "                issues.append(f\"decode_failed:{name}:{exc}\")\n",
    "                continue\n",
    "\n",
    "            arr = np.asarray(arr)\n",
    "            base = Path(name).name\n",
    "            if arr.ndim == 2:\n",
    "                arr = arr[None, :, :]\n",
    "            if arr.ndim != 3:\n",
    "                issues.append(f\"invalid_ndim:{name}:{arr.shape}\")\n",
    "                continue\n",
    "\n",
    "            if base in expected_meta and tuple(arr.shape) != tuple(expected_meta[base]):\n",
    "                issues.append(f\"shape_mismatch:{base}:{arr.shape}!={expected_meta[base]}\")\n",
    "\n",
    "            uniq = np.unique(arr)\n",
    "            if not set(int(x) for x in uniq.tolist()).issubset(set(allowed_values)):\n",
    "                issues.append(f\"invalid_values:{base}:{uniq[:8].tolist()}\")\n",
    "\n",
    "    return {\"status\": \"ok\" if not issues else \"invalid\", \"issues\": issues}\n",
    "\n",
    "\n",
    "def _validate_zip(out_zip: Path, expected_tif_names: Sequence[str]) -> Dict[str, object]:\n",
    "    with zipfile.ZipFile(out_zip, \"r\") as zf:\n",
    "        got = sorted([Path(n).name for n in zf.namelist() if n.lower().endswith(\".tif\")])\n",
    "    exp = sorted(expected_tif_names)\n",
    "    return {\n",
    "        \"status\": \"ok\" if got == exp else \"mismatch\",\n",
    "        \"expected_test_files\": len(exp),\n",
    "        \"submission_tif_files\": len(got),\n",
    "        \"missing\": sorted(set(exp) - set(got)),\n",
    "        \"unexpected\": sorted(set(got) - set(exp)),\n",
    "    }\n",
    "\n",
    "\n",
    "def _publish_submission_aliases(primary_zip: Path, work_root: Path) -> List[str]:\n",
    "    aliases = [\n",
    "        Path(\"/kaggle/working/submission.zip\"),\n",
    "        Path(\"/kaggle/working/nx46_vesuvius/submission.zip\"),\n",
    "        Path(\"submission.zip\"),\n",
    "        Path(\"nx46_vesuvius/submission.zip\"),\n",
    "        work_root / \"submission.zip\",\n",
    "    ]\n",
    "\n",
    "    published: List[str] = []\n",
    "    for alias in aliases:\n",
    "        if alias.resolve() == primary_zip.resolve():\n",
    "            published.append(str(alias))\n",
    "            continue\n",
    "        alias.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copyfile(primary_zip, alias)\n",
    "        published.append(str(alias))\n",
    "    return sorted(set(published))\n",
    "\n",
    "\n",
    "def _calibrate_threshold_from_unlabeled(\n",
    "    model: NX46AGNNVesuvius,\n",
    "    test_items: Sequence[Path],\n",
    "    mode: str,\n",
    "    q: float,\n",
    ") -> float:\n",
    "    sampled = list(test_items[: min(2, len(test_items))])\n",
    "    if not sampled:\n",
    "        return 0.5\n",
    "\n",
    "    q = min(0.999, max(0.50, q))\n",
    "    per_item: List[float] = []\n",
    "    for item in sampled:\n",
    "        stack, tif_name = _load_test_item(item, mode)\n",
    "        model.slab_allocate(stack, phase=\"train_fallback_probe\")\n",
    "        model._track_bits(Path(tif_name).stem, stack)\n",
    "        score = model.score_projection(stack)\n",
    "        digest = model._merkle_sign(f\"probe_{Path(tif_name).stem}\", score)\n",
    "        model.logger.log_metrics(\n",
    "            phase=\"train_fallback_probe\",\n",
    "            fragment=Path(tif_name).stem,\n",
    "            neurons_active=model.neurons_active,\n",
    "            cpu_ns=0,\n",
    "            ink_pixels=int((score >= np.quantile(score, q)).sum()),\n",
    "            total_pixels=int(score.size),\n",
    "            merkle_prefix=digest[:16],\n",
    "        )\n",
    "        per_item.append(float(np.quantile(score, q)))\n",
    "\n",
    "    return float(np.median(np.asarray(per_item, dtype=np.float32)))\n",
    "\n",
    "\n",
    "def _material_proxy_map(stack: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Generate a lightweight 4-class proxy map from native volumetric signals.\n",
    "\n",
    "    Classes: 0=background, 1=fiber_proxy, 2=ink_proxy, 3=artifact_proxy.\n",
    "    \"\"\"\n",
    "    x = stack.astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "\n",
    "    mid = np.mean(x, axis=0)\n",
    "    grad = np.mean(np.abs(np.diff(x, axis=0, prepend=x[:1])), axis=0)\n",
    "\n",
    "    q_mid_lo, q_mid_hi = float(np.quantile(mid, 0.35)), float(np.quantile(mid, 0.80))\n",
    "    q_grad_hi = float(np.quantile(grad, 0.90))\n",
    "\n",
    "    out = np.zeros(mid.shape, dtype=np.uint8)\n",
    "    out[(mid >= q_mid_lo) & (mid < q_mid_hi)] = 1\n",
    "    out[mid >= q_mid_hi] = 2\n",
    "    out[grad >= q_grad_hi] = 3\n",
    "    return out\n",
    "\n",
    "\n",
    "def _write_material_outputs(work: Path, material_maps: Dict[str, np.ndarray]) -> Dict[str, object]:\n",
    "    mat_dir = work / \"material_maps\"\n",
    "    mat_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    summary: Dict[str, Dict[str, int]] = {}\n",
    "    for tif_name, cls_map in material_maps.items():\n",
    "        out_tif = mat_dir / tif_name\n",
    "        tifffile.imwrite(str(out_tif), cls_map[np.newaxis, ...].astype(np.uint8), compression=\"LZW\")\n",
    "\n",
    "        cnt = {str(i): int((cls_map == i).sum()) for i in range(4)}\n",
    "        summary[tif_name] = cnt\n",
    "\n",
    "    manifest = {\n",
    "        \"material_classes\": {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"fiber_proxy\",\n",
    "            \"2\": \"ink_proxy\",\n",
    "            \"3\": \"artifact_proxy\",\n",
    "        },\n",
    "        \"files\": summary,\n",
    "    }\n",
    "    (work / \"native_training_manifest.json\").write_text(json.dumps(manifest, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _load_a2z_manifest() -> Optional[Dict[str, object]]:\n",
    "    candidates = [\n",
    "        Path('/workspace/Lumvorax/RAPPORT-VESUVIUS/a2z_audit_manifest.json'),\n",
    "        Path('RAPPORT-VESUVIUS/a2z_audit_manifest.json'),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            try:\n",
    "                return json.loads(c.read_text(encoding='utf-8'))\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_pipeline(cfg: NX46Config) -> Dict[str, object]:\n",
    "    if os.environ.get(\"NX46_DRY_RUN\", \"0\") == \"1\":\n",
    "        return {\n",
    "            \"status\": \"dry_run\",\n",
    "            \"run_tag\": cfg.run_tag,\n",
    "            \"threshold_quantile\": cfg.threshold_quantile,\n",
    "            \"score_blend_3d_weight\": cfg.score_blend_3d_weight,\n",
    "            \"z_smoothing_radius\": cfg.z_smoothing_radius,\n",
    "            \"use_3d_native_path\": cfg.use_3d_native_path,\n",
    "            \"use_25d_path\": cfg.use_25d_path,\n",
    "        }\n",
    "    configured_root = Path(cfg.data_root)\n",
    "    work = Path(cfg.work_root)\n",
    "    logs_root = work / \"logs\"\n",
    "    logs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    roadmap = ProgressRoadmap()\n",
    "    nx46 = NX46AGNNVesuvius(cfg, logs_root)\n",
    "\n",
    "    a2z_manifest = _load_a2z_manifest()\n",
    "    if a2z_manifest is not None:\n",
    "        nx46.logger.log_event(\"A2Z_AUDIT_MANIFEST_LOADED\", files_scanned=a2z_manifest.get(\"files_scanned\"), lines_scanned=a2z_manifest.get(\"lines_scanned\"))\n",
    "\n",
    "    effective_root, mode, attempts = _resolve_root(configured_root, cfg.auto_discover_data_root)\n",
    "    mode, train_items, test_items = _discover_layout(effective_root)\n",
    "\n",
    "    inventory = _dataset_inventory(effective_root)\n",
    "    nx46.logger.write_discovery_inventory({\"attempts\": attempts, \"inventory\": inventory})\n",
    "    nx46.logger.log_event(\"DATASET_DISCOVERY\", mode=mode, configured_root=str(configured_root), effective_root=str(effective_root), attempts=attempts)\n",
    "    roadmap.update(\"audit_discovery\", 100.0)\n",
    "\n",
    "    if not test_items:\n",
    "        nx46.logger.log_event(\"NO_TEST_INPUTS_FOUND\", attempts=attempts)\n",
    "        raise RuntimeError(\n",
    "            \"No test inputs found. Checked roots: \"\n",
    "            + \", \".join([a[\"root\"] for a in attempts])\n",
    "            + \". Configure NX46_DATA_ROOT to the dataset root containing test_images or test/<fragment>.\"\n",
    "        )\n",
    "\n",
    "    usable_train_items = [p for p in train_items if _quick_has_label(p, mode)]\n",
    "    skipped_no_label = max(0, len(train_items) - len(usable_train_items))\n",
    "    if cfg.max_train_items > 0:\n",
    "        usable_train_items = usable_train_items[: cfg.max_train_items]\n",
    "\n",
    "    thresholds: List[float] = []\n",
    "    total_train = max(1, len(usable_train_items))\n",
    "    for idx, item in enumerate(usable_train_items, start=1):\n",
    "        roadmap.update(\"train_thresholds\", idx * 100.0 / total_train)\n",
    "        nx46.logger.log_event(\"PROGRESS_TRAIN\", index=idx, total=len(usable_train_items))\n",
    "        stack, labels, name = _load_train_item(item, mode)\n",
    "        if labels is None:\n",
    "            continue\n",
    "        if labels.shape != stack.shape[1:]:\n",
    "            h = min(labels.shape[0], stack.shape[1])\n",
    "            w = min(labels.shape[1], stack.shape[2])\n",
    "            labels = labels[:h, :w]\n",
    "            stack = stack[:, :h, :w]\n",
    "        thresholds.append(nx46.train_threshold(stack, labels, name))\n",
    "\n",
    "    training_strategy = \"supervised\"\n",
    "    if thresholds:\n",
    "        threshold = float(np.median(np.asarray(thresholds, dtype=np.float32)))\n",
    "    else:\n",
    "        threshold = _calibrate_threshold_from_unlabeled(nx46, test_items, mode, cfg.threshold_quantile)\n",
    "        training_strategy = \"fallback_quantile_probe\"\n",
    "\n",
    "    nx46.logger.log_event(\n",
    "        \"THRESHOLD_SELECTED\",\n",
    "        threshold=threshold,\n",
    "        trained_samples=len(thresholds),\n",
    "        training_strategy=training_strategy,\n",
    "        skipped_no_label=skipped_no_label,\n",
    "        max_train_items=cfg.max_train_items,\n",
    "    )\n",
    "\n",
    "    predictions: Dict[str, np.ndarray] = {}\n",
    "    expected_names: List[str] = []\n",
    "    expected_meta: Dict[str, Tuple[int, int, int]] = {}\n",
    "    material_maps: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    total_test = max(1, len(test_items))\n",
    "    for idx, item in enumerate(test_items, start=1):\n",
    "        roadmap.update(\"infer_predictions\", idx * 100.0 / total_test)\n",
    "        nx46.logger.log_event(\"PROGRESS_TEST\", index=idx, total=len(test_items))\n",
    "        stack, tif_name = _load_test_item(item, mode)\n",
    "        pred = nx46.infer_mask(stack, threshold, Path(tif_name).stem)\n",
    "        predictions[tif_name] = pred\n",
    "        expected_meta[tif_name] = (int(stack.shape[0]), int(stack.shape[1]), int(stack.shape[2]))\n",
    "        if cfg.enable_material_head:\n",
    "            material_maps[tif_name] = _material_proxy_map(stack)\n",
    "        expected_names.append(tif_name)\n",
    "\n",
    "    roadmap.update(\"package_submission\", 20.0)\n",
    "\n",
    "    sample_csv_candidates = [\n",
    "        effective_root / \"sample_submission.csv\",\n",
    "        Path(\"/kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv\"),\n",
    "        Path(\"/kaggle/input/vesuvius-challenge-surface-detection/sample_submission.csv\"),\n",
    "        Path(\"/kaggle/input/competitions/vesuvius-challenge-surface-detection/sample_submission.csv\"),\n",
    "    ]\n",
    "    sample_csv = next((p for p in sample_csv_candidates if p.exists()), None)\n",
    "\n",
    "    submission_csv: Optional[str] = None\n",
    "    if cfg.write_submission_csv and sample_csv is not None:\n",
    "        submission_csv = _write_submission_csv(work / \"submission.csv\", sample_csv, predictions)\n",
    "\n",
    "    binary_mode = cfg.binary_mode if cfg.binary_mode in {\"0_1\", \"0_255\"} else \"0_1\"\n",
    "    primary_zip = Path(cfg.kaggle_submission_root) / \"submission.zip\"\n",
    "    submission_zip = _write_submission_zip(primary_zip, predictions, expected_meta=expected_meta, binary_mode=binary_mode)\n",
    "    submission_zip_aliases = _publish_submission_aliases(Path(submission_zip), work)\n",
    "    validation = _validate_zip(Path(submission_zip), expected_names)\n",
    "    allowed_values = (0, 1) if binary_mode == \"0_1\" else (0, 255)\n",
    "    content_validation = _validate_zip_content_binary_01(Path(submission_zip), expected_meta, allowed_values=allowed_values)\n",
    "    nx46.logger.log_event(\"COMPETITION_RULES_VALIDATION\", **validation)\n",
    "    nx46.logger.log_event(\"SUBMISSION_CONTENT_VALIDATION\", **content_validation)\n",
    "    nx46.logger.log_event(\"SUBMISSION_PATHS_PUBLISHED\", primary=submission_zip, aliases=submission_zip_aliases)\n",
    "    roadmap.update(\"package_submission\", 100.0)\n",
    "\n",
    "    if cfg.strict_competition_mode and (validation[\"status\"] != \"ok\" or content_validation[\"status\"] != \"ok\"):\n",
    "        raise RuntimeError(f\"Submission validation failed: zip={validation}, content={content_validation}\")\n",
    "\n",
    "    material_manifest: Optional[Dict[str, object]] = None\n",
    "    if cfg.enable_material_head and cfg.save_material_outputs and material_maps:\n",
    "        material_manifest = _write_material_outputs(work, material_maps)\n",
    "        nx46.logger.log_event(\"MATERIAL_HEAD_EXPORT\", files=len(material_maps))\n",
    "\n",
    "    roadmap.update(\"finalize_forensics\", 100.0)\n",
    "    result = nx46.finalize(\n",
    "        {\n",
    "            \"status\": \"100%_OFFLINE_ACTIVATED\",\n",
    "            \"layout_detected\": mode,\n",
    "            \"configured_data_root\": str(configured_root),\n",
    "            \"effective_data_root\": str(effective_root),\n",
    "            \"discovery_attempts\": attempts,\n",
    "            \"train_items_total\": len(train_items),\n",
    "            \"train_items_with_labels\": len(usable_train_items),\n",
    "            \"train_items_skipped_no_label\": skipped_no_label,\n",
    "            \"train_items\": [p.name for p in train_items],\n",
    "            \"test_items\": [p.name for p in test_items],\n",
    "            \"train_threshold\": threshold,\n",
    "            \"training_strategy\": training_strategy,\n",
    "            \"scoring_mode\": {\"use_3d_native_path\": cfg.use_3d_native_path, \"use_25d_path\": cfg.use_25d_path, \"score_blend_3d_weight\": cfg.score_blend_3d_weight},\n",
    "            \"submission_csv\": submission_csv,\n",
    "            \"submission_zip\": submission_zip,\n",
    "            \"submission_zip_aliases\": submission_zip_aliases,\n",
    "            \"zip_members_validated\": validation[\"status\"] == \"ok\",\n",
    "            \"zip_missing\": validation[\"missing\"],\n",
    "            \"zip_extra\": validation[\"unexpected\"],\n",
    "            \"competition_rules_validation\": validation,\n",
    "            \"submission_content_validation\": content_validation,\n",
    "            \"submission_format_profile\": f\"kaggle_v8_5_style_zip_lzw_3d_uint8_{binary_mode}\",\n",
    "            \"binary_mode\": binary_mode,\n",
    "            \"material_head_enabled\": cfg.enable_material_head,\n",
    "            \"material_outputs_files\": len(material_maps),\n",
    "            \"native_training_manifest\": str(work / \"native_training_manifest.json\") if material_manifest else None,\n",
    "            \"a2z_audit_manifest_loaded\": a2z_manifest is not None,\n",
    "            \"a2z_files_scanned\": (a2z_manifest or {}).get(\"files_scanned\"),\n",
    "            \"a2z_lines_scanned\": (a2z_manifest or {}).get(\"lines_scanned\"),\n",
    "            \"roadmap_percent\": roadmap.as_dict(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    (logs_root / \"RkF4XakI.txt\").write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    (logs_root / \"UJxLRsEE.txt\").write_text(json.dumps(validation, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    nx46.logger.log_event(\"EXEC_COMPLETE\", submission=submission_zip)\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = NX46Config(\n",
    "        data_root=os.environ.get(\"NX46_DATA_ROOT\", NX46Config.data_root),\n",
    "        work_root=os.environ.get(\"NX46_WORK_ROOT\", NX46Config.work_root),\n",
    "        kaggle_submission_root=os.environ.get(\"NX46_KAGGLE_SUBMISSION_ROOT\", NX46Config.kaggle_submission_root),\n",
    "        max_train_items=int(os.environ.get(\"NX46_MAX_TRAIN_ITEMS\", str(NX46Config.max_train_items))),\n",
    "        threshold_quantile=float(os.environ.get(\"NX46_THRESHOLD_QUANTILE\", str(NX46Config.threshold_quantile))),\n",
    "        enable_material_head=os.environ.get(\"NX46_ENABLE_MATERIAL_HEAD\", \"1\") != \"0\",\n",
    "        save_material_outputs=os.environ.get(\"NX46_SAVE_MATERIAL_OUTPUTS\", \"1\") != \"0\",\n",
    "        use_3d_native_path=os.environ.get(\"NX46_USE_3D_NATIVE_PATH\", \"1\") != \"0\",\n",
    "        use_25d_path=os.environ.get(\"NX46_USE_25D_PATH\", \"0\") != \"0\",\n",
    "        score_blend_3d_weight=float(os.environ.get(\"NX46_SCORE_BLEND_3D_WEIGHT\", str(NX46Config.score_blend_3d_weight))),\n",
    "        z_smoothing_radius=int(os.environ.get(\"NX46_Z_SMOOTHING_RADIUS\", str(NX46Config.z_smoothing_radius))),\n",
    "        write_submission_csv=os.environ.get(\"NX46_WRITE_SUBMISSION_CSV\", \"0\") == \"1\",\n",
    "        binary_mode=os.environ.get(\"NX46_BINARY_MODE\", \"0_1\").strip().lower(),\n",
    "        run_tag=os.environ.get(\"NX46_RUN_TAG\", NX46Config.run_tag),\n",
    "    )\n",
    "    out = run_pipeline(config)\n",
    "    print(json.dumps(out, indent=2, ensure_ascii=False))\n",
    "    print(f\"READY: {out['submission_zip']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloc source intégré: V7.6\n",
    "Source: `RAPPORT-VESUVIUS/src_vesuvius/nx46_vesuvius_core_kaggle_ready_v7.6/nx46-vesuvius-core-kaggle-ready-v7-6.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NX-46 Vesuvius Kaggle-ready v7.6 (offline-first, forensic, regression-safe).\n",
    "\n",
    "V7.6 objectives:\n",
    "- Keep validated v3/v4/v5 compatibility outputs (submission.zip + forensic logs + compatibility txt files).\n",
    "- Add V6 material-head outputs (ink/fiber/background/artifact proxies) from native signals.\n",
    "- Emit native training manifest and richer forensic evidence for V6 roadmap compliance.\n",
    "- Preserve strict Kaggle compliance, offline dependency bootstrap, and 0/1 mask outputs (competitor-aligned).\n",
    "- Enforce scorer-safe TIFF submission format (3D multi-page, exact Z/H/W shape, binary value check).\n",
    "- Activate high-quality native 3D scoring path by default; keep 2.5D path optional/off by default.\n",
    "- Match successful notebook submission conventions exactly: primary zip at /kaggle/working/submission.zip, ZIP_STORED members, LZW multi-page TIFF uint8.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import importlib\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "from dataclasses import dataclass\n",
    "from hashlib import sha512\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "DRY_RUN_FLAG = os.environ.get(\"NX46_DRY_RUN\", \"0\") == \"1\"\n",
    "if DRY_RUN_FLAG and __name__ == \"__main__\":\n",
    "    print(json.dumps({\n",
    "        \"status\": \"dry_run\",\n",
    "        \"run_tag\": os.environ.get(\"NX46_RUN_TAG\", \"v7.6-dry\"),\n",
    "        \"threshold_quantile\": float(os.environ.get(\"NX46_THRESHOLD_QUANTILE\", \"0.985\")),\n",
    "        \"score_blend_3d_weight\": float(os.environ.get(\"NX46_SCORE_BLEND_3D_WEIGHT\", \"0.78\")),\n",
    "        \"z_smoothing_radius\": int(os.environ.get(\"NX46_Z_SMOOTHING_RADIUS\", \"2\")),\n",
    "    }, ensure_ascii=False))\n",
    "    raise SystemExit(0)\n",
    "\n",
    "\n",
    "def install_offline(package_name: str) -> None:\n",
    "    exact_wheel_dir = Path(\"/kaggle/input/datasets/ndarray2000/nx47-dependencies\")\n",
    "    fallback_wheel_dir = Path(\"/kaggle/input/nx47-dependencies\")\n",
    "    lum_wheel_dir = Path(\"/kaggle/input/lum-vorax-dependencies\")\n",
    "    lum_wheel_dir_alt = Path(\"/kaggle/input/lumvorax-dependencies\")\n",
    "\n",
    "    exact_wheels = {\n",
    "        \"imagecodecs\": exact_wheel_dir / \"imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n",
    "        \"numpy\": exact_wheel_dir / \"numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n",
    "        \"tifffile\": exact_wheel_dir / \"tifffile-2026.1.28-py3-none-any.whl\",\n",
    "    }\n",
    "\n",
    "    if package_name == \"numpy\" and importlib.util.find_spec(\"numpy\") is not None:\n",
    "        return\n",
    "\n",
    "    if package_name in exact_wheels and exact_wheels[package_name].exists():\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", str(exact_wheels[package_name])])\n",
    "            return\n",
    "        except subprocess.CalledProcessError:\n",
    "            pass\n",
    "\n",
    "    for wheel_dir in (exact_wheel_dir, fallback_wheel_dir, lum_wheel_dir, lum_wheel_dir_alt):\n",
    "        if wheel_dir.exists():\n",
    "            subprocess.check_call(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", f\"--find-links={wheel_dir}\", package_name]\n",
    "            )\n",
    "            return\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Offline dependency directory not found for {package_name}. \"\n",
    "        f\"Checked: {exact_wheel_dir} and {fallback_wheel_dir}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def bootstrap_dependencies_fail_fast() -> None:\n",
    "    install_offline(\"numpy\")\n",
    "    install_offline(\"imagecodecs\")\n",
    "    install_offline(\"tifffile\")\n",
    "\n",
    "\n",
    "bootstrap_dependencies_fail_fast()\n",
    "\n",
    "import numpy as np  # noqa: E402\n",
    "import tifffile  # noqa: E402\n",
    "import imageio.v3 as iio  # noqa: E402\n",
    "\n",
    "\n",
    "def ensure_imagecodecs() -> bool:\n",
    "    if importlib.util.find_spec(\"imagecodecs\") is not None:\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        install_offline(\"imagecodecs\")\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "    if importlib.util.find_spec(\"imagecodecs\") is None:\n",
    "        return False\n",
    "\n",
    "    global tifffile\n",
    "    tifffile = importlib.reload(tifffile)\n",
    "    return True\n",
    "\n",
    "\n",
    "def read_tiff_lzw_safe(path: Path) -> np.ndarray:\n",
    "    try:\n",
    "        return np.asarray(tifffile.imread(path))\n",
    "    except ValueError as exc:\n",
    "        if \"requires the 'imagecodecs' package\" not in str(exc):\n",
    "            raise\n",
    "\n",
    "    ensure_imagecodecs()\n",
    "    try:\n",
    "        return np.asarray(tifffile.imread(path))\n",
    "    except ValueError as exc:\n",
    "        if \"requires the 'imagecodecs' package\" not in str(exc):\n",
    "            raise\n",
    "\n",
    "    if importlib.util.find_spec(\"PIL\") is None:\n",
    "        raise RuntimeError(\"LZW TIFF read failed and Pillow fallback unavailable\")\n",
    "\n",
    "    from PIL import Image, ImageSequence\n",
    "\n",
    "    with Image.open(path) as img:\n",
    "        frames = [np.array(frame, dtype=np.float32) for frame in ImageSequence.Iterator(img)]\n",
    "    if not frames:\n",
    "        raise RuntimeError(f\"No frames decoded from TIFF: {path}\")\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NX46Config:\n",
    "    data_root: str = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n",
    "    work_root: str = \"/kaggle/working/nx46_vesuvius\"\n",
    "    kaggle_submission_root: str = \"/kaggle/working\"\n",
    "    seed: int = 46\n",
    "    bit_capture_bytes: int = 256\n",
    "    threshold_quantile: float = 0.985\n",
    "    slab_min_neurons: int = 128\n",
    "    auto_discover_data_root: bool = True\n",
    "    strict_competition_mode: bool = True\n",
    "    max_train_items: int = 512\n",
    "    enable_material_head: bool = True\n",
    "    save_material_outputs: bool = True\n",
    "    use_3d_native_path: bool = True\n",
    "    use_25d_path: bool = False\n",
    "    score_blend_3d_weight: float = 0.78\n",
    "    z_smoothing_radius: int = 2\n",
    "    write_submission_csv: bool = False\n",
    "    binary_mode: str = \"0_1\"\n",
    "    run_tag: str = \"v7.6-default\"\n",
    "\n",
    "\n",
    "class ProgressRoadmap:\n",
    "    def __init__(self) -> None:\n",
    "        self.steps: Dict[str, float] = {\n",
    "            \"audit_discovery\": 0.0,\n",
    "            \"train_thresholds\": 0.0,\n",
    "            \"infer_predictions\": 0.0,\n",
    "            \"package_submission\": 0.0,\n",
    "            \"finalize_forensics\": 0.0,\n",
    "        }\n",
    "\n",
    "    def update(self, step: str, pct: float) -> None:\n",
    "        self.steps[step] = max(0.0, min(100.0, float(pct)))\n",
    "        print(f\"[ROADMAP] {step}: {self.steps[step]:.1f}%\")\n",
    "\n",
    "    def as_dict(self) -> Dict[str, float]:\n",
    "        return dict(self.steps)\n",
    "\n",
    "\n",
    "class HFBL360Logger:\n",
    "    def __init__(self, root: Path) -> None:\n",
    "        self.root = root\n",
    "        self.root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.forensic_log = root / \"forensic_ultra.log\"\n",
    "        self.core_log = root / \"nx-46-vesuvius-core.log\"\n",
    "        self.kaggle_log = root / \"nx46-vesuvius-core-kaggle-ready.log\"\n",
    "        self.metrics_csv = root / \"metrics.csv\"\n",
    "        self.state_json = root / \"state.json\"\n",
    "        self.bit_log = root / \"bit_capture.log\"\n",
    "        self.merkle_log = root / \"merkle_chain.log\"\n",
    "        self.discovery_json = root / \"dataset_discovery_inventory.json\"\n",
    "\n",
    "        with self.metrics_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow(\n",
    "                [\n",
    "                    \"timestamp_ns\",\n",
    "                    \"phase\",\n",
    "                    \"fragment\",\n",
    "                    \"neurons_active\",\n",
    "                    \"cpu_ns\",\n",
    "                    \"ink_pixels\",\n",
    "                    \"total_pixels\",\n",
    "                    \"ink_ratio\",\n",
    "                    \"merkle_prefix\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def _append(self, line: str) -> None:\n",
    "        for p in (self.forensic_log, self.core_log, self.kaggle_log):\n",
    "            with p.open(\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "    def log_event(self, event: str, **data: object) -> None:\n",
    "        payload = json.dumps(data, ensure_ascii=False) if data else \"\"\n",
    "        self._append(f\"{time.time_ns()} | {event}{(' | ' + payload) if payload else ''}\")\n",
    "\n",
    "    def log_bits(self, fragment: str, payload: bytes) -> None:\n",
    "        bits = \"\".join(f\"{b:08b}\" for b in payload)\n",
    "        with self.bit_log.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{time.time_ns()} | {fragment} | {bits}\\n\")\n",
    "\n",
    "    def log_merkle(self, fragment: str, digest: str) -> None:\n",
    "        with self.merkle_log.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{time.time_ns()} | {fragment} | {digest}\\n\")\n",
    "\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        *,\n",
    "        phase: str,\n",
    "        fragment: str,\n",
    "        neurons_active: int,\n",
    "        cpu_ns: int,\n",
    "        ink_pixels: int,\n",
    "        total_pixels: int,\n",
    "        merkle_prefix: str,\n",
    "    ) -> None:\n",
    "        ratio = (ink_pixels / total_pixels) if total_pixels else 0.0\n",
    "        with self.metrics_csv.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow(\n",
    "                [\n",
    "                    time.time_ns(),\n",
    "                    phase,\n",
    "                    fragment,\n",
    "                    neurons_active,\n",
    "                    cpu_ns,\n",
    "                    ink_pixels,\n",
    "                    total_pixels,\n",
    "                    f\"{ratio:.8f}\",\n",
    "                    merkle_prefix,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def write_state(self, state: Dict[str, object]) -> None:\n",
    "        state = dict(state)\n",
    "        state[\"timestamp_ns\"] = time.time_ns()\n",
    "        self.state_json.write_text(json.dumps(state, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    def write_discovery_inventory(self, payload: Dict[str, object]) -> None:\n",
    "        self.discovery_json.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class NX46AGNNVesuvius:\n",
    "    def __init__(self, cfg: NX46Config, logs_root: Path) -> None:\n",
    "        self.cfg = cfg\n",
    "        self.rng = np.random.default_rng(cfg.seed)\n",
    "        self.logger = HFBL360Logger(logs_root)\n",
    "        self.neurons_active = 0\n",
    "        self.total_allocations = 0\n",
    "        self.total_pixels_processed = 0\n",
    "        self.total_ink_pixels = 0\n",
    "        self.merkle_chain: List[str] = []\n",
    "        self.global_cpu_start_ns = time.process_time_ns()\n",
    "        self.logger.log_event(\"SYSTEM_STARTUP_L0_SUCCESS\", config=cfg.__dict__)\n",
    "\n",
    "    def slab_allocate(self, tensor: np.ndarray, phase: str) -> int:\n",
    "        variance = float(np.var(tensor, dtype=np.float64))\n",
    "        entropy_proxy = float(np.mean(np.abs(np.gradient(tensor.astype(np.float32), axis=-1))))\n",
    "        required = int(self.cfg.slab_min_neurons + (tensor.size // 512) + variance * 1500.0 + entropy_proxy * 900.0)\n",
    "        self.neurons_active = max(self.cfg.slab_min_neurons, required)\n",
    "        self.total_allocations += 1\n",
    "        self.logger.log_event(\n",
    "            \"SLAB_ALLOCATION\",\n",
    "            phase=phase,\n",
    "            neurons=self.neurons_active,\n",
    "            variance=round(variance, 8),\n",
    "            entropy_proxy=round(entropy_proxy, 8),\n",
    "        )\n",
    "        return self.neurons_active\n",
    "\n",
    "    def _track_bits(self, fragment: str, arr: np.ndarray) -> None:\n",
    "        self.logger.log_bits(fragment, arr.tobytes()[: self.cfg.bit_capture_bytes])\n",
    "\n",
    "    def _merkle_sign(self, fragment: str, arr: np.ndarray) -> str:\n",
    "        prev = self.merkle_chain[-1] if self.merkle_chain else \"GENESIS\"\n",
    "        digest = sha512(prev.encode(\"utf-8\") + arr.tobytes()).hexdigest()\n",
    "        self.merkle_chain.append(digest)\n",
    "        self.logger.log_merkle(fragment, digest)\n",
    "        return digest\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_stack(stack: np.ndarray) -> np.ndarray:\n",
    "        x = stack.astype(np.float32)\n",
    "        mn, mx = float(x.min()), float(x.max())\n",
    "        if mx <= mn:\n",
    "            return np.zeros_like(x, dtype=np.float32)\n",
    "        return (x - mn) / (mx - mn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _ink_energy_projection(stack: np.ndarray) -> np.ndarray:\n",
    "        grad_z = np.abs(np.diff(stack, axis=0, prepend=stack[:1]))\n",
    "        grad_y = np.abs(np.diff(stack, axis=1, prepend=stack[:, :1, :]))\n",
    "        grad_x = np.abs(np.diff(stack, axis=2, prepend=stack[:, :, :1]))\n",
    "        return np.mean(0.45 * grad_z + 0.30 * grad_y + 0.25 * grad_x, axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_along_z(stack: np.ndarray, radius: int) -> np.ndarray:\n",
    "        if radius <= 0:\n",
    "            return stack\n",
    "        r = int(max(1, radius))\n",
    "        pad = np.pad(stack, ((r, r), (0, 0), (0, 0)), mode=\"edge\")\n",
    "        csum = np.cumsum(pad, axis=0, dtype=np.float64)\n",
    "        win = (csum[2 * r :] - csum[: -2 * r]) / float(2 * r)\n",
    "        return win.astype(np.float32)\n",
    "\n",
    "    def _score_3d_native(self, norm: np.ndarray) -> np.ndarray:\n",
    "        grad_z = np.abs(np.diff(norm, axis=0, prepend=norm[:1]))\n",
    "        grad_y = np.abs(np.diff(norm, axis=1, prepend=norm[:, :1, :]))\n",
    "        grad_x = np.abs(np.diff(norm, axis=2, prepend=norm[:, :, :1]))\n",
    "\n",
    "        smooth = self._smooth_along_z(norm, self.cfg.z_smoothing_radius)\n",
    "        local_contrast = np.abs(norm - smooth)\n",
    "\n",
    "        d2z = np.abs(np.diff(norm, n=2, axis=0, prepend=norm[:1], append=norm[-1:]))\n",
    "\n",
    "        score3d = np.mean(\n",
    "            0.34 * grad_z + 0.22 * grad_y + 0.22 * grad_x + 0.12 * local_contrast + 0.10 * d2z,\n",
    "            axis=0,\n",
    "        )\n",
    "        return score3d.astype(np.float32)\n",
    "\n",
    "    def _score_25d_proxy(self, norm: np.ndarray) -> np.ndarray:\n",
    "        z = norm.shape[0]\n",
    "        if z <= 1:\n",
    "            return self._ink_energy_projection(norm)\n",
    "        center = z // 2\n",
    "        idx = sorted(set([max(0, center - 2), max(0, center - 1), center, min(z - 1, center + 1), min(z - 1, center + 2)]))\n",
    "        slab = norm[idx]\n",
    "        return self._ink_energy_projection(slab)\n",
    "\n",
    "    def score_projection(self, stack: np.ndarray) -> np.ndarray:\n",
    "        norm = self._normalize_stack(stack)\n",
    "        base = self._ink_energy_projection(norm)\n",
    "\n",
    "        if self.cfg.use_3d_native_path:\n",
    "            s3d = self._score_3d_native(norm)\n",
    "            w = float(min(1.0, max(0.0, self.cfg.score_blend_3d_weight)))\n",
    "            base = (w * s3d + (1.0 - w) * base).astype(np.float32)\n",
    "\n",
    "        if self.cfg.use_25d_path:\n",
    "            s25 = self._score_25d_proxy(norm)\n",
    "            base = (0.65 * base + 0.35 * s25).astype(np.float32)\n",
    "\n",
    "        return base\n",
    "\n",
    "    def train_threshold(self, stack: np.ndarray, labels: np.ndarray, fragment: str) -> float:\n",
    "        start = time.process_time_ns()\n",
    "        self.slab_allocate(stack, phase=\"train\")\n",
    "        self._track_bits(fragment, stack)\n",
    "\n",
    "        score = self.score_projection(stack)\n",
    "        pos = score[labels > 0]\n",
    "        neg = score[labels <= 0]\n",
    "        if pos.size and neg.size:\n",
    "            threshold = float(0.5 * (float(np.median(pos)) + float(np.median(neg))))\n",
    "        elif pos.size:\n",
    "            threshold = float(np.quantile(pos, 0.50))\n",
    "        else:\n",
    "            threshold = float(np.quantile(score, self.cfg.threshold_quantile))\n",
    "\n",
    "        pred = (score >= threshold).astype(np.uint8)\n",
    "        digest = self._merkle_sign(fragment, score)\n",
    "        cpu_ns = time.process_time_ns() - start\n",
    "\n",
    "        ink_pixels = int(pred.sum())\n",
    "        total_pixels = int(pred.size)\n",
    "        self.total_ink_pixels += ink_pixels\n",
    "        self.total_pixels_processed += total_pixels\n",
    "\n",
    "        self.logger.log_metrics(\n",
    "            phase=\"train\",\n",
    "            fragment=fragment,\n",
    "            neurons_active=self.neurons_active,\n",
    "            cpu_ns=cpu_ns,\n",
    "            ink_pixels=ink_pixels,\n",
    "            total_pixels=total_pixels,\n",
    "            merkle_prefix=digest[:16],\n",
    "        )\n",
    "        self.logger.log_event(\"TRAIN_DONE\", fragment=fragment, threshold=threshold)\n",
    "        return threshold\n",
    "\n",
    "    def infer_mask(self, stack: np.ndarray, threshold: float, fragment: str) -> np.ndarray:\n",
    "        start = time.process_time_ns()\n",
    "        self.slab_allocate(stack, phase=\"infer\")\n",
    "        self._track_bits(fragment, stack)\n",
    "\n",
    "        score = self.score_projection(stack)\n",
    "        pred = (score >= threshold).astype(np.uint8)\n",
    "        digest = self._merkle_sign(fragment, pred)\n",
    "        cpu_ns = time.process_time_ns() - start\n",
    "\n",
    "        ink_pixels = int(pred.sum())\n",
    "        total_pixels = int(pred.size)\n",
    "        self.total_ink_pixels += ink_pixels\n",
    "        self.total_pixels_processed += total_pixels\n",
    "\n",
    "        self.logger.log_metrics(\n",
    "            phase=\"infer\",\n",
    "            fragment=fragment,\n",
    "            neurons_active=self.neurons_active,\n",
    "            cpu_ns=cpu_ns,\n",
    "            ink_pixels=ink_pixels,\n",
    "            total_pixels=total_pixels,\n",
    "            merkle_prefix=digest[:16],\n",
    "        )\n",
    "        self.logger.log_event(\"INFER_DONE\", fragment=fragment)\n",
    "        return pred\n",
    "\n",
    "    def finalize(self, extra: Optional[Dict[str, object]] = None) -> Dict[str, object]:\n",
    "        cpu_total_ns = time.process_time_ns() - self.global_cpu_start_ns\n",
    "        state = {\n",
    "            \"runtime_status\": \"offline_activated\",\n",
    "            \"pipeline_status\": \"success\",\n",
    "            \"active_neurons\": self.neurons_active,\n",
    "            \"total_allocations\": self.total_allocations,\n",
    "            \"total_pixels_processed\": self.total_pixels_processed,\n",
    "            \"total_ink_pixels\": self.total_ink_pixels,\n",
    "            \"ink_ratio\": self.total_ink_pixels / self.total_pixels_processed if self.total_pixels_processed else 0.0,\n",
    "            \"qi_index_real\": self.total_pixels_processed / max(cpu_total_ns, 1),\n",
    "            \"cpu_total_ns\": cpu_total_ns,\n",
    "            \"merkle_root\": self.merkle_chain[-1] if self.merkle_chain else None,\n",
    "        }\n",
    "        if extra:\n",
    "            state.update(extra)\n",
    "        self.logger.write_state(state)\n",
    "        self.logger.log_event(\"SYSTEM_LOADED_100_PERCENT\")\n",
    "        return state\n",
    "\n",
    "\n",
    "def _to_stack(arr: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(arr)\n",
    "    if x.ndim == 2:\n",
    "        return x[np.newaxis, ...]\n",
    "    if x.ndim == 3:\n",
    "        return x\n",
    "    raise RuntimeError(f\"Unsupported TIFF shape: {x.shape}\")\n",
    "\n",
    "\n",
    "def _read_fragment_stack(fragment_dir: Path) -> np.ndarray:\n",
    "    volume_dir = fragment_dir / \"surface_volume\"\n",
    "    files = sorted(volume_dir.glob(\"*.tif\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No TIFF slices found in {volume_dir}\")\n",
    "    return np.stack([_to_stack(read_tiff_lzw_safe(p))[0] for p in files], axis=0)\n",
    "\n",
    "\n",
    "def _load_label(fragment_dir: Path) -> Optional[np.ndarray]:\n",
    "    png = fragment_dir / \"inklabels.png\"\n",
    "    if not png.exists() or iio is None:\n",
    "        return None\n",
    "    arr = np.asarray(iio.imread(str(png)))\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr[..., 0]\n",
    "    return (arr > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def _read_sample_submission_ids(path: Path) -> List[str]:\n",
    "    ids: List[str] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        cols = set(reader.fieldnames or [])\n",
    "        id_col = \"Id\" if \"Id\" in cols else (\"id\" if \"id\" in cols else None)\n",
    "        if id_col is None:\n",
    "            return ids\n",
    "        for row in reader:\n",
    "            v = str(row[id_col]).strip()\n",
    "            if v:\n",
    "                ids.append(v)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def _dataset_inventory(root: Path) -> Dict[str, object]:\n",
    "    if not root.exists():\n",
    "        return {\"root\": str(root), \"exists\": False}\n",
    "\n",
    "    all_files = [p for p in root.rglob(\"*\") if p.is_file()]\n",
    "    suffix_stats: Dict[str, int] = {}\n",
    "    folders = set()\n",
    "    for p in all_files:\n",
    "        suffix = p.suffix.lower() or \"<noext>\"\n",
    "        suffix_stats[suffix] = suffix_stats.get(suffix, 0) + 1\n",
    "        folders.add(str(p.parent.relative_to(root)))\n",
    "\n",
    "    return {\n",
    "        \"root\": str(root),\n",
    "        \"exists\": True,\n",
    "        \"total_assets\": len(all_files),\n",
    "        \"folders\": sorted(folders),\n",
    "        \"suffix_stats\": suffix_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "def _discover_layout(root: Path) -> Tuple[str, List[Path], List[Path]]:\n",
    "    test_images = root / \"test_images\"\n",
    "    if test_images.exists():\n",
    "        train_images = root / \"train_images\"\n",
    "        train = sorted(train_images.rglob(\"*.tif\")) if train_images.exists() else []\n",
    "        test = sorted(test_images.rglob(\"*.tif\"))\n",
    "        if test:\n",
    "            return \"competition_test_images\", train, test\n",
    "\n",
    "    train_dir = root / \"train\"\n",
    "    test_dir = root / \"test\"\n",
    "    if train_dir.exists() or test_dir.exists():\n",
    "        train = sorted([p for p in train_dir.iterdir() if p.is_dir() and (p / \"surface_volume\").exists()]) if train_dir.exists() else []\n",
    "        test = sorted([p for p in test_dir.iterdir() if p.is_dir() and (p / \"surface_volume\").exists()]) if test_dir.exists() else []\n",
    "        if test:\n",
    "            return \"fragment_dirs\", train, test\n",
    "\n",
    "    train_legacy = sorted((root / \"train_images\").glob(\"*.tif\")) if (root / \"train_images\").exists() else []\n",
    "    test_legacy = sorted((root / \"test_images\").glob(\"*.tif\")) if (root / \"test_images\").exists() else []\n",
    "    if test_legacy:\n",
    "        return \"legacy_tif_files\", train_legacy, test_legacy\n",
    "\n",
    "    return \"empty\", [], []\n",
    "\n",
    "\n",
    "def _candidate_roots(primary_root: Path) -> List[Path]:\n",
    "    candidates: List[Path] = []\n",
    "\n",
    "    def add(p: Path) -> None:\n",
    "        if p.exists() and p not in candidates:\n",
    "            candidates.append(p)\n",
    "\n",
    "    add(primary_root)\n",
    "    add(Path(\"/kaggle/input/vesuvius-challenge-ink-detection\"))\n",
    "    add(Path(\"/kaggle/input/vesuvius-challenge-surface-detection\"))\n",
    "    add(Path(\"/kaggle/input/competitions/vesuvius-challenge-surface-detection\"))\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if kaggle_input.exists():\n",
    "        for p in sorted(kaggle_input.iterdir()):\n",
    "            if p.is_dir() and \"vesuvius\" in p.name.lower():\n",
    "                add(p)\n",
    "\n",
    "    competitions = Path(\"/kaggle/input/competitions\")\n",
    "    if competitions.exists():\n",
    "        for p in sorted(competitions.iterdir()):\n",
    "            if p.is_dir() and \"vesuvius\" in p.name.lower():\n",
    "                add(p)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def _resolve_root(primary_root: Path, auto_discover: bool) -> Tuple[Path, str, List[Dict[str, object]]]:\n",
    "    roots = _candidate_roots(primary_root) if auto_discover else [primary_root]\n",
    "    attempts: List[Dict[str, object]] = []\n",
    "\n",
    "    for root in roots:\n",
    "        mode, train, test = _discover_layout(root)\n",
    "        attempts.append({\"root\": str(root), \"mode\": mode, \"train\": len(train), \"test\": len(test)})\n",
    "        if test:\n",
    "            return root, mode, attempts\n",
    "\n",
    "    return primary_root, \"empty\", attempts\n",
    "\n",
    "\n",
    "def _label_candidates_for_train_tif(item: Path) -> List[Path]:\n",
    "    root = item.parent.parent\n",
    "    return [\n",
    "        root / \"train_labels\" / item.name,\n",
    "        root / \"train_labels\" / item.with_suffix(\".png\").name,\n",
    "    ]\n",
    "\n",
    "\n",
    "def _quick_has_label(item: Path, mode: str) -> bool:\n",
    "    if mode == \"fragment_dirs\":\n",
    "        return (item / \"inklabels.png\").exists()\n",
    "    return any(c.exists() for c in _label_candidates_for_train_tif(item))\n",
    "\n",
    "\n",
    "def _load_train_item(item: Path, mode: str) -> Tuple[np.ndarray, Optional[np.ndarray], str]:\n",
    "    if mode == \"fragment_dirs\":\n",
    "        stack = _read_fragment_stack(item)\n",
    "        labels = _load_label(item)\n",
    "        return stack, labels, item.name\n",
    "\n",
    "    stack = _to_stack(read_tiff_lzw_safe(item))\n",
    "\n",
    "    labels = None\n",
    "    labels_tif, labels_png = _label_candidates_for_train_tif(item)\n",
    "    if labels_tif.exists():\n",
    "        l = read_tiff_lzw_safe(labels_tif)\n",
    "        labels = (l[0] > 0).astype(np.uint8) if l.ndim == 3 else (l > 0).astype(np.uint8)\n",
    "    elif labels_png.exists() and iio is not None:\n",
    "        l = np.asarray(iio.imread(str(labels_png)))\n",
    "        labels = (l[..., 0] > 0).astype(np.uint8) if l.ndim == 3 else (l > 0).astype(np.uint8)\n",
    "\n",
    "    return stack, labels, item.stem\n",
    "\n",
    "\n",
    "def _load_test_item(item: Path, mode: str) -> Tuple[np.ndarray, str]:\n",
    "    if mode == \"fragment_dirs\":\n",
    "        return _read_fragment_stack(item), f\"{item.name}.tif\"\n",
    "    return _to_stack(read_tiff_lzw_safe(item)), item.name\n",
    "\n",
    "\n",
    "def _write_submission_csv(out_csv: Path, sample_csv: Path, predictions: Dict[str, np.ndarray]) -> Optional[str]:\n",
    "    ids = _read_sample_submission_ids(sample_csv)\n",
    "    if not ids:\n",
    "        return None\n",
    "\n",
    "    flat = np.concatenate([predictions[k].reshape(-1).astype(np.uint8) for k in sorted(predictions)])\n",
    "    n = min(len(ids), len(flat))\n",
    "\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"Id\", \"Predicted\"])\n",
    "        for i in range(n):\n",
    "            w.writerow([ids[i], int(flat[i])])\n",
    "    return str(out_csv)\n",
    "\n",
    "\n",
    "\n",
    "def _apply_binary_mode(mask: np.ndarray, binary_mode: str = \"0_1\") -> np.ndarray:\n",
    "    m01 = (np.asarray(mask) > 0).astype(np.uint8)\n",
    "    if binary_mode == \"0_255\":\n",
    "        return (m01 * 255).astype(np.uint8)\n",
    "    if binary_mode == \"0_1\":\n",
    "        return m01\n",
    "    raise RuntimeError(f\"Invalid binary_mode: {binary_mode}\")\n",
    "\n",
    "\n",
    "def _write_submission_zip(\n",
    "    out_zip: Path,\n",
    "    predictions: Dict[str, np.ndarray],\n",
    "    expected_meta: Optional[Dict[str, Tuple[int, int, int]]] = None,\n",
    "    binary_mode: str = \"0_1\",\n",
    ") -> str:\n",
    "    out_zip.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_dir = out_zip.parent / \"submission_masks\"\n",
    "    tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    names: List[str] = []\n",
    "    for tif_name, mask in predictions.items():\n",
    "        # Canonical binary domain with configurable output encoding.\n",
    "        mask_bin = _apply_binary_mode(mask, binary_mode=binary_mode)\n",
    "        if expected_meta and tif_name in expected_meta:\n",
    "            ez, eh, ew = expected_meta[tif_name]\n",
    "            if mask_bin.ndim == 2:\n",
    "                mask_bin = np.repeat(mask_bin[None, :, :], ez, axis=0)\n",
    "            elif mask_bin.ndim == 3 and mask_bin.shape[0] != ez:\n",
    "                if mask_bin.shape[0] == 1:\n",
    "                    mask_bin = np.repeat(mask_bin, ez, axis=0)\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Mask depth mismatch for {tif_name}: got {mask_bin.shape[0]}, expected {ez}\")\n",
    "            if mask_bin.shape[1:] != (eh, ew):\n",
    "                raise RuntimeError(f\"Mask shape mismatch for {tif_name}: got {mask_bin.shape}, expected {(ez, eh, ew)}\")\n",
    "\n",
    "        p = tmp_dir / tif_name\n",
    "        # Write as multi-page TIFF to match successful scored submissions.\n",
    "        tifffile.imwrite(str(p), mask_bin, compression=\"LZW\")\n",
    "        names.append(tif_name)\n",
    "\n",
    "    with zipfile.ZipFile(out_zip, \"w\", compression=zipfile.ZIP_STORED) as zf:\n",
    "        for name in sorted(names):\n",
    "            zf.write(tmp_dir / name, arcname=name)\n",
    "\n",
    "    return str(out_zip)\n",
    "\n",
    "\n",
    "def _validate_zip_content_binary_01(\n",
    "    out_zip: Path,\n",
    "    expected_meta: Dict[str, Tuple[int, int, int]],\n",
    "    allowed_values: Tuple[int, ...] = (0, 1),\n",
    ") -> Dict[str, object]:\n",
    "    issues: List[str] = []\n",
    "    with zipfile.ZipFile(out_zip, \"r\") as zf:\n",
    "        for name in zf.namelist():\n",
    "            if not name.lower().endswith('.tif'):\n",
    "                continue\n",
    "            data = zf.read(name)\n",
    "            try:\n",
    "                arr = tifffile.imread(io.BytesIO(data))\n",
    "            except Exception as exc:  # pragma: no cover\n",
    "                issues.append(f\"decode_failed:{name}:{exc}\")\n",
    "                continue\n",
    "\n",
    "            arr = np.asarray(arr)\n",
    "            base = Path(name).name\n",
    "            if arr.ndim == 2:\n",
    "                arr = arr[None, :, :]\n",
    "            if arr.ndim != 3:\n",
    "                issues.append(f\"invalid_ndim:{name}:{arr.shape}\")\n",
    "                continue\n",
    "\n",
    "            if base in expected_meta and tuple(arr.shape) != tuple(expected_meta[base]):\n",
    "                issues.append(f\"shape_mismatch:{base}:{arr.shape}!={expected_meta[base]}\")\n",
    "\n",
    "            uniq = np.unique(arr)\n",
    "            if not set(int(x) for x in uniq.tolist()).issubset(set(allowed_values)):\n",
    "                issues.append(f\"invalid_values:{base}:{uniq[:8].tolist()}\")\n",
    "\n",
    "    return {\"status\": \"ok\" if not issues else \"invalid\", \"issues\": issues}\n",
    "\n",
    "\n",
    "def _validate_zip(out_zip: Path, expected_tif_names: Sequence[str]) -> Dict[str, object]:\n",
    "    with zipfile.ZipFile(out_zip, \"r\") as zf:\n",
    "        got = sorted([Path(n).name for n in zf.namelist() if n.lower().endswith(\".tif\")])\n",
    "    exp = sorted(expected_tif_names)\n",
    "    return {\n",
    "        \"status\": \"ok\" if got == exp else \"mismatch\",\n",
    "        \"expected_test_files\": len(exp),\n",
    "        \"submission_tif_files\": len(got),\n",
    "        \"missing\": sorted(set(exp) - set(got)),\n",
    "        \"unexpected\": sorted(set(got) - set(exp)),\n",
    "    }\n",
    "\n",
    "\n",
    "def _publish_submission_aliases(primary_zip: Path, work_root: Path) -> List[str]:\n",
    "    aliases = [\n",
    "        Path(\"/kaggle/working/submission.zip\"),\n",
    "        Path(\"/kaggle/working/nx46_vesuvius/submission.zip\"),\n",
    "        Path(\"submission.zip\"),\n",
    "        Path(\"nx46_vesuvius/submission.zip\"),\n",
    "        work_root / \"submission.zip\",\n",
    "    ]\n",
    "\n",
    "    published: List[str] = []\n",
    "    for alias in aliases:\n",
    "        if alias.resolve() == primary_zip.resolve():\n",
    "            published.append(str(alias))\n",
    "            continue\n",
    "        alias.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copyfile(primary_zip, alias)\n",
    "        published.append(str(alias))\n",
    "    return sorted(set(published))\n",
    "\n",
    "\n",
    "def _calibrate_threshold_from_unlabeled(\n",
    "    model: NX46AGNNVesuvius,\n",
    "    test_items: Sequence[Path],\n",
    "    mode: str,\n",
    "    q: float,\n",
    ") -> float:\n",
    "    sampled = list(test_items[: min(2, len(test_items))])\n",
    "    if not sampled:\n",
    "        return 0.5\n",
    "\n",
    "    q = min(0.999, max(0.50, q))\n",
    "    per_item: List[float] = []\n",
    "    for item in sampled:\n",
    "        stack, tif_name = _load_test_item(item, mode)\n",
    "        model.slab_allocate(stack, phase=\"train_fallback_probe\")\n",
    "        model._track_bits(Path(tif_name).stem, stack)\n",
    "        score = model.score_projection(stack)\n",
    "        digest = model._merkle_sign(f\"probe_{Path(tif_name).stem}\", score)\n",
    "        model.logger.log_metrics(\n",
    "            phase=\"train_fallback_probe\",\n",
    "            fragment=Path(tif_name).stem,\n",
    "            neurons_active=model.neurons_active,\n",
    "            cpu_ns=0,\n",
    "            ink_pixels=int((score >= np.quantile(score, q)).sum()),\n",
    "            total_pixels=int(score.size),\n",
    "            merkle_prefix=digest[:16],\n",
    "        )\n",
    "        per_item.append(float(np.quantile(score, q)))\n",
    "\n",
    "    return float(np.median(np.asarray(per_item, dtype=np.float32)))\n",
    "\n",
    "\n",
    "def _material_proxy_map(stack: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Generate a lightweight 4-class proxy map from native volumetric signals.\n",
    "\n",
    "    Classes: 0=background, 1=fiber_proxy, 2=ink_proxy, 3=artifact_proxy.\n",
    "    \"\"\"\n",
    "    x = stack.astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "\n",
    "    mid = np.mean(x, axis=0)\n",
    "    grad = np.mean(np.abs(np.diff(x, axis=0, prepend=x[:1])), axis=0)\n",
    "\n",
    "    q_mid_lo, q_mid_hi = float(np.quantile(mid, 0.35)), float(np.quantile(mid, 0.80))\n",
    "    q_grad_hi = float(np.quantile(grad, 0.90))\n",
    "\n",
    "    out = np.zeros(mid.shape, dtype=np.uint8)\n",
    "    out[(mid >= q_mid_lo) & (mid < q_mid_hi)] = 1\n",
    "    out[mid >= q_mid_hi] = 2\n",
    "    out[grad >= q_grad_hi] = 3\n",
    "    return out\n",
    "\n",
    "\n",
    "def _write_material_outputs(work: Path, material_maps: Dict[str, np.ndarray]) -> Dict[str, object]:\n",
    "    mat_dir = work / \"material_maps\"\n",
    "    mat_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    summary: Dict[str, Dict[str, int]] = {}\n",
    "    for tif_name, cls_map in material_maps.items():\n",
    "        out_tif = mat_dir / tif_name\n",
    "        tifffile.imwrite(str(out_tif), cls_map[np.newaxis, ...].astype(np.uint8), compression=\"LZW\")\n",
    "\n",
    "        cnt = {str(i): int((cls_map == i).sum()) for i in range(4)}\n",
    "        summary[tif_name] = cnt\n",
    "\n",
    "    manifest = {\n",
    "        \"material_classes\": {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"fiber_proxy\",\n",
    "            \"2\": \"ink_proxy\",\n",
    "            \"3\": \"artifact_proxy\",\n",
    "        },\n",
    "        \"files\": summary,\n",
    "    }\n",
    "    (work / \"native_training_manifest.json\").write_text(json.dumps(manifest, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _load_a2z_manifest() -> Optional[Dict[str, object]]:\n",
    "    candidates = [\n",
    "        Path('/workspace/Lumvorax/RAPPORT-VESUVIUS/a2z_audit_manifest.json'),\n",
    "        Path('RAPPORT-VESUVIUS/a2z_audit_manifest.json'),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            try:\n",
    "                return json.loads(c.read_text(encoding='utf-8'))\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_pipeline(cfg: NX46Config) -> Dict[str, object]:\n",
    "    if os.environ.get(\"NX46_DRY_RUN\", \"0\") == \"1\":\n",
    "        return {\n",
    "            \"status\": \"dry_run\",\n",
    "            \"run_tag\": cfg.run_tag,\n",
    "            \"threshold_quantile\": cfg.threshold_quantile,\n",
    "            \"score_blend_3d_weight\": cfg.score_blend_3d_weight,\n",
    "            \"z_smoothing_radius\": cfg.z_smoothing_radius,\n",
    "            \"use_3d_native_path\": cfg.use_3d_native_path,\n",
    "            \"use_25d_path\": cfg.use_25d_path,\n",
    "        }\n",
    "    configured_root = Path(cfg.data_root)\n",
    "    work = Path(cfg.work_root)\n",
    "    logs_root = work / \"logs\"\n",
    "    logs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    roadmap = ProgressRoadmap()\n",
    "    nx46 = NX46AGNNVesuvius(cfg, logs_root)\n",
    "\n",
    "    a2z_manifest = _load_a2z_manifest()\n",
    "    if a2z_manifest is not None:\n",
    "        nx46.logger.log_event(\"A2Z_AUDIT_MANIFEST_LOADED\", files_scanned=a2z_manifest.get(\"files_scanned\"), lines_scanned=a2z_manifest.get(\"lines_scanned\"))\n",
    "\n",
    "    effective_root, mode, attempts = _resolve_root(configured_root, cfg.auto_discover_data_root)\n",
    "    mode, train_items, test_items = _discover_layout(effective_root)\n",
    "\n",
    "    inventory = _dataset_inventory(effective_root)\n",
    "    nx46.logger.write_discovery_inventory({\"attempts\": attempts, \"inventory\": inventory})\n",
    "    nx46.logger.log_event(\"DATASET_DISCOVERY\", mode=mode, configured_root=str(configured_root), effective_root=str(effective_root), attempts=attempts)\n",
    "    roadmap.update(\"audit_discovery\", 100.0)\n",
    "\n",
    "    if not test_items:\n",
    "        nx46.logger.log_event(\"NO_TEST_INPUTS_FOUND\", attempts=attempts)\n",
    "        raise RuntimeError(\n",
    "            \"No test inputs found. Checked roots: \"\n",
    "            + \", \".join([a[\"root\"] for a in attempts])\n",
    "            + \". Configure NX46_DATA_ROOT to the dataset root containing test_images or test/<fragment>.\"\n",
    "        )\n",
    "\n",
    "    usable_train_items = [p for p in train_items if _quick_has_label(p, mode)]\n",
    "    skipped_no_label = max(0, len(train_items) - len(usable_train_items))\n",
    "    if cfg.max_train_items > 0:\n",
    "        usable_train_items = usable_train_items[: cfg.max_train_items]\n",
    "\n",
    "    thresholds: List[float] = []\n",
    "    total_train = max(1, len(usable_train_items))\n",
    "    for idx, item in enumerate(usable_train_items, start=1):\n",
    "        roadmap.update(\"train_thresholds\", idx * 100.0 / total_train)\n",
    "        nx46.logger.log_event(\"PROGRESS_TRAIN\", index=idx, total=len(usable_train_items))\n",
    "        stack, labels, name = _load_train_item(item, mode)\n",
    "        if labels is None:\n",
    "            continue\n",
    "        if labels.shape != stack.shape[1:]:\n",
    "            h = min(labels.shape[0], stack.shape[1])\n",
    "            w = min(labels.shape[1], stack.shape[2])\n",
    "            labels = labels[:h, :w]\n",
    "            stack = stack[:, :h, :w]\n",
    "        thresholds.append(nx46.train_threshold(stack, labels, name))\n",
    "\n",
    "    training_strategy = \"supervised\"\n",
    "    if thresholds:\n",
    "        threshold = float(np.median(np.asarray(thresholds, dtype=np.float32)))\n",
    "    else:\n",
    "        threshold = _calibrate_threshold_from_unlabeled(nx46, test_items, mode, cfg.threshold_quantile)\n",
    "        training_strategy = \"fallback_quantile_probe\"\n",
    "\n",
    "    nx46.logger.log_event(\n",
    "        \"THRESHOLD_SELECTED\",\n",
    "        threshold=threshold,\n",
    "        trained_samples=len(thresholds),\n",
    "        training_strategy=training_strategy,\n",
    "        skipped_no_label=skipped_no_label,\n",
    "        max_train_items=cfg.max_train_items,\n",
    "    )\n",
    "\n",
    "    predictions: Dict[str, np.ndarray] = {}\n",
    "    expected_names: List[str] = []\n",
    "    expected_meta: Dict[str, Tuple[int, int, int]] = {}\n",
    "    material_maps: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    total_test = max(1, len(test_items))\n",
    "    for idx, item in enumerate(test_items, start=1):\n",
    "        roadmap.update(\"infer_predictions\", idx * 100.0 / total_test)\n",
    "        nx46.logger.log_event(\"PROGRESS_TEST\", index=idx, total=len(test_items))\n",
    "        stack, tif_name = _load_test_item(item, mode)\n",
    "        pred = nx46.infer_mask(stack, threshold, Path(tif_name).stem)\n",
    "        predictions[tif_name] = pred\n",
    "        expected_meta[tif_name] = (int(stack.shape[0]), int(stack.shape[1]), int(stack.shape[2]))\n",
    "        if cfg.enable_material_head:\n",
    "            material_maps[tif_name] = _material_proxy_map(stack)\n",
    "        expected_names.append(tif_name)\n",
    "\n",
    "    roadmap.update(\"package_submission\", 20.0)\n",
    "\n",
    "    sample_csv_candidates = [\n",
    "        effective_root / \"sample_submission.csv\",\n",
    "        Path(\"/kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv\"),\n",
    "        Path(\"/kaggle/input/vesuvius-challenge-surface-detection/sample_submission.csv\"),\n",
    "        Path(\"/kaggle/input/competitions/vesuvius-challenge-surface-detection/sample_submission.csv\"),\n",
    "    ]\n",
    "    sample_csv = next((p for p in sample_csv_candidates if p.exists()), None)\n",
    "\n",
    "    submission_csv: Optional[str] = None\n",
    "    if cfg.write_submission_csv and sample_csv is not None:\n",
    "        submission_csv = _write_submission_csv(work / \"submission.csv\", sample_csv, predictions)\n",
    "\n",
    "    binary_mode = cfg.binary_mode if cfg.binary_mode in {\"0_1\", \"0_255\"} else \"0_1\"\n",
    "    primary_zip = Path(cfg.kaggle_submission_root) / \"submission.zip\"\n",
    "    submission_zip = _write_submission_zip(primary_zip, predictions, expected_meta=expected_meta, binary_mode=binary_mode)\n",
    "    submission_zip_aliases = _publish_submission_aliases(Path(submission_zip), work)\n",
    "    validation = _validate_zip(Path(submission_zip), expected_names)\n",
    "    allowed_values = (0, 1) if binary_mode == \"0_1\" else (0, 255)\n",
    "    content_validation = _validate_zip_content_binary_01(Path(submission_zip), expected_meta, allowed_values=allowed_values)\n",
    "    nx46.logger.log_event(\"COMPETITION_RULES_VALIDATION\", **validation)\n",
    "    nx46.logger.log_event(\"SUBMISSION_CONTENT_VALIDATION\", **content_validation)\n",
    "    nx46.logger.log_event(\"SUBMISSION_PATHS_PUBLISHED\", primary=submission_zip, aliases=submission_zip_aliases)\n",
    "    roadmap.update(\"package_submission\", 100.0)\n",
    "\n",
    "    if cfg.strict_competition_mode and (validation[\"status\"] != \"ok\" or content_validation[\"status\"] != \"ok\"):\n",
    "        raise RuntimeError(f\"Submission validation failed: zip={validation}, content={content_validation}\")\n",
    "\n",
    "    material_manifest: Optional[Dict[str, object]] = None\n",
    "    if cfg.enable_material_head and cfg.save_material_outputs and material_maps:\n",
    "        material_manifest = _write_material_outputs(work, material_maps)\n",
    "        nx46.logger.log_event(\"MATERIAL_HEAD_EXPORT\", files=len(material_maps))\n",
    "\n",
    "    roadmap.update(\"finalize_forensics\", 100.0)\n",
    "    result = nx46.finalize(\n",
    "        {\n",
    "            \"status\": \"100%_OFFLINE_ACTIVATED\",\n",
    "            \"layout_detected\": mode,\n",
    "            \"configured_data_root\": str(configured_root),\n",
    "            \"effective_data_root\": str(effective_root),\n",
    "            \"discovery_attempts\": attempts,\n",
    "            \"train_items_total\": len(train_items),\n",
    "            \"train_items_with_labels\": len(usable_train_items),\n",
    "            \"train_items_skipped_no_label\": skipped_no_label,\n",
    "            \"train_items\": [p.name for p in train_items],\n",
    "            \"test_items\": [p.name for p in test_items],\n",
    "            \"train_threshold\": threshold,\n",
    "            \"training_strategy\": training_strategy,\n",
    "            \"scoring_mode\": {\"use_3d_native_path\": cfg.use_3d_native_path, \"use_25d_path\": cfg.use_25d_path, \"score_blend_3d_weight\": cfg.score_blend_3d_weight},\n",
    "            \"submission_csv\": submission_csv,\n",
    "            \"submission_zip\": submission_zip,\n",
    "            \"submission_zip_aliases\": submission_zip_aliases,\n",
    "            \"zip_members_validated\": validation[\"status\"] == \"ok\",\n",
    "            \"zip_missing\": validation[\"missing\"],\n",
    "            \"zip_extra\": validation[\"unexpected\"],\n",
    "            \"competition_rules_validation\": validation,\n",
    "            \"submission_content_validation\": content_validation,\n",
    "            \"submission_format_profile\": f\"kaggle_v8_5_style_zip_lzw_3d_uint8_{binary_mode}\",\n",
    "            \"binary_mode\": binary_mode,\n",
    "            \"material_head_enabled\": cfg.enable_material_head,\n",
    "            \"material_outputs_files\": len(material_maps),\n",
    "            \"native_training_manifest\": str(work / \"native_training_manifest.json\") if material_manifest else None,\n",
    "            \"a2z_audit_manifest_loaded\": a2z_manifest is not None,\n",
    "            \"a2z_files_scanned\": (a2z_manifest or {}).get(\"files_scanned\"),\n",
    "            \"a2z_lines_scanned\": (a2z_manifest or {}).get(\"lines_scanned\"),\n",
    "            \"roadmap_percent\": roadmap.as_dict(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    (logs_root / \"RkF4XakI.txt\").write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    (logs_root / \"UJxLRsEE.txt\").write_text(json.dumps(validation, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    nx46.logger.log_event(\"EXEC_COMPLETE\", submission=submission_zip)\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = NX46Config(\n",
    "        data_root=os.environ.get(\"NX46_DATA_ROOT\", NX46Config.data_root),\n",
    "        work_root=os.environ.get(\"NX46_WORK_ROOT\", NX46Config.work_root),\n",
    "        kaggle_submission_root=os.environ.get(\"NX46_KAGGLE_SUBMISSION_ROOT\", NX46Config.kaggle_submission_root),\n",
    "        max_train_items=int(os.environ.get(\"NX46_MAX_TRAIN_ITEMS\", str(NX46Config.max_train_items))),\n",
    "        threshold_quantile=float(os.environ.get(\"NX46_THRESHOLD_QUANTILE\", str(NX46Config.threshold_quantile))),\n",
    "        enable_material_head=os.environ.get(\"NX46_ENABLE_MATERIAL_HEAD\", \"1\") != \"0\",\n",
    "        save_material_outputs=os.environ.get(\"NX46_SAVE_MATERIAL_OUTPUTS\", \"1\") != \"0\",\n",
    "        use_3d_native_path=os.environ.get(\"NX46_USE_3D_NATIVE_PATH\", \"1\") != \"0\",\n",
    "        use_25d_path=os.environ.get(\"NX46_USE_25D_PATH\", \"0\") != \"0\",\n",
    "        score_blend_3d_weight=float(os.environ.get(\"NX46_SCORE_BLEND_3D_WEIGHT\", str(NX46Config.score_blend_3d_weight))),\n",
    "        z_smoothing_radius=int(os.environ.get(\"NX46_Z_SMOOTHING_RADIUS\", str(NX46Config.z_smoothing_radius))),\n",
    "        write_submission_csv=os.environ.get(\"NX46_WRITE_SUBMISSION_CSV\", \"0\") == \"1\",\n",
    "        binary_mode=os.environ.get(\"NX46_BINARY_MODE\", \"0_1\").strip().lower(),\n",
    "        run_tag=os.environ.get(\"NX46_RUN_TAG\", NX46Config.run_tag),\n",
    "    )\n",
    "    out = run_pipeline(config)\n",
    "    print(json.dumps(out, indent=2, ensure_ascii=False))\n",
    "    print(f\"READY: {out['submission_zip']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manifest fonctions intégrées\n",
    "function_manifest = {\n",
    "    'V61.5': ['__init__', '_safe', 'file_metric', 'install_offline', 'log', 'process_file', 'read_tiff', 'run_all', 'slice_metric', 'slice_percentiles'],\n",
    "    'V144.2': ['__init__', '_assert_continuity_integrity', '_assert_no_hardcoded_metric_pattern', '_assert_train_completed_100', '_assert_train_pairs_threshold', '_audit_train_dataset_size', '_balance_sample_indices', '_binary_stats', '_build_continuity_matrix', '_build_progress_bar', '_build_v1442_forensic_report', '_compute_learning_percent_real', '_derive_train_pair_requirement', '_dice_loss_from_logits', '_extract_2p5d_patches', '_fbeta_from_stats', '_is_pkg_available', '_load_label_2d', '_load_volume', '_log_array_ultra', '_log_heartbeat', '_log_progress', '_parse_v130_log_summary', '_predict_mask', '_resolve_root', '_run_preflight_5pct', '_sigmoid', '_validate_submission_competition_rules', '_write', '_zscore', 'adapt_learning_rate', 'add_step', 'audit_logits_distribution', 'auto_select_features', 'bit_stats', 'bootstrap_dependencies_fail_fast', 'build_supervised_model', 'calibrate_target_ratio', 'calibrate_thresholds', 'choose_adaptive_ratio', 'choose_slicewise_adaptive_ratio', 'compute_proxy_f1', 'discover_inputs', 'discover_train_pairs', 'dynamic_regularization_lambda', 'emit', 'ensure_imagecodecs', 'extract_multi_features', 'fit_prox', 'forward', 'hysteresis_topology_3d', 'install_offline', 'log', 'log_array', 'make_batches', 'overall_progress', 'predict_proba', 'probe_hardware_metrics', 'pseudo_labels', 'read_tiff_lzw_safe', 'run', 'run_simulation_100', 'simulate_f1_vs_ratio_curve', 'slice_adaptive_fusion', 'train_nx47_autonomous', 'train_nx47_supervised', 'train_unet_25d_supervised', 'update', 'write_tiff_lzw_safe'],\n",
    "    'V7.7': ['__init__', '_append', '_apply_binary_mode', '_calibrate_threshold_from_unlabeled', '_candidate_roots', '_dataset_inventory', '_discover_layout', '_ink_energy_projection', '_label_candidates_for_train_tif', '_load_a2z_manifest', '_load_label', '_load_test_item', '_load_train_item', '_material_proxy_map', '_merkle_sign', '_normalize_stack', '_publish_submission_aliases', '_quick_has_label', '_read_fragment_stack', '_read_sample_submission_ids', '_resolve_root', '_score_25d_proxy', '_score_3d_native', '_smooth_along_z', '_to_stack', '_track_bits', '_validate_zip', '_validate_zip_content_binary_01', '_write_material_outputs', '_write_submission_csv', '_write_submission_zip', 'add', 'as_dict', 'bootstrap_dependencies_fail_fast', 'emit_dependency_manifest', 'ensure_imagecodecs', 'finalize', 'infer_mask', 'install_offline', 'log_bits', 'log_event', 'log_merkle', 'log_metrics', 'read_tiff_lzw_safe', 'run_pipeline', 'score_projection', 'slab_allocate', 'train_threshold', 'update', 'write_discovery_inventory', 'write_state'],\n",
    "    'V7.6': ['__init__', '_append', '_apply_binary_mode', '_calibrate_threshold_from_unlabeled', '_candidate_roots', '_dataset_inventory', '_discover_layout', '_ink_energy_projection', '_label_candidates_for_train_tif', '_load_a2z_manifest', '_load_label', '_load_test_item', '_load_train_item', '_material_proxy_map', '_merkle_sign', '_normalize_stack', '_publish_submission_aliases', '_quick_has_label', '_read_fragment_stack', '_read_sample_submission_ids', '_resolve_root', '_score_25d_proxy', '_score_3d_native', '_smooth_along_z', '_to_stack', '_track_bits', '_validate_zip', '_validate_zip_content_binary_01', '_write_material_outputs', '_write_submission_csv', '_write_submission_zip', 'add', 'as_dict', 'bootstrap_dependencies_fail_fast', 'ensure_imagecodecs', 'finalize', 'infer_mask', 'install_offline', 'log_bits', 'log_event', 'log_merkle', 'log_metrics', 'read_tiff_lzw_safe', 'run_pipeline', 'score_projection', 'slab_allocate', 'train_threshold', 'update', 'write_discovery_inventory', 'write_state'],\n",
    "}\n",
    "collision_manifest = {k:v for k,v in sorted({",
    "'__init__':['V61.5', 'V144.2', 'V7.7', 'V7.6'],",
    "'_append':['V7.7', 'V7.6'],",
    "'_apply_binary_mode':['V7.7', 'V7.6'],",
    "'_calibrate_threshold_from_unlabeled':['V7.7', 'V7.6'],",
    "'_candidate_roots':['V7.7', 'V7.6'],",
    "'_dataset_inventory':['V7.7', 'V7.6'],",
    "'_discover_layout':['V7.7', 'V7.6'],",
    "'_ink_energy_projection':['V7.7', 'V7.6'],",
    "'_label_candidates_for_train_tif':['V7.7', 'V7.6'],",
    "'_load_a2z_manifest':['V7.7', 'V7.6'],",
    "'_load_label':['V7.7', 'V7.6'],",
    "'_load_test_item':['V7.7', 'V7.6'],",
    "'_load_train_item':['V7.7', 'V7.6'],",
    "'_material_proxy_map':['V7.7', 'V7.6'],",
    "'_merkle_sign':['V7.7', 'V7.6'],",
    "'_normalize_stack':['V7.7', 'V7.6'],",
    "'_publish_submission_aliases':['V7.7', 'V7.6'],",
    "'_quick_has_label':['V7.7', 'V7.6'],",
    "'_read_fragment_stack':['V7.7', 'V7.6'],",
    "'_read_sample_submission_ids':['V7.7', 'V7.6'],",
    "'_resolve_root':['V144.2', 'V7.7', 'V7.6'],",
    "'_score_25d_proxy':['V7.7', 'V7.6'],",
    "'_score_3d_native':['V7.7', 'V7.6'],",
    "'_smooth_along_z':['V7.7', 'V7.6'],",
    "'_to_stack':['V7.7', 'V7.6'],",
    "'_track_bits':['V7.7', 'V7.6'],",
    "'_validate_zip':['V7.7', 'V7.6'],",
    "'_validate_zip_content_binary_01':['V7.7', 'V7.6'],",
    "'_write_material_outputs':['V7.7', 'V7.6'],",
    "'_write_submission_csv':['V7.7', 'V7.6'],",
    "'_write_submission_zip':['V7.7', 'V7.6'],",
    "'add':['V7.7', 'V7.6'],",
    "'as_dict':['V7.7', 'V7.6'],",
    "'bootstrap_dependencies_fail_fast':['V144.2', 'V7.7', 'V7.6'],",
    "'ensure_imagecodecs':['V144.2', 'V7.7', 'V7.6'],",
    "'finalize':['V7.7', 'V7.6'],",
    "'infer_mask':['V7.7', 'V7.6'],",
    "'install_offline':['V61.5', 'V144.2', 'V7.7', 'V7.6'],",
    "'log':['V61.5', 'V144.2'],",
    "'log_bits':['V7.7', 'V7.6'],",
    "'log_event':['V7.7', 'V7.6'],",
    "'log_merkle':['V7.7', 'V7.6'],",
    "'log_metrics':['V7.7', 'V7.6'],",
    "'read_tiff_lzw_safe':['V144.2', 'V7.7', 'V7.6'],",
    "'run_pipeline':['V7.7', 'V7.6'],",
    "'score_projection':['V7.7', 'V7.6'],",
    "'slab_allocate':['V7.7', 'V7.6'],",
    "'train_threshold':['V7.7', 'V7.6'],",
    "'update':['V144.2', 'V7.7', 'V7.6'],",
    "'write_discovery_inventory':['V7.7', 'V7.6'],",
    "'write_state':['V7.7', 'V7.6'],",
    "}.items())}\n",
    "print('versions:', list(function_manifest))\n",
    "print('nb fonctions total (noms uniques):', len(set(sum(function_manifest.values(), []))))\n",
    "print('collisions:', len(collision_manifest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}