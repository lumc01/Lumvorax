{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa564db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T18:42:44.954058Z",
     "iopub.status.busy": "2026-02-27T18:42:44.953650Z",
     "iopub.status.idle": "2026-02-27T18:48:17.136262Z",
     "shell.execute_reply": "2026-02-27T18:48:17.135298Z"
    },
    "papermill": {
     "duration": 332.187687,
     "end_time": "2026-02-27T18:48:17.137615",
     "exception": false,
     "start_time": "2026-02-27T18:42:44.949928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-27 18:42:58.741322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1772217778.939047      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1772217778.992169      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras backend: jax Keras version: 3.12.0.dev2025100703\n",
      "Num test volumes: 1\n",
      "Model params (M): 70.056598\n",
      "CFG: overlap_public=0.42, overlap_base=0.43, overlap_hi=0.6, INK_MODE=fg12, T_low=0.5, T_high=0.9, OV06_MAIN_ONLY=True, USE_LUM_RESONANCE=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1772217806.805314      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3301 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up JAX (compile once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total patch 27:   0%|          | 0/27 [00:00<?, ?it/s]2026-02-27 18:43:36.931611: E external/xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2026-02-27 18:43:37.121411: E external/xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "Total patch 27: 100%|██████████| 27/27 [00:30<00:00,  1.15s/it]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.11it/s]\n",
      "Total patch 64: 100%|██████████| 64/64 [00:29<00:00,  2.19it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.12it/s]\n",
      "Total patch 64: 100%|██████████| 64/64 [00:29<00:00,  2.19it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.12it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.12it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.12it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.12it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n",
      "Total patch 27: 100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] id=1407735 | 4.85 min | elapsed 0.08 h | positives=3054752 | lum_score=8.000\n",
      "\n",
      "LUM resonance summary:\n",
      "     id  positives  lum_spectral_score  lum_spectral_gain  lum_prior_mean  lum_prior_gate_rate  minutes\n",
      "1407735    3054752                 8.0                1.0        0.096087             0.095068 4.854478\n",
      "Submission ZIP: /kaggle/working/submission.zip\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Vesuvius — SINGLE-PATH DROP-IN (public-anchored + private-seeded hysteresis)\n",
    "# Goal: beat/at least match public 0.55 using ONE safe upgrade:\n",
    "#   strong = (private_prob >= 0.90)\n",
    "#   weak   = (private_prob >= 0.50) OR (public_argmax != 0)\n",
    "#   mask   = binary_propagation(strong within weak) + closing + dust\n",
    "#\n",
    "# Writes: /kaggle/working/submission.zip\n",
    "# ============================================================\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "# protobuf compatibility shim (protobuf>=5 removed MessageFactory.GetPrototype used by some deps)\n",
    "try:\n",
    "    from google.protobuf import message_factory as _pb_message_factory\n",
    "    if not hasattr(_pb_message_factory.MessageFactory, \"GetPrototype\"):\n",
    "        def _compat_get_prototype(self, descriptor):\n",
    "            return _pb_message_factory.GetMessageClass(descriptor)\n",
    "        _pb_message_factory.MessageFactory.GetPrototype = _compat_get_prototype\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# protobuf stability (common Kaggle container mismatch)\n",
    "os.environ.setdefault(\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\", \"python\")\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"4\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"4\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"4\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"4\")\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "var = Path(\"/kaggle/input/vsdetection-packages-offline-installer-only/whls\")\n",
    "whl_patterns = [\n",
    "    \"keras_nightly-*.whl\",\n",
    "    \"tifffile-*.whl\",\n",
    "    \"imagecodecs-*.whl\",\n",
    "    \"medicai-*.whl\",\n",
    "]\n",
    "whls = []\n",
    "for pat in whl_patterns:\n",
    "    found = sorted(var.glob(pat))\n",
    "    if not found:\n",
    "        raise FileNotFoundError(f\"Missing wheel for pattern: {pat} in {var}\")\n",
    "    whls.append(str(found[0]))\n",
    "\n",
    "subprocess.check_call([\n",
    "    \"python\", \"-m\", \"pip\", \"install\", *whls,\n",
    "    \"--no-index\", \"--find-links\", str(var)\n",
    "])\n",
    "clear_output()\n",
    "\n",
    "import time, zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import remove_small_objects\n",
    "import keras\n",
    "from medicai.transforms import Compose, NormalizeIntensity\n",
    "from medicai.models import TransUNet\n",
    "from medicai.utils.inference import SlidingWindowInference\n",
    "\n",
    "print(\"Keras backend:\", keras.config.backend(), \"Keras version:\", keras.version())\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG (minimal, safe)\n",
    "# ----------------------------\n",
    "CFG = dict(\n",
    "    # model\n",
    "    kaggle_model_path=\"/kaggle/input/vsd-model/keras/\",\n",
    "    weights_relpath=\"transunet/3/transunet.seresnext50.160px.comboloss.weights.h5\",\n",
    "\n",
    "    # SWI overlaps\n",
    "    overlap_public=0.42,  # EXACT public 0.55\n",
    "    overlap_base=0.43,    # EXACT private 0.55 (important!)\n",
    "    overlap_hi=0.60,      # OV06\n",
    "    OV06_MAIN_ONLY=True,\n",
    "\n",
    "    # TTA\n",
    "    USE_TTA=True,\n",
    "\n",
    "    # binary logit definition (match your private 0.55)\n",
    "    INK_MODE=\"fg12\",\n",
    "\n",
    "    # thresholds (match your private 0.55)\n",
    "    T_low=0.50,\n",
    "    T_high=0.90,\n",
    "\n",
    "    # topology (match both notebooks' common setting)\n",
    "    z_radius=3,\n",
    "    xy_radius=2,\n",
    "    dust_min_size=100,\n",
    "\n",
    "    # warmup\n",
    "    DO_WARMUP=True,\n",
    "\n",
    ")\n",
    "\n",
    "# SHF/RSR overlay isolated from competitor baseline config\n",
    "# Baseline-safe defaults: disabled unless explicitly enabled\n",
    "LUM_CFG = dict(\n",
    "    # synchronized with competitor baseline parameters\n",
    "    USE_LUM_RESONANCE=True,\n",
    "    LUM_BLEND_ALPHA=CFG[\"overlap_base\"],\n",
    "    LUM_SPECTRAL_GAMMA=CFG[\"overlap_hi\"],\n",
    "    LUM_PRIOR_WEIGHT=CFG[\"overlap_public\"],\n",
    "    LUM_SMOOTH_STEPS=CFG[\"z_radius\"],\n",
    "    LUM_PRIOR_THRESHOLD=CFG[\"T_low\"],\n",
    ")\n",
    "\n",
    "root_dir = \"/kaggle/input/vesuvius-challenge-surface-detection\"\n",
    "test_dir = f\"{root_dir}/test_images\"\n",
    "output_dir = \"/kaggle/working/submission_masks\"\n",
    "zip_path = \"/kaggle/working/submission.zip\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "test_df = pd.read_csv(f\"{root_dir}/test.csv\")\n",
    "ids = test_df[\"id\"].tolist()\n",
    "print(\"Num test volumes:\", len(ids))\n",
    "\n",
    "ROI = (160, 160, 160)\n",
    "\n",
    "# ----------------------------\n",
    "# Transform (same style)\n",
    "# ----------------------------\n",
    "_val_pipeline = Compose([\n",
    "    NormalizeIntensity(keys=[\"image\"], nonzero=True, channel_wise=False),\n",
    "])\n",
    "def val_transformation(image):\n",
    "    return _val_pipeline({\"image\": image})[\"image\"]\n",
    "\n",
    "def load_volume(path):\n",
    "    vol = tifffile.imread(path).astype(np.float32)\n",
    "    return vol[None, ..., None]  # (1, D, H, W, 1)\n",
    "\n",
    "# ----------------------------\n",
    "# Numerics\n",
    "# ----------------------------\n",
    "def sigmoid_stable(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    out = np.empty_like(x, dtype=np.float32)\n",
    "    pos = x >= 0\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-x[pos]))\n",
    "    ex = np.exp(x[~pos])\n",
    "    out[~pos] = ex / (1.0 + ex)\n",
    "    return out\n",
    "\n",
    "def logsumexp2(a, b):\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    b = np.asarray(b, dtype=np.float32)\n",
    "    m = np.maximum(a, b)\n",
    "    return m + np.log(np.exp(a - m) + np.exp(b - m) + 1e-12)\n",
    "\n",
    "def binary_logit_from_multiclass_logits(logits_5d, mode=\"fg12\"):\n",
    "    x = np.asarray(logits_5d, dtype=np.float32)[0]  # (D,H,W,3)\n",
    "    L0, L1, L2 = x[...,0], x[...,1], x[...,2]\n",
    "    if mode == \"fg12\":\n",
    "        return (logsumexp2(L1, L2) - L0).astype(np.float32, copy=False)\n",
    "    elif mode == \"class1\":\n",
    "        return (L1 - logsumexp2(L0, L2)).astype(np.float32, copy=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown INK_MODE={mode}\")\n",
    "\n",
    "# ----------------------------\n",
    "# LUM/VORAX SHF-RSR helpers\n",
    "# ----------------------------\n",
    "def shf_spectral_signature(prob):\n",
    "    p = np.asarray(prob, dtype=np.float32)\n",
    "    fft_mag = np.abs(np.fft.rfftn(p)).astype(np.float32, copy=False)\n",
    "    hi = float(np.percentile(fft_mag, 92.0))\n",
    "    lo = float(np.percentile(fft_mag, 60.0))\n",
    "    score = hi / (lo + 1e-6)\n",
    "    return float(np.clip(score, 0.0, 8.0))\n",
    "\n",
    "def rsr_recursive_prior(pub_fg_bool, smooth_steps=2):\n",
    "    prior = pub_fg_bool.astype(np.float32, copy=False)\n",
    "    for _ in range(max(0, int(smooth_steps))):\n",
    "        prior = ndi.gaussian_filter(prior, sigma=(0.0, 1.2, 1.2))\n",
    "        prior = np.clip(prior, 0.0, 1.0)\n",
    "    return prior\n",
    "\n",
    "def lum_resonance_blend(prob, pub_fg_bool, lum_cfg):\n",
    "    spectral = shf_spectral_signature(prob)\n",
    "    spectral_gain = np.clip((spectral - 1.0) * lum_cfg[\"LUM_SPECTRAL_GAMMA\"], 0.0, 1.0)\n",
    "\n",
    "    prior = rsr_recursive_prior(pub_fg_bool, smooth_steps=lum_cfg[\"LUM_SMOOTH_STEPS\"])\n",
    "    prior_gate = (prior >= lum_cfg[\"LUM_PRIOR_THRESHOLD\"]).astype(np.float32)\n",
    "\n",
    "    alpha = float(lum_cfg[\"LUM_BLEND_ALPHA\"])\n",
    "    w_prior = float(lum_cfg[\"LUM_PRIOR_WEIGHT\"])\n",
    "    blended = prob * (1.0 - alpha) + alpha * ((1.0 - w_prior) * prob + w_prior * prior_gate)\n",
    "    boosted = np.clip(blended + spectral_gain * prior * 0.08, 0.0, 1.0).astype(np.float32, copy=False)\n",
    "\n",
    "    return boosted, {\n",
    "        \"lum_spectral_score\": float(spectral),\n",
    "        \"lum_spectral_gain\": float(spectral_gain),\n",
    "        \"lum_prior_mean\": float(prior.mean()),\n",
    "        \"lum_prior_gate_rate\": float(prior_gate.mean()),\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Topology helpers\n",
    "# ----------------------------\n",
    "def build_anisotropic_struct(z_radius: int, xy_radius: int):\n",
    "    z, r = int(z_radius), int(xy_radius)\n",
    "    if z == 0 and r == 0:\n",
    "        return None\n",
    "    if z == 0 and r > 0:\n",
    "        size = 2*r + 1\n",
    "        struct = np.zeros((1, size, size), dtype=bool)\n",
    "        cy = cx = r\n",
    "        for dy in range(-r, r+1):\n",
    "            for dx in range(-r, r+1):\n",
    "                if dy*dy + dx*dx <= r*r:\n",
    "                    struct[0, cy+dy, cx+dx] = True\n",
    "        return struct\n",
    "    if z > 0 and r == 0:\n",
    "        struct = np.zeros((2*z+1, 1, 1), dtype=bool)\n",
    "        struct[:, 0, 0] = True\n",
    "        return struct\n",
    "    depth = 2*z + 1\n",
    "    size  = 2*r + 1\n",
    "    struct = np.zeros((depth, size, size), dtype=bool)\n",
    "    cz = z; cy = cx = r\n",
    "    for dz in range(-z, z+1):\n",
    "        for dy in range(-r, r+1):\n",
    "            for dx in range(-r, r+1):\n",
    "                if dy*dy + dx*dx <= r*r:\n",
    "                    struct[cz+dz, cy+dy, cx+dx] = True\n",
    "    return struct\n",
    "\n",
    "def seeded_hysteresis_with_topology(\n",
    "    prob, pub_fg_bool,\n",
    "    T_low=0.50, T_high=0.90,\n",
    "    z_radius=3, xy_radius=2, dust_min_size=100\n",
    "):\n",
    "    prob = np.asarray(prob, dtype=np.float32)\n",
    "    strong = prob >= float(T_high)\n",
    "\n",
    "    # SAFE expansion: weak includes private weak OR public foreground\n",
    "    weak = (prob >= float(T_low)) | pub_fg_bool\n",
    "\n",
    "    if not strong.any():\n",
    "        return np.zeros_like(prob, dtype=np.uint8)\n",
    "\n",
    "    struct_hyst = ndi.generate_binary_structure(3, 3)\n",
    "    mask = ndi.binary_propagation(strong, mask=weak, structure=struct_hyst)\n",
    "\n",
    "    if not mask.any():\n",
    "        return np.zeros_like(prob, dtype=np.uint8)\n",
    "\n",
    "    struct_close = build_anisotropic_struct(z_radius, xy_radius)\n",
    "    if struct_close is not None:\n",
    "        mask = ndi.binary_closing(mask, structure=struct_close)\n",
    "\n",
    "    if int(dust_min_size) > 0:\n",
    "        mask = remove_small_objects(mask.astype(bool), min_size=int(dust_min_size))\n",
    "\n",
    "    return mask.astype(np.uint8)\n",
    "\n",
    "# ----------------------------\n",
    "# Model + SWI (logits)\n",
    "# ----------------------------\n",
    "weights_path = f\"{CFG['kaggle_model_path']}/{CFG['weights_relpath']}\"\n",
    "\n",
    "model = TransUNet(\n",
    "    input_shape=(160, 160, 160, 1),\n",
    "    encoder_name=\"seresnext50\",\n",
    "    classifier_activation=None,  # TRUE logits\n",
    "    num_classes=3,\n",
    ")\n",
    "model.load_weights(weights_path)\n",
    "print(\"Model params (M):\", model.count_params() / 1e6)\n",
    "\n",
    "def build_swi(overlap):\n",
    "    return SlidingWindowInference(\n",
    "        model,\n",
    "        num_classes=3,\n",
    "        roi_size=ROI,\n",
    "        sw_batch_size=1,\n",
    "        mode=\"gaussian\",\n",
    "        overlap=float(overlap),\n",
    "    )\n",
    "\n",
    "swi_public = build_swi(CFG[\"overlap_public\"])  # public 0.55\n",
    "swi_base   = build_swi(CFG[\"overlap_base\"])    # private base 0.55\n",
    "swi_hi     = build_swi(CFG[\"overlap_hi\"])      # OV06\n",
    "\n",
    "# ----------------------------\n",
    "# TTA (same set)\n",
    "# ----------------------------\n",
    "def iter_tta(volume):\n",
    "    yield volume, (lambda y: y)\n",
    "    for axis in [1, 2, 3]:\n",
    "        v = np.flip(volume, axis=axis)\n",
    "        inv = (lambda y, axis=axis: np.flip(y, axis=axis))\n",
    "        yield v, inv\n",
    "    for k in [1, 2, 3]:\n",
    "        v = np.rot90(volume, k=k, axes=(2, 3))\n",
    "        inv = (lambda y, k=k: np.rot90(y, k=-k, axes=(2, 3)))\n",
    "        yield v, inv\n",
    "\n",
    "# ----------------------------\n",
    "# Predict BOTH streams in one loop (single final path)\n",
    "# - Public: mean multiclass logits -> argmax labels\n",
    "# - Private: OV06 main-only + mean binary logits -> prob\n",
    "# ----------------------------\n",
    "def predict_pub_labels_and_private_prob(volume):\n",
    "    mode = CFG[\"INK_MODE\"]\n",
    "\n",
    "    if not CFG[\"USE_TTA\"]:\n",
    "        l_pub = np.asarray(swi_public(volume))\n",
    "        pub_labels = l_pub.argmax(-1).astype(np.uint8).squeeze()\n",
    "\n",
    "        l_prv = np.asarray(swi_hi(volume))\n",
    "        s = binary_logit_from_multiclass_logits(l_prv, mode=mode)\n",
    "        prob = sigmoid_stable(s)\n",
    "        return pub_labels, prob\n",
    "\n",
    "    logits_sum = None\n",
    "    s_sum = None\n",
    "    n = 0\n",
    "\n",
    "    for t, (v, inv) in enumerate(iter_tta(volume)):\n",
    "        # public stream\n",
    "        l_pub = np.asarray(swi_public(v))\n",
    "        l_pub = inv(l_pub)\n",
    "        logits_sum = l_pub.astype(np.float32) if logits_sum is None else (logits_sum + l_pub.astype(np.float32))\n",
    "\n",
    "        # private stream (OV06 main-only)\n",
    "        if CFG[\"OV06_MAIN_ONLY\"]:\n",
    "            swi_use = swi_hi if (t == 0) else swi_base\n",
    "        else:\n",
    "            swi_use = swi_hi\n",
    "\n",
    "        l_prv = np.asarray(swi_use(v))\n",
    "        l_prv = inv(l_prv)\n",
    "        s = binary_logit_from_multiclass_logits(l_prv, mode=mode)\n",
    "        s_sum = s.astype(np.float32) if s_sum is None else (s_sum + s.astype(np.float32))\n",
    "\n",
    "        n += 1\n",
    "\n",
    "    mean_logits = logits_sum / float(n)\n",
    "    pub_labels = mean_logits.argmax(-1).astype(np.uint8).squeeze()\n",
    "\n",
    "    s_mean = (s_sum / float(n)).astype(np.float32, copy=False)\n",
    "    prob = sigmoid_stable(s_mean)\n",
    "    return pub_labels, prob\n",
    "\n",
    "# ----------------------------\n",
    "# Warmup (compile once)\n",
    "# ----------------------------\n",
    "def warmup(volume):\n",
    "    _ = np.asarray(swi_public(volume))\n",
    "    _ = np.asarray(swi_base(volume))\n",
    "    _ = np.asarray(swi_hi(volume))\n",
    "\n",
    "# ----------------------------\n",
    "# Run + zip\n",
    "# ----------------------------\n",
    "print(\"CFG:\",\n",
    "      f\"overlap_public={CFG['overlap_public']}, overlap_base={CFG['overlap_base']}, overlap_hi={CFG['overlap_hi']},\",\n",
    "      f\"INK_MODE={CFG['INK_MODE']}, T_low={CFG['T_low']}, T_high={CFG['T_high']},\",\n",
    "      f\"OV06_MAIN_ONLY={CFG['OV06_MAIN_ONLY']},\",\n",
    "      f\"USE_LUM_RESONANCE={LUM_CFG['USE_LUM_RESONANCE']}\")\n",
    "\n",
    "t_global0 = time.perf_counter()\n",
    "run_rows = []\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    for i, image_id in enumerate(ids):\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        tif_path = f\"{test_dir}/{image_id}.tif\"\n",
    "        volume = load_volume(tif_path)\n",
    "        volume = val_transformation(volume)\n",
    "\n",
    "        if i == 0 and CFG[\"DO_WARMUP\"]:\n",
    "            print(\"Warming up JAX (compile once)...\")\n",
    "            warmup(volume)\n",
    "\n",
    "        pub_labels, prob = predict_pub_labels_and_private_prob(volume)\n",
    "\n",
    "        # public fg anchor (no topology here; used only as weak region expansion)\n",
    "        pub_fg = (pub_labels != 0)\n",
    "\n",
    "        lum_metrics = {\n",
    "            \"lum_spectral_score\": 0.0,\n",
    "            \"lum_spectral_gain\": 0.0,\n",
    "            \"lum_prior_mean\": 0.0,\n",
    "            \"lum_prior_gate_rate\": 0.0,\n",
    "        }\n",
    "        prob_for_output = prob\n",
    "        if LUM_CFG[\"USE_LUM_RESONANCE\"]:\n",
    "            prob_for_output, lum_metrics = lum_resonance_blend(prob, pub_fg, LUM_CFG)\n",
    "\n",
    "        # single final path\n",
    "        output = seeded_hysteresis_with_topology(\n",
    "            prob_for_output,\n",
    "            pub_fg_bool=pub_fg,\n",
    "            T_low=CFG[\"T_low\"],\n",
    "            T_high=CFG[\"T_high\"],\n",
    "            z_radius=CFG[\"z_radius\"],\n",
    "            xy_radius=CFG[\"xy_radius\"],\n",
    "            dust_min_size=CFG[\"dust_min_size\"],\n",
    "        )\n",
    "\n",
    "        out_path = f\"{output_dir}/{image_id}.tif\"\n",
    "        tifffile.imwrite(out_path, output.astype(np.uint8))\n",
    "        zf.write(out_path, arcname=f\"{image_id}.tif\")\n",
    "        os.remove(out_path)\n",
    "\n",
    "        dt = time.perf_counter() - t0\n",
    "        elapsed = time.perf_counter() - t_global0\n",
    "        run_rows.append({\n",
    "            \"id\": image_id,\n",
    "            \"positives\": int(output.sum()),\n",
    "            **lum_metrics,\n",
    "            \"minutes\": float(dt / 60.0),\n",
    "        })\n",
    "        print(f\"[{i+1}/{len(ids)}] id={image_id} | {dt/60:.2f} min | elapsed {elapsed/3600:.2f} h | positives={int(output.sum())} | lum_score={lum_metrics['lum_spectral_score']:.3f}\")\n",
    "\n",
    "if run_rows:\n",
    "    run_df = pd.DataFrame(run_rows)\n",
    "    print(\"\\nLUM resonance summary:\")\n",
    "    print(run_df[[\"id\", \"positives\", \"lum_spectral_score\", \"lum_spectral_gain\", \"lum_prior_mean\", \"lum_prior_gate_rate\", \"minutes\"]].to_string(index=False))\n",
    "\n",
    "print(\"Submission ZIP:\", zip_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15062069,
     "sourceId": 117682,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 14910215,
     "modelId": 510647,
     "modelInstanceId": 516822,
     "sourceId": 681152,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14811492,
     "modelId": 510647,
     "modelInstanceId": 503784,
     "sourceId": 674747,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14570138,
     "modelId": 510647,
     "modelInstanceId": 495238,
     "sourceId": 655294,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14687610,
     "modelId": 510647,
     "modelInstanceId": 503784,
     "sourceId": 665589,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 15477237,
     "modelId": 510647,
     "modelInstanceId": 516822,
     "sourceId": 732880,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14789938,
     "modelId": 510647,
     "modelInstanceId": 499479,
     "sourceId": 673516,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14761443,
     "modelId": 510647,
     "modelInstanceId": 495238,
     "sourceId": 672178,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14691066,
     "modelId": 510647,
     "modelInstanceId": 504051,
     "sourceId": 665924,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 14626934,
     "modelId": 510647,
     "modelInstanceId": 499479,
     "sourceId": 660383,
     "sourceType": "modelInstanceVersion"
    },
    {
     "sourceId": 290917305,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 339.018044,
   "end_time": "2026-02-27T18:48:20.413695",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-27T18:42:41.395651",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
