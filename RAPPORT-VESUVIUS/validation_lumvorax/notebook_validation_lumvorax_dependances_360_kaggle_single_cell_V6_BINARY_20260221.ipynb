{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LUMVORAX Dependency 360 Validation - V6 Binary\n",
        "Mode wheel+.so robuste Kaggle avec fallback compression quand LZW indisponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# LUMVORAX DEPENDENCY 360 VALIDATION (KAGGLE SINGLE CELL - V6 BINARY)\n",
        "# ================================================================\n",
        "# Purpose:\n",
        "# - Binary-first validation for Kaggle dependency datasets.\n",
        "# - NO C/.h validation and NO native source compilation checks.\n",
        "# - Validate wheel set + shared object presence + optional .so load + roundtrip.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import ctypes\n",
        "import importlib\n",
        "import json\n",
        "import os\n",
        "import platform\n",
        "import re\n",
        "import struct\n",
        "import subprocess\n",
        "import sys\n",
        "import tempfile\n",
        "import time\n",
        "from hashlib import sha256, sha512\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "LUM_MAGIC = b\"LUMV1\\x00\\x00\\x00\"\n",
        "\n",
        "KAGGLE_DEP_PATHS = [\n",
        "    Path('/kaggle/input/datasets/ndarray2000/nx47-dependencies'),\n",
        "    Path('/kaggle/input/nx47-dependencies'),\n",
        "    Path('/kaggle/input/lum-vorax-dependencies'),\n",
        "    Path('/kaggle/input/lumvorax-dependencies'),\n",
        "]\n",
        "\n",
        "EXPECTED_WHEELS = [\n",
        "    'imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    'imageio-2.37.2-py3-none-any.whl',\n",
        "    'lazy_loader-0.4-py3-none-any.whl',\n",
        "    'networkx-3.6.1-py3-none-any.whl',\n",
        "    'numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    'opencv_python-4.13.0.92-cp37-abi3-manylinux_2_28_x86_64.whl',\n",
        "    'packaging-26.0-py3-none-any.whl',\n",
        "    'pillow-12.1.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    'scikit_image-0.26.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    'scipy-1.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    'tifffile-2026.1.28-py3-none-any.whl',\n",
        "    'tifffile-2026.2.16-py3-none-any.whl',\n",
        "]\n",
        "EXPECTED_NATIVE_LIB = 'liblumvorax.so'\n",
        "\n",
        "IS_KAGGLE = Path('/kaggle').exists()\n",
        "STRICT_NO_FALLBACK = os.environ.get('LUMVORAX_STRICT_NO_FALLBACK', '1') == '1'\n",
        "REQUIRE_DATASET = os.environ.get('LUMVORAX_REQUIRE_DATASET', '1' if IS_KAGGLE else '0') == '1'\n",
        "REQUIRE_SO_PRESENCE = os.environ.get('LUMVORAX_REQUIRE_SO_PRESENCE', '1') == '1'\n",
        "ENFORCE_SO_LOAD = os.environ.get('LUMVORAX_ENFORCE_SO_LOAD', '0') == '1'\n",
        "SKIP_ROUNDTRIP = os.environ.get('LUMVORAX_SKIP_ROUNDTRIP', '0' if IS_KAGGLE else '1') == '1'\n",
        "\n",
        "\n",
        "def now_ns() -> int:\n",
        "    return time.time_ns()\n",
        "\n",
        "\n",
        "def log_event(report: Dict[str, Any], step: str, **payload: Any) -> None:\n",
        "    report.setdefault('events', []).append({'ts_ns': now_ns(), 'step': step, **payload})\n",
        "\n",
        "\n",
        "def pkg_available(name: str) -> bool:\n",
        "    try:\n",
        "        importlib.import_module(name)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def detect_dataset_root(report: Dict[str, Any]) -> Optional[Path]:\n",
        "    for root in KAGGLE_DEP_PATHS:\n",
        "        if root.exists() and root.is_dir():\n",
        "            log_event(report, 'dataset_root_selected', root=str(root))\n",
        "            return root\n",
        "    log_event(report, 'dataset_root_missing', tried=[str(p) for p in KAGGLE_DEP_PATHS])\n",
        "    return None\n",
        "\n",
        "\n",
        "def install_wheel_file(wheel_path: Path, report: Dict[str, Any], reason: str) -> Dict[str, Any]:\n",
        "    cmd = [sys.executable, '-m', 'pip', 'install', '--disable-pip-version-check', '--no-index', str(wheel_path)]\n",
        "    try:\n",
        "        log_event(report, 'wheel_install_attempt', wheel=str(wheel_path), reason=reason, cmd=cmd)\n",
        "        subprocess.check_call(cmd)\n",
        "        return {'status': 'installed', 'wheel': str(wheel_path), 'reason': reason}\n",
        "    except Exception as exc:\n",
        "        log_event(report, 'wheel_install_fail', wheel=str(wheel_path), reason=reason, error=str(exc))\n",
        "        return {'status': 'failed', 'wheel': str(wheel_path), 'reason': reason, 'error': str(exc)}\n",
        "\n",
        "\n",
        "def install_offline_if_missing(pkg: str, report: Dict[str, Any], dataset_root: Optional[Path]) -> Dict[str, Any]:\n",
        "    if pkg_available(pkg):\n",
        "        return {'package': pkg, 'status': 'already_installed'}\n",
        "\n",
        "    mapping = {\n",
        "        'numpy': 'numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "        'tifffile': 'tifffile-2026.2.16-py3-none-any.whl',\n",
        "        'imagecodecs': 'imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    }\n",
        "    if dataset_root and pkg in mapping:\n",
        "        wheel = dataset_root / mapping[pkg]\n",
        "        if wheel.exists():\n",
        "            res = install_wheel_file(wheel, report, reason=f'exact_{pkg}_wheel')\n",
        "            if res['status'] == 'installed' and pkg_available(pkg):\n",
        "                return {'package': pkg, 'status': 'installed', 'method': 'exact_wheel', 'wheel': str(wheel)}\n",
        "\n",
        "    last = 'not found'\n",
        "    for root in KAGGLE_DEP_PATHS:\n",
        "        if not root.exists():\n",
        "            continue\n",
        "        cmd = [sys.executable, '-m', 'pip', 'install', '--disable-pip-version-check', '--no-index', f'--find-links={root}', pkg]\n",
        "        try:\n",
        "            log_event(report, 'dependency_install_attempt', package=pkg, root=str(root), cmd=cmd)\n",
        "            subprocess.check_call(cmd)\n",
        "            if pkg_available(pkg):\n",
        "                return {'package': pkg, 'status': 'installed', 'method': 'find_links', 'root': str(root)}\n",
        "        except Exception as exc:\n",
        "            last = str(exc)\n",
        "            log_event(report, 'dependency_install_fail', package=pkg, root=str(root), error=last)\n",
        "\n",
        "    return {'package': pkg, 'status': 'missing', 'error': last}\n",
        "\n",
        "\n",
        "def inspect_dataset_artifacts(root: Optional[Path], report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    if root is None:\n",
        "        return {'status': 'missing', 'reason': 'dataset_root_not_found'}\n",
        "\n",
        "    files = {p.name: p for p in root.iterdir() if p.is_file()}\n",
        "    missing_wheels = [w for w in EXPECTED_WHEELS if w not in files]\n",
        "    present_wheels = [w for w in EXPECTED_WHEELS if w in files]\n",
        "    native = files.get(EXPECTED_NATIVE_LIB)\n",
        "\n",
        "    out = {\n",
        "        'status': 'ok' if ((not REQUIRE_SO_PRESENCE or native is not None) and len(missing_wheels) == 0) else 'fail',\n",
        "        'dataset_root': str(root),\n",
        "        'expected_native_lib': EXPECTED_NATIVE_LIB,\n",
        "        'resolved_native_lib_name': native.name if native else None,\n",
        "        'native_lib': str(native) if native else None,\n",
        "        'native_lib_sha256': sha256(native.read_bytes()).hexdigest() if native else None,\n",
        "        'native_lib_size': native.stat().st_size if native else None,\n",
        "        'expected_wheel_count': len(EXPECTED_WHEELS),\n",
        "        'present_wheels_count': len(present_wheels),\n",
        "        'missing_wheels': missing_wheels,\n",
        "        'present_wheels': present_wheels,\n",
        "    }\n",
        "    log_event(report, 'dataset_artifacts_checked', status=out['status'], missing_wheels=len(missing_wheels), native_found=bool(native))\n",
        "    return out\n",
        "\n",
        "\n",
        "def check_native_load(lib_path: Optional[str], report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    if not lib_path:\n",
        "        return {'status': 'missing', 'reason': 'native_library_missing'}\n",
        "\n",
        "    try:\n",
        "        ctypes.CDLL(lib_path)\n",
        "        log_event(report, 'native_load_ok', lib=lib_path)\n",
        "        return {'status': 'ok', 'lib': lib_path}\n",
        "    except Exception as exc:\n",
        "        err = str(exc)\n",
        "        m = re.search(r'GLIBC_(\\d+\\.\\d+)', err)\n",
        "        diag = {\n",
        "            'status': 'abi_incompatible' if m else 'fail',\n",
        "            'lib': lib_path,\n",
        "            'error': err,\n",
        "            'required_glibc': m.group(1) if m else None,\n",
        "            'runtime_glibc': platform.libc_ver()[1] or 'unknown',\n",
        "            'blocking': bool(ENFORCE_SO_LOAD),\n",
        "        }\n",
        "        log_event(report, 'native_load_check', **diag)\n",
        "        if ENFORCE_SO_LOAD:\n",
        "            raise RuntimeError(f'native_so_load_enforced_failed: {err}')\n",
        "        return diag\n",
        "\n",
        "\n",
        "def inspect_so_symbols(lib_path: Optional[str], report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    if not lib_path:\n",
        "        return {'status': 'missing', 'reason': 'no_lib_path'}\n",
        "\n",
        "    nm = os.environ.get('NM_BIN', 'nm')\n",
        "    cmd = [nm, '-D', lib_path]\n",
        "    try:\n",
        "        proc = subprocess.run(cmd, capture_output=True, text=True)\n",
        "        if proc.returncode != 0:\n",
        "            return {'status': 'fail', 'returncode': proc.returncode, 'stderr_head': (proc.stderr or '')[:1200]}\n",
        "\n",
        "        symbols = []\n",
        "        for line in proc.stdout.splitlines():\n",
        "            if ' T ' in line or ' t ' in line:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    symbols.append(parts[-1])\n",
        "        lum_related = [s for s in symbols if s.startswith(('lum_', 'vorax_', 'log_', 'forensic_'))]\n",
        "        out = {\n",
        "            'status': 'ok',\n",
        "            'symbol_count_total': len(symbols),\n",
        "            'symbol_count_lum_related': len(lum_related),\n",
        "            'lum_related_head': lum_related[:200],\n",
        "        }\n",
        "        log_event(report, 'so_symbols_scanned', total=out['symbol_count_total'], lum_related=out['symbol_count_lum_related'])\n",
        "        return out\n",
        "    except Exception as exc:\n",
        "        return {'status': 'fail', 'error': str(exc), 'cmd': cmd}\n",
        "\n",
        "\n",
        "def normalize_volume(arr):\n",
        "    import numpy as np\n",
        "\n",
        "    if arr.ndim == 2:\n",
        "        arr = arr[np.newaxis, :, :]\n",
        "    if arr.ndim != 3:\n",
        "        raise ValueError(f'Expected 2D/3D volume, got {arr.shape}')\n",
        "    return np.ascontiguousarray(arr.astype(np.float32, copy=False))\n",
        "\n",
        "\n",
        "def encode_lum_v1(arr3d):\n",
        "    z, h, w = arr3d.shape\n",
        "    payload = arr3d.tobytes()\n",
        "    digest16 = sha512(payload).digest()[:16]\n",
        "    header = struct.pack('<8sIII16s', LUM_MAGIC, z, h, w, digest16)\n",
        "    return header + payload\n",
        "\n",
        "\n",
        "def decode_lum_v1(blob: bytes):\n",
        "    import numpy as np\n",
        "\n",
        "    hs = struct.calcsize('<8sIII16s')\n",
        "    magic, z, h, w, digest16 = struct.unpack('<8sIII16s', blob[:hs])\n",
        "    if magic != LUM_MAGIC:\n",
        "        raise ValueError('invalid LUM magic')\n",
        "    payload = blob[hs:]\n",
        "    expected = int(z) * int(h) * int(w) * 4\n",
        "    if len(payload) != expected:\n",
        "        raise ValueError('payload size mismatch')\n",
        "    if sha512(payload).digest()[:16] != digest16:\n",
        "        raise ValueError('payload checksum mismatch')\n",
        "    return np.frombuffer(payload, dtype=np.float32).reshape((z, h, w))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _tiff_compression_plan(report: Dict[str, Any]) -> List[tuple[str, Optional[str]]]:\n",
        "    \"\"\"Build a robust compression plan for Kaggle runtimes.\n",
        "\n",
        "    Some Kaggle images run Python 3.12 while the dataset ships cp311 imagecodecs wheels.\n",
        "    In that case import may appear installed but LZW backend is unavailable at runtime.\n",
        "    \"\"\"\n",
        "    plan: List[tuple[str, Optional[str]]] = []\n",
        "\n",
        "    lzw_ready = False\n",
        "    lzw_error = None\n",
        "    try:\n",
        "        import imagecodecs  # type: ignore\n",
        "        lzw_ready = hasattr(imagecodecs, 'lzw_encode')\n",
        "        if not lzw_ready:\n",
        "            lzw_error = 'imagecodecs imported but lzw_encode missing'\n",
        "    except Exception as exc:\n",
        "        lzw_error = str(exc)\n",
        "\n",
        "    if lzw_ready:\n",
        "        plan.append(('LZW', 'LZW'))\n",
        "    else:\n",
        "        report.setdefault('warnings', []).append({\n",
        "            'type': 'compression',\n",
        "            'detail': {\n",
        "                'status': 'lzw_unavailable',\n",
        "                'reason': lzw_error,\n",
        "                'note': 'Falling back to ADOBE_DEFLATE/NONE for runtime stability.'\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # keep deterministic fallback chain\n",
        "    plan.append(('ADOBE_DEFLATE', 'ADOBE_DEFLATE'))\n",
        "    plan.append(('NONE', None))\n",
        "\n",
        "    # if strict requested and LZW is ready, prioritize only LZW first\n",
        "    if STRICT_NO_FALLBACK and lzw_ready:\n",
        "        return [('LZW', 'LZW')]\n",
        "    return plan\n",
        "\n",
        "def tiff_lum_roundtrip_test(report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    import numpy as np\n",
        "    import tifffile\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as td:\n",
        "        td = Path(td)\n",
        "        tif_path = td / 'synthetic_teacher.tif'\n",
        "        lum_path = td / 'synthetic_teacher.lum'\n",
        "\n",
        "        rng = np.random.default_rng(42)\n",
        "        vol = (rng.random((8, 32, 32)) > 0.87).astype(np.uint8)\n",
        "\n",
        "        compressions = _tiff_compression_plan(report)\n",
        "\n",
        "        used = None\n",
        "        errors: List[Dict[str, str]] = []\n",
        "        for tag, comp in compressions:\n",
        "            try:\n",
        "                tifffile.imwrite(tif_path, vol, compression=comp)\n",
        "                used = tag\n",
        "                break\n",
        "            except Exception as exc:\n",
        "                errors.append({'attempt': tag, 'error': str(exc)})\n",
        "\n",
        "        if used is None:\n",
        "            report.setdefault('warnings', []).append({'type': 'roundtrip', 'detail': {'status': 'write_failed', 'errors': errors}})\n",
        "            return {'status': 'skipped', 'reason': 'tiff_write_unavailable', 'forensic_write': {'write_errors': errors, 'write_compression_used': None}}\n",
        "\n",
        "        arr3d = normalize_volume(tifffile.imread(tif_path))\n",
        "        blob = encode_lum_v1(arr3d)\n",
        "        lum_path.write_bytes(blob)\n",
        "        restored = decode_lum_v1(blob)\n",
        "\n",
        "        return {\n",
        "            'status': 'ok',\n",
        "            'shape': [int(x) for x in restored.shape],\n",
        "            'roundtrip_ok': bool((arr3d == restored).all()),\n",
        "            'write_compression_used': used,\n",
        "            'forensic_write': {'write_errors': errors, 'write_compression_used': used},\n",
        "        }\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    t0 = now_ns()\n",
        "    report: Dict[str, Any] = {\n",
        "        'report_name': 'lumvorax_dependency_360_kaggle_single_cell_v6_binary',\n",
        "        'timestamp_ns': now_ns(),\n",
        "        'runtime': {\n",
        "            'python': sys.version,\n",
        "            'platform': platform.platform(),\n",
        "            'cwd': str(Path.cwd()),\n",
        "            'is_kaggle': IS_KAGGLE,\n",
        "        },\n",
        "        'policy': {\n",
        "            'strict_no_fallback': STRICT_NO_FALLBACK,\n",
        "            'require_dataset': REQUIRE_DATASET,\n",
        "            'require_so_presence': REQUIRE_SO_PRESENCE,\n",
        "            'enforce_so_load': ENFORCE_SO_LOAD,\n",
        "            'skip_roundtrip': SKIP_ROUNDTRIP,\n",
        "            'source_header_validation_enabled': False,\n",
        "            'c_syntax_smoke_enabled': False,\n",
        "        },\n",
        "        'dataset_expected': {\n",
        "            'native_lib': EXPECTED_NATIVE_LIB,\n",
        "            'wheels': EXPECTED_WHEELS,\n",
        "        },\n",
        "        'events': [],\n",
        "        'warnings': [],\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        dataset_root = detect_dataset_root(report)\n",
        "        report['dataset_root'] = str(dataset_root) if dataset_root else None\n",
        "\n",
        "        if REQUIRE_DATASET and dataset_root is None:\n",
        "            raise RuntimeError('dataset_root_required_but_not_found')\n",
        "\n",
        "        report['install_report'] = [install_offline_if_missing(p, report, dataset_root) for p in ('numpy', 'tifffile', 'imagecodecs')]\n",
        "        report['imports'] = {p: pkg_available(p) for p in ('numpy', 'tifffile', 'imagecodecs', 'pyarrow')}\n",
        "\n",
        "        report['dataset_artifacts'] = inspect_dataset_artifacts(dataset_root, report)\n",
        "        if report['dataset_artifacts'].get('status') != 'ok':\n",
        "            if REQUIRE_DATASET:\n",
        "                raise RuntimeError('dataset_artifacts_incomplete')\n",
        "            report['warnings'].append({'type': 'dataset', 'detail': report['dataset_artifacts']})\n",
        "            report['so_symbol_inventory'] = {'status': 'skipped', 'reason': 'dataset_artifacts_not_ok'}\n",
        "            report['so_load_check'] = {'status': 'skipped', 'reason': 'dataset_artifacts_not_ok'}\n",
        "        else:\n",
        "            native_lib = report['dataset_artifacts'].get('native_lib')\n",
        "            report['so_symbol_inventory'] = inspect_so_symbols(native_lib, report)\n",
        "            report['so_load_check'] = check_native_load(native_lib, report)\n",
        "\n",
        "            if report['so_load_check'].get('status') != 'ok':\n",
        "                report['warnings'].append({'type': 'so_load', 'detail': report['so_load_check']})\n",
        "\n",
        "        if SKIP_ROUNDTRIP:\n",
        "            report['tiff_lum_roundtrip_test'] = {'status': 'skipped', 'reason': 'LUMVORAX_SKIP_ROUNDTRIP=1'}\n",
        "        else:\n",
        "            report['tiff_lum_roundtrip_test'] = tiff_lum_roundtrip_test(report)\n",
        "\n",
        "        report['status'] = 'ok_with_warnings' if report['warnings'] else 'ok'\n",
        "    except Exception as exc:\n",
        "        report['status'] = 'fail'\n",
        "        report['error_type'] = type(exc).__name__\n",
        "        report['error'] = str(exc)\n",
        "        log_event(report, 'fatal_error', error_type=type(exc).__name__, error=str(exc))\n",
        "\n",
        "    report['elapsed_ns'] = now_ns() - t0\n",
        "    report['elapsed_s'] = report['elapsed_ns'] / 1_000_000_000\n",
        "\n",
        "    out = Path('/kaggle/working/lumvorax_360_validation_report_v6_binary.json')\n",
        "    if not out.parent.exists():\n",
        "        out = Path('lumvorax_360_validation_report_v6_binary.json')\n",
        "    out.write_text(json.dumps(report, indent=2), encoding='utf-8')\n",
        "\n",
        "    print(json.dumps({\n",
        "        'status': report.get('status'),\n",
        "        'error_type': report.get('error_type'),\n",
        "        'error': report.get('error'),\n",
        "        'report': str(out),\n",
        "        'dataset_root': report.get('dataset_root'),\n",
        "        'native_lib': report.get('dataset_artifacts', {}).get('native_lib') if isinstance(report.get('dataset_artifacts'), dict) else None,\n",
        "        'present_wheels_count': report.get('dataset_artifacts', {}).get('present_wheels_count') if isinstance(report.get('dataset_artifacts'), dict) else None,\n",
        "        'missing_wheels_count': len(report.get('dataset_artifacts', {}).get('missing_wheels', [])) if isinstance(report.get('dataset_artifacts'), dict) else None,\n",
        "        'so_load_status': report.get('so_load_check', {}).get('status') if isinstance(report.get('so_load_check'), dict) else None,\n",
        "        'so_symbol_count': report.get('so_symbol_inventory', {}).get('symbol_count_lum_related') if isinstance(report.get('so_symbol_inventory'), dict) else None,\n",
        "        'roundtrip_status': report.get('tiff_lum_roundtrip_test', {}).get('status') if isinstance(report.get('tiff_lum_roundtrip_test'), dict) else None,\n",
        "        'warnings_count': len(report.get('warnings', [])),\n",
        "        'events_count': len(report.get('events', [])),\n",
        "        'elapsed_ns': report.get('elapsed_ns'),\n",
        "    }, indent=2))\n",
        "\n",
        "    if report.get('status') == 'fail':\n",
        "        raise SystemExit(2)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}