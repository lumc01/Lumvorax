{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# LUMVORAX DEPENDENCY 360 VALIDATION (KAGGLE SINGLE CELL - V3 COMPLETE)\n",
        "# ================================================================\n",
        "# - Full forensic timeline with nanosecond timestamps.\n",
        "# - Strict fail policy by default (no compression fallback).\n",
        "# - Optionally relaxed mode for diagnostics.\n",
        "# - Single-file copy/paste for Kaggle.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import importlib\n",
        "import json\n",
        "import os\n",
        "import platform\n",
        "import re\n",
        "import shutil\n",
        "import struct\n",
        "import subprocess\n",
        "import sys\n",
        "import tempfile\n",
        "import time\n",
        "from hashlib import sha256, sha512\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "LUM_MAGIC = b\"LUMV1\\x00\\x00\\x00\"\n",
        "FUNC_RE = re.compile(r\"^\\s*([a-zA-Z_][\\w\\s\\*]+?)\\s+([a-zA-Z_]\\w*)\\s*\\(([^;]*?)\\)\\s*;\\s*$\")\n",
        "\n",
        "KAGGLE_DEP_PATHS = [\n",
        "    Path('/kaggle/input/datasets/ndarray2000/nx47-dependencies'),\n",
        "    Path('/kaggle/input/nx47-dependencies'),\n",
        "    Path('/kaggle/input/lum-vorax-dependencies'),\n",
        "    Path('/kaggle/input/lumvorax-dependencies'),\n",
        "]\n",
        "SOURCE_SCAN_DIRS = [\n",
        "    Path('/kaggle/working/src/lum'), Path('/kaggle/working/src/file_formats'), Path('/kaggle/working/src/vorax'),\n",
        "    Path('/kaggle/working/src/logger'), Path('/kaggle/working/src/debug'),\n",
        "    Path('src/lum'), Path('src/file_formats'), Path('src/vorax'), Path('src/logger'), Path('src/debug'),\n",
        "]\n",
        "\n",
        "STRICT_NO_FALLBACK = os.environ.get(\"LUMVORAX_STRICT_NO_FALLBACK\", \"1\") == \"1\"\n",
        "REQUIRE_NATIVE = os.environ.get(\"LUMVORAX_REQUIRE_NATIVE\", \"1\") == \"1\"\n",
        "\n",
        "\n",
        "def now_ns() -> int:\n",
        "    return time.time_ns()\n",
        "\n",
        "\n",
        "def log_event(report: Dict[str, Any], step: str, **payload: Any) -> None:\n",
        "    report.setdefault(\"events\", []).append({\"ts_ns\": now_ns(), \"step\": step, **payload})\n",
        "\n",
        "\n",
        "def pkg_available(name: str) -> bool:\n",
        "    try:\n",
        "        importlib.import_module(name)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def install_offline_if_missing(pkg: str, report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    if pkg_available(pkg):\n",
        "        log_event(report, \"dependency_already_installed\", package=pkg)\n",
        "        return {\"package\": pkg, \"status\": \"already_installed\"}\n",
        "\n",
        "    py = sys.executable\n",
        "    exact = {\n",
        "        'numpy': 'numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "        'tifffile': 'tifffile-2026.1.28-py3-none-any.whl',\n",
        "        'imagecodecs': 'imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl',\n",
        "    }\n",
        "    last = 'not found'\n",
        "    for root in KAGGLE_DEP_PATHS:\n",
        "        if not root.exists():\n",
        "            log_event(report, \"dependency_path_absent\", package=pkg, root=str(root))\n",
        "            continue\n",
        "        wheel = root / exact.get(pkg, '')\n",
        "        try:\n",
        "            if wheel.exists():\n",
        "                cmd = [py, '-m', 'pip', 'install', '--disable-pip-version-check', '--no-index', str(wheel)]\n",
        "            else:\n",
        "                cmd = [py, '-m', 'pip', 'install', '--disable-pip-version-check', '--no-index', f'--find-links={root}', pkg]\n",
        "            log_event(report, \"dependency_install_attempt\", package=pkg, root=str(root), cmd=cmd)\n",
        "            subprocess.check_call(cmd)\n",
        "            if pkg_available(pkg):\n",
        "                log_event(report, \"dependency_install_ok\", package=pkg, root=str(root))\n",
        "                return {\"package\": pkg, \"status\": \"installed\", \"root\": str(root)}\n",
        "        except Exception as exc:\n",
        "            last = str(exc)\n",
        "            log_event(report, \"dependency_install_fail\", package=pkg, root=str(root), error=last)\n",
        "\n",
        "    return {\"package\": pkg, \"status\": \"missing\", \"error\": last}\n",
        "\n",
        "\n",
        "def scan_headers_and_functions(report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    modules, headers, funcs_total = [], 0, 0\n",
        "    for d in SOURCE_SCAN_DIRS:\n",
        "        if not d.exists() or not d.is_dir():\n",
        "            log_event(report, \"source_dir_missing\", directory=str(d))\n",
        "            continue\n",
        "        for h in sorted(d.glob('*.h')):\n",
        "            lines = h.read_text(encoding='utf-8', errors='replace').splitlines()\n",
        "            funcs = []\n",
        "            for ln in lines:\n",
        "                m = FUNC_RE.match(ln)\n",
        "                if m:\n",
        "                    funcs.append({'return': m.group(1).strip(), 'name': m.group(2), 'args': m.group(3).strip()})\n",
        "            modules.append({'header': str(h), 'function_count': len(funcs), 'functions': funcs[:30]})\n",
        "            headers += 1\n",
        "            funcs_total += len(funcs)\n",
        "    log_event(report, \"header_scan_done\", headers=headers, functions=funcs_total)\n",
        "    return {'summary': {'headers': headers, 'functions': funcs_total}, 'modules': modules}\n",
        "\n",
        "\n",
        "def smoke_compile_c_modules(report: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    gcc = shutil.which('gcc')\n",
        "    if not gcc:\n",
        "        if REQUIRE_NATIVE:\n",
        "            raise RuntimeError('gcc_not_found in strict native mode')\n",
        "        log_event(report, \"smoke_skipped\", reason=\"gcc_not_found\")\n",
        "        return [{'status': 'skipped', 'reason': 'gcc_not_found'}]\n",
        "\n",
        "    candidates = [\n",
        "        Path('/kaggle/working/src/lum/lum_core.c'), Path('/kaggle/working/src/file_formats/lum_native_universal_format.c'),\n",
        "        Path('/kaggle/working/src/file_formats/lum_native_file_handler.c'), Path('/kaggle/working/src/file_formats/lum_secure_serialization.c'),\n",
        "        Path('/kaggle/working/src/vorax/vorax_3d_volume.c'), Path('/kaggle/working/src/vorax/vorax_operations.c'),\n",
        "        Path('src/lum/lum_core.c'), Path('src/file_formats/lum_native_universal_format.c'),\n",
        "        Path('src/file_formats/lum_native_file_handler.c'), Path('src/file_formats/lum_secure_serialization.c'),\n",
        "        Path('src/vorax/vorax_3d_volume.c'), Path('src/vorax/vorax_operations.c'),\n",
        "    ]\n",
        "\n",
        "    existing = [c for c in candidates if c.exists()]\n",
        "    if not existing:\n",
        "        if REQUIRE_NATIVE:\n",
        "            raise RuntimeError('no_c_sources_found in strict native mode')\n",
        "        log_event(report, \"smoke_skipped\", reason=\"no_c_sources_found\")\n",
        "        return [{'status': 'skipped', 'reason': 'no_c_sources_found'}]\n",
        "\n",
        "    out = []\n",
        "    for c in existing:\n",
        "        cmd = [gcc, '-fsyntax-only', str(c), '-I', str(Path('src').resolve())]\n",
        "        t0 = now_ns()\n",
        "        r = subprocess.run(cmd, capture_output=True, text=True)\n",
        "        out.append({'file': str(c), 'status': 'ok' if r.returncode == 0 else 'fail', 'returncode': r.returncode, 'stderr_head': (r.stderr or '')[:2000]})\n",
        "        log_event(report, \"c_smoke_result\", file=str(c), returncode=r.returncode, elapsed_ns=now_ns() - t0)\n",
        "\n",
        "    failures = [x for x in out if x['status'] != 'ok']\n",
        "    if failures and REQUIRE_NATIVE:\n",
        "        raise RuntimeError(f'c_syntax_smoke_failed:{len(failures)}')\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def normalize_volume(arr):\n",
        "    import numpy as np\n",
        "    if arr.ndim == 2:\n",
        "        arr = arr[np.newaxis, :, :]\n",
        "    if arr.ndim != 3:\n",
        "        raise ValueError(f'Expected 2D/3D volume, got {arr.shape}')\n",
        "    return np.ascontiguousarray(arr.astype(np.float32, copy=False))\n",
        "\n",
        "\n",
        "def encode_lum_v1(arr3d):\n",
        "    z, h, w = arr3d.shape\n",
        "    payload = arr3d.tobytes()\n",
        "    digest16 = sha512(payload).digest()[:16]\n",
        "    header = struct.pack('<8sIII16s', LUM_MAGIC, z, h, w, digest16)\n",
        "    return header + payload\n",
        "\n",
        "\n",
        "def decode_lum_v1(blob: bytes):\n",
        "    import numpy as np\n",
        "    hs = struct.calcsize('<8sIII16s')\n",
        "    magic, z, h, w, digest16 = struct.unpack('<8sIII16s', blob[:hs])\n",
        "    if magic != LUM_MAGIC:\n",
        "        raise ValueError('invalid LUM magic')\n",
        "    payload = blob[hs:]\n",
        "    expected = int(z) * int(h) * int(w) * 4\n",
        "    if len(payload) != expected:\n",
        "        raise ValueError('payload size mismatch')\n",
        "    if sha512(payload).digest()[:16] != digest16:\n",
        "        raise ValueError('payload checksum mismatch')\n",
        "    return np.frombuffer(payload, dtype=np.float32).reshape((z, h, w))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def competitor_teacher_asset_test(report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    candidates = []\n",
        "    for root in KAGGLE_DEP_PATHS:\n",
        "        candidates.append(root / 'competitor_teacher_1407735.tif')\n",
        "        candidates.append(root / 'competitor_teacher_1407735.lum')\n",
        "\n",
        "    found = []\n",
        "    for c in candidates:\n",
        "        if c.exists():\n",
        "            b = c.read_bytes()\n",
        "            item = {\n",
        "                'path': str(c),\n",
        "                'size': len(b),\n",
        "                'sha256': sha256(b).hexdigest(),\n",
        "                'sha512': sha512(b).hexdigest(),\n",
        "            }\n",
        "            found.append(item)\n",
        "            log_event(report, 'competitor_asset_found', **item)\n",
        "\n",
        "    if not found:\n",
        "        log_event(report, 'competitor_assets_missing')\n",
        "        return {'status': 'fail', 'reason': 'competitor_teacher_assets_not_found'}\n",
        "\n",
        "    has_tif = any(x['path'].lower().endswith('.tif') for x in found)\n",
        "    has_lum = any(x['path'].lower().endswith('.lum') for x in found)\n",
        "    return {'status': 'ok' if (has_tif and has_lum) else 'fail', 'has_tif': has_tif, 'has_lum': has_lum, 'assets': found}\n",
        "\n",
        "def tiff_lum_roundtrip_test(report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    import numpy as np\n",
        "    import tifffile\n",
        "\n",
        "    tifffile = importlib.reload(tifffile)\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as td:\n",
        "        td = Path(td)\n",
        "        tif_path = td / 'synthetic_teacher.tif'\n",
        "        lum_path = td / 'synthetic_teacher.lum'\n",
        "\n",
        "        rng = np.random.default_rng(42)\n",
        "        vol = (rng.random((8, 32, 32)) > 0.87).astype(np.uint8)\n",
        "\n",
        "        write_errors = []\n",
        "        used = None\n",
        "        compressions = [('LZW', 'LZW')]\n",
        "        if not STRICT_NO_FALLBACK:\n",
        "            compressions.extend([('ADOBE_DEFLATE', 'ADOBE_DEFLATE'), ('NONE', None)])\n",
        "\n",
        "        for tag, comp in compressions:\n",
        "            try:\n",
        "                tifffile.imwrite(tif_path, vol, compression=comp)\n",
        "                used = tag\n",
        "                log_event(report, \"tiff_write_ok\", compression=tag)\n",
        "                break\n",
        "            except Exception as exc:\n",
        "                write_errors.append({'attempt': tag, 'error': str(exc)})\n",
        "                log_event(report, \"tiff_write_fail\", compression=tag, error=str(exc))\n",
        "\n",
        "        if used is None:\n",
        "            raise RuntimeError(f\"tiff_write_failed: {write_errors}\")\n",
        "\n",
        "        arr3d = normalize_volume(np.asarray(tifffile.imread(tif_path)))\n",
        "        blob = encode_lum_v1(arr3d)\n",
        "        lum_path.write_bytes(blob)\n",
        "        restored = decode_lum_v1(blob)\n",
        "\n",
        "        slice_logs = []\n",
        "        for z in range(restored.shape[0]):\n",
        "            s = restored[z]\n",
        "            slice_logs.append({'z': z, 'min': float(s.min()), 'max': float(s.max()), 'mean': float(s.mean()), 'std': float(s.std()), 'nonzero_pct': float((s > 0).mean() * 100.0)})\n",
        "\n",
        "        return {\n",
        "            'status': 'ok',\n",
        "            'strict_no_fallback': STRICT_NO_FALLBACK,\n",
        "            'shape': [int(x) for x in restored.shape],\n",
        "            'dtype': str(restored.dtype),\n",
        "            'global_min': float(restored.min()), 'global_max': float(restored.max()), 'global_mean': float(restored.mean()),\n",
        "            'global_nonzero_pct': float((restored > 0).mean() * 100.0),\n",
        "            'slice_logs': slice_logs,\n",
        "            'roundtrip_ok': bool(np.allclose(arr3d, restored, atol=0.0)),\n",
        "            'tiff_sha512': sha512(tif_path.read_bytes()).hexdigest(),\n",
        "            'lum_sha512': sha512(lum_path.read_bytes()).hexdigest(),\n",
        "            'tiff_sha256': sha256(tif_path.read_bytes()).hexdigest(),\n",
        "            'lum_sha256': sha256(lum_path.read_bytes()).hexdigest(),\n",
        "            'write_compression_used': used,\n",
        "            'forensic_write': {'write_errors': write_errors, 'write_compression_used': used},\n",
        "        }\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    t0 = now_ns()\n",
        "    report: Dict[str, Any] = {\n",
        "        'report_name': 'lumvorax_dependency_360_kaggle_single_cell_v3_complete',\n",
        "        'timestamp_ns': now_ns(),\n",
        "        'runtime': {\n",
        "            'python': sys.version,\n",
        "            'platform': platform.platform(),\n",
        "            'cwd': str(Path.cwd()),\n",
        "            'is_kaggle': Path('/kaggle').exists(),\n",
        "        },\n",
        "        'policy': {\n",
        "            'strict_no_fallback': STRICT_NO_FALLBACK,\n",
        "            'require_native': REQUIRE_NATIVE,\n",
        "        },\n",
        "        'events': [],\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        for pkg in ('numpy', 'tifffile', 'imagecodecs'):\n",
        "            report.setdefault('install_report', []).append(install_offline_if_missing(pkg, report))\n",
        "\n",
        "        report['imports'] = {p: pkg_available(p) for p in ('numpy', 'tifffile', 'imagecodecs', 'pyarrow')}\n",
        "        log_event(report, \"imports_checked\", imports=report['imports'])\n",
        "\n",
        "        report['dependency_dataset_paths'] = [\n",
        "            {'path': str(p), 'exists': p.exists(), 'files_count': (len(list(p.iterdir())) if p.exists() and p.is_dir() else 0)}\n",
        "            for p in KAGGLE_DEP_PATHS\n",
        "        ]\n",
        "        log_event(report, \"dataset_paths_checked\", paths=report['dependency_dataset_paths'])\n",
        "\n",
        "        report['module_inventory'] = scan_headers_and_functions(report)\n",
        "        if REQUIRE_NATIVE and report['module_inventory']['summary']['headers'] <= 0:\n",
        "            raise RuntimeError('no_native_headers_found')\n",
        "\n",
        "        report['c_syntax_smoke'] = smoke_compile_c_modules(report)\n",
        "        report['competitor_teacher_assets_test'] = competitor_teacher_asset_test(report)\n",
        "        if report['competitor_teacher_assets_test'].get('status') != 'ok':\n",
        "            raise RuntimeError('competitor_teacher_assets_missing_or_incomplete')\n",
        "        report['tiff_lum_roundtrip_test'] = tiff_lum_roundtrip_test(report)\n",
        "\n",
        "        report['status'] = 'ok'\n",
        "    except Exception as exc:\n",
        "        report['status'] = 'fail'\n",
        "        report['error_type'] = type(exc).__name__\n",
        "        report['error'] = str(exc)\n",
        "        log_event(report, \"fatal_error\", error_type=type(exc).__name__, error=str(exc))\n",
        "\n",
        "    report['elapsed_ns'] = now_ns() - t0\n",
        "    report['elapsed_s'] = report['elapsed_ns'] / 1_000_000_000\n",
        "\n",
        "    out = Path('/kaggle/working/lumvorax_360_validation_report_v3_complete.json')\n",
        "    if not out.parent.exists():\n",
        "        out = Path('lumvorax_360_validation_report_v3_complete.json')\n",
        "    out.write_text(json.dumps(report, indent=2), encoding='utf-8')\n",
        "\n",
        "    print(json.dumps({\n",
        "        'status': report.get('status'),\n",
        "        'error_type': report.get('error_type'),\n",
        "        'error': report.get('error'),\n",
        "        'report': str(out),\n",
        "        'module_headers': report.get('module_inventory', {}).get('summary', {}).get('headers'),\n",
        "        'public_functions': report.get('module_inventory', {}).get('summary', {}).get('functions'),\n",
        "        'roundtrip_status': report.get('tiff_lum_roundtrip_test', {}).get('status') if isinstance(report.get('tiff_lum_roundtrip_test'), dict) else None,\n",
        "        'write_compression_used': report.get('tiff_lum_roundtrip_test', {}).get('write_compression_used') if isinstance(report.get('tiff_lum_roundtrip_test'), dict) else None,\n",
        "        'events_count': len(report.get('events', [])),\n",
        "        'elapsed_ns': report.get('elapsed_ns'),\n",
        "    }, indent=2))\n",
        "\n",
        "    if report.get('status') != 'ok':\n",
        "        raise SystemExit(2)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}