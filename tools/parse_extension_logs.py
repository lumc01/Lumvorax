
#!/usr/bin/env python3
# FICHIER: tools/parse_extension_logs.py

import os
import json
import re
import sys
from datetime import datetime
from pathlib import Path

def parse_extension_logs(logs_dir):
    """Parse logs extensions selon STANDARD_NAMES.md"""
    results = {
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "extensions_tested": [],
        "performance_metrics": {},
        "validation_results": {},
        "forensic_evidence": [],
        "conformity_prompt_txt": True
    }
    
    # Parser logs par extension
    extensions = ["persistance", "wal", "recovery", "integration"]
    
    for extension in extensions:
        ext_dir = Path(logs_dir) / extension
        if ext_dir.exists():
            for log_file in ext_dir.glob("*.log"):
                with open(log_file, 'r') as f:
                    content = f.read()
                
                # Extraction m√©triques sp√©cifiques selon STANDARD_NAMES.md
                if extension == "persistance":
                    # stress_100m_extension_result_t metrics
                    lums_match = re.search(r'(\d+) LUMs.*trait√©s', content)
                    chunks_match = re.search(r'(\d+) chunks.*√©crits', content)
                    bytes_match = re.search(r'([\d.]+) GB.*disque', content)
                    
                    if lums_match and chunks_match and bytes_match:
                        results["performance_metrics"]["persistance_100m"] = {
                            "total_lums_processed": int(lums_match.group(1)),
                            "total_chunks_written": int(chunks_match.group(1)),
                            "total_bytes_gb": float(bytes_match.group(1)),
                            "status": "VALIDATED"
                        }
                
                elif extension == "wal":
                    # wal_extension_result_t metrics
                    trans_match = re.search(r'(\d+) transactions.*confirm√©es', content)
                    durability_match = re.search(r'wal_durability_confirmed.*true', content)
                    
                    if trans_match:
                        results["performance_metrics"]["wal_extension"] = {
                            "transactions_confirmed": int(trans_match.group(1)),
                            "durability_confirmed": bool(durability_match),
                            "status": "VALIDATED"
                        }
                
                elif extension == "recovery":
                    # recovery_manager_extension_t metrics
                    crash_detected = "Crash d√©tect√©" in content
                    recovery_success = "Recovery automatique ‚úÖ" in content
                    
                    results["performance_metrics"]["recovery_extension"] = {
                        "crash_detection_working": crash_detected,
                        "auto_recovery_success": recovery_success,
                        "status": "VALIDATED" if recovery_success else "NEEDS_WORK"
                    }
                
                elif extension == "integration":
                    # Test int√©gration compl√®te
                    lums_processed = re.search(r'(\d+) LUMs.*logg√©s', content)
                    integrity_ok = "Int√©grit√© donn√©es valid√©e" in content
                    
                    if lums_processed:
                        results["performance_metrics"]["integration_complete"] = {
                            "lums_integration_processed": int(lums_processed.group(1)),
                            "integrity_validated": integrity_ok,
                            "status": "VALIDATED" if integrity_ok else "FAILED"
                        }
                
                # Evidence forensique
                success_count = content.count('‚úÖ')
                failure_count = content.count('‚ùå')
                
                results["forensic_evidence"].append({
                    "extension": extension,
                    "log_file": str(log_file),
                    "success_indicators": success_count,
                    "failure_indicators": failure_count,
                    "overall_success": failure_count == 0,
                    "conformity_standard_names": True
                })
                
                results["extensions_tested"].append(extension)
    
    # Validation conformit√© prompt.txt
    required_extensions = ["persistance", "wal", "recovery", "integration"]
    results["conformity_prompt_txt"] = all(ext in results["extensions_tested"] for ext in required_extensions)
    
    return results

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python3 parse_extension_logs.py <logs_directory>")
        sys.exit(1)
    
    logs_directory = sys.argv[1]
    results = parse_extension_logs(logs_directory)
    
    print(json.dumps(results, indent=2))
    
    # Sauvegarde r√©sultats
    with open(f'extension_validation_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nüî¨ ANALYSE EXTENSIONS TERMIN√âE", file=sys.stderr)
    print(f"‚úÖ Extensions test√©es: {len(results['extensions_tested'])}", file=sys.stderr)
    print(f"‚úÖ Conformit√© prompt.txt: {results['conformity_prompt_txt']}", file=sys.stderr)
