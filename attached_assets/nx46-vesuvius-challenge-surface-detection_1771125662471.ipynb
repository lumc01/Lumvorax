{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117682,"databundleVersionId":15062069,"sourceType":"competition"},{"sourceId":14755914,"sourceType":"datasetVersion","datasetId":9431333},{"sourceId":14799025,"sourceType":"datasetVersion","datasetId":9462392},{"sourceId":14809675,"sourceType":"datasetVersion","datasetId":9470090}],"dockerImageVersionId":31260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":206.30043,"end_time":"2026-02-11T01:16:48.486286","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-02-11T01:13:22.185856","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================================================\n# 01) NX46-Vesuvius Challenge - Surface Detection\n# 02) Kaggle Vesuvius pipeline: discovery -> load -> features -> segment -> overlay -> package\n# 03) Robust offline dependencies + LZW-safe TIFF I/O + slice-wise adaptive fusion\n# ================================================================\nfrom __future__ import annotations\n\nimport gc\nimport importlib\nimport json\nimport os\nimport platform\nimport subprocess\nimport sys\nimport time\nimport zipfile\nfrom dataclasses import asdict, dataclass, field\nfrom hashlib import sha512\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, List, Tuple\n\nimport numpy as np\nfrom scipy.ndimage import (\n    binary_closing,\n    binary_propagation,\n    gaussian_filter,\n    generate_binary_structure,\n    label,\n    laplace,\n    sobel,\n    uniform_filter,\n)\n\nimport tifffile\n\ntry:\n    from PIL import Image, ImageSequence\nexcept Exception:  # pragma: no cover\n    Image = None\n    ImageSequence = None\n\n\ntry:\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\nexcept Exception:  # pragma: no cover\n    torch = None\n    nn = None\n    F = None\n\n\n@dataclass\nclass V139Config:\n    top_k_features: int = 6\n    train_max_samples: int = 250_000\n    l1_candidates: Tuple[float, ...] = (1e-4, 3e-4, 1e-3, 3e-3, 1e-2)\n    l2_candidates: Tuple[float, ...] = (1e-4, 1e-3, 1e-2)\n    max_iter: int = 120\n    lr: float = 0.08\n\n    pseudo_pos_pct: float = 99.0\n    pseudo_neg_pct: float = 50.0\n\n    z_radius: int = 3\n    xy_radius: int = 2\n\n    target_active_ratio: float = 0.03\n\n    max_layers: int = 320\n    overlay_stride: int = 8\n    full_pixel_trace: bool = False\n    trace_pixel_budget: int = 4000\n\n    ultra_console_log: bool = True\n    ultra_step_log: bool = True\n    ultra_bit_trace_arrays: bool = True\n    ultra_bit_trace_limit: int = 64\n\n    # V125: meta-neuron / evolutionary controls\n    meta_neurons: int = 3\n    ratio_candidates: Tuple[float, ...] = (0.02, 0.04, 0.06, 0.08, 0.12)\n    pruning_quantile: float = 0.25\n    mutation_noise: float = 0.015\n    f1_stagnation_window: int = 5\n    run_simulation_100: bool = False\n    simulation_export_curve: bool = True\n\n    # V125 supervised mode\n    supervised_train: bool = True\n    max_train_volumes: int = 24\n    max_val_volumes: int = 8\n    max_samples_per_volume: int = 40_000\n    pos_neg_ratio: float = 1.0\n    strong_th: float = 0.65\n    weak_th: float = 0.45\n    dust_min_size: int = 24\n    golden_nonce_topk: int = 11\n    supervised_epochs: int = 0\n    convergence_patience: int = 5\n    convergence_min_delta: float = 1e-6\n    auto_epoch_safety_cap: int = 0\n    threshold_scan: Tuple[float, ...] = (0.35, 0.4, 0.45, 0.5, 0.55, 0.6)\n    fbeta_beta: float = 0.5\n\n    # V131 2.5D U-Net competitive path\n    use_unet_25d: bool = True\n    unet_in_slices: int = 7\n    unet_base_channels: int = 24\n    patch_size: int = 128\n    patch_stride: int = 64\n    unet_epochs: int = 2\n    unet_lr: float = 1e-3\n    unet_batch_size: int = 8\n\n    # Logit forensic audit\n    export_logit_audit: bool = True\n    logit_hist_bins: int = 20\n\n    # V131 forensic integration (V130 logs + concurrent benchmark)\n    v130_log_path: str = 'nx47-vesu-kernel-new-v130.log'\n    export_forensic_v139_report: bool = True\n\n    # V133 strict continuity + no fallback policy\n    enforce_nx_legacy_continuity: bool = True\n    strict_no_fallback: bool = True\n    min_train_pairs_required: int = 786\n    require_train_completion_100: bool = True\n    forbid_autonomous_mode: bool = True\n    enforce_no_hardcoded_metrics: bool = True\n    hardcoded_metric_policy: str = \"warn\"  # warn|error\n    adapt_train_threshold_to_dataset_size: bool = True\n    train_pair_coverage_target_pct: float = 100.0\n    min_train_image_files_required: int = 786\n    min_train_label_files_required: int = 786\n    enforce_competition_rules: bool = True\n    competition_rules_path: str = \"Competition_Rules_Vesuvius_Challenge _Surface_Detection.md\"\n    metric_demo_notebook_path: str = \"vesuvius-2025-metric-demo.ipynb\"\n\n    # V138 execution hardening\n    preflight_train_pct: float = 5.0\n    preflight_test_pct: float = 5.0\n    progress_bar_width: int = 24\n    heartbeat_interval_s: float = 30.0\n    stage_stall_alert_s: float = 180.0\n    run_ablation_check: bool = True\n    stability_probe_runs: int = 0\n\n\n@dataclass\nclass PlanStep:\n    name: str\n    description: str\n    progress: float = 0.0\n    done: bool = False\n\n\n@dataclass\nclass PlanTracker:\n    output_path: Path\n    steps: List[PlanStep] = field(default_factory=list)\n\n    def add_step(self, name: str, description: str) -> None:\n        self.steps.append(PlanStep(name=name, description=description))\n\n    def update(self, name: str, progress: float, done: bool = False) -> None:\n        for step in self.steps:\n            if step.name == name:\n                step.progress = float(np.clip(progress, 0.0, 100.0))\n                step.done = done\n                break\n        self._write()\n\n    def overall_progress(self) -> float:\n        return float(np.mean([s.progress for s in self.steps])) if self.steps else 0.0\n\n    def _write(self) -> None:\n        payload = {\n            \"generated_at_ns\": time.time_ns(),\n            \"roadmap\": [\n                {\n                    \"name\": s.name,\n                    \"description\": s.description,\n                    \"progress_percent\": round(s.progress, 2),\n                    \"done\": s.done,\n                }\n                for s in self.steps\n            ],\n            \"overall_progress_percent\": round(self.overall_progress(), 2),\n        }\n        self.output_path.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n\n\nclass MemoryTracker:\n    def __init__(self) -> None:\n        self.events: List[Dict[str, Any]] = []\n\n    def log_array(self, stage: str, arr: np.ndarray) -> None:\n        arr = np.asarray(arr)\n        self.events.append(\n            {\n                \"ts_ns\": time.time_ns(),\n                \"stage\": stage,\n                \"shape\": list(arr.shape),\n                \"dtype\": str(arr.dtype),\n                \"bytes\": int(arr.nbytes),\n                \"min\": float(arr.min()) if arr.size else 0.0,\n                \"max\": float(arr.max()) if arr.size else 0.0,\n                \"mean\": float(arr.mean()) if arr.size else 0.0,\n                \"sha512\": sha512(arr.tobytes()).hexdigest(),\n            }\n        )\n\n\nclass UltraAuthentic360Merkle:\n    def __init__(self, path: Path, console: bool = True) -> None:\n        self.path = path\n        self.console = console\n        self.prev_hash = \"0\" * 128\n        self.path.parent.mkdir(parents=True, exist_ok=True)\n        self.path.write_text(\"\", encoding=\"utf-8\")\n\n    def bit_stats(self, arr: np.ndarray, bit_limit: int) -> Dict[str, Any]:\n        raw = np.asarray(arr).tobytes()\n        preview = raw[: max(0, int(bit_limit))]\n        ones = int(sum(bin(b).count(\"1\") for b in preview))\n        return {\n            \"byte_preview_len\": len(preview),\n            \"one_bits_in_preview\": ones,\n            \"zero_bits_in_preview\": len(preview) * 8 - ones,\n            \"preview_sha512\": sha512(preview).hexdigest(),\n        }\n\n    def emit(self, event: Dict[str, Any]) -> None:\n        payload = dict(event)\n        payload[\"prev_merkle\"] = self.prev_hash\n        canonical = json.dumps(payload, sort_keys=True, default=str)\n        cur = sha512(canonical.encode()).hexdigest()\n        payload[\"merkle\"] = cur\n        self.prev_hash = cur\n        line = json.dumps(payload, ensure_ascii=False)\n        with self.path.open(\"a\", encoding=\"utf-8\") as f:\n            f.write(line + \"\\n\")\n        if self.console:\n            print(line, flush=True)\n\n\ndef install_offline(package_name: str) -> None:\n    exact_wheel_dir = Path(\"/kaggle/input/datasets/ndarray2000/nx47-dependencies\")\n    fallback_wheel_dir = Path(\"/kaggle/input/nx47-dependencies\")\n\n    exact_wheels = {\n        \"imagecodecs\": exact_wheel_dir / \"imagecodecs-2026.1.14-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n        \"numpy\": exact_wheel_dir / \"numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\",\n        \"tifffile\": exact_wheel_dir / \"tifffile-2026.1.28-py3-none-any.whl\",\n    }\n\n    if package_name == \"numpy\":\n        try:\n            import numpy as _np  # noqa\n            return\n        except Exception:\n            pass\n\n    if package_name in exact_wheels and exact_wheels[package_name].exists():\n        try:\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", str(exact_wheels[package_name])])\n            return\n        except subprocess.CalledProcessError:\n            pass\n\n    for wheel_dir in (exact_wheel_dir, fallback_wheel_dir):\n        if wheel_dir.exists():\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-index\", f\"--find-links={wheel_dir}\", package_name])\n            return\n\n    raise RuntimeError(f\"Offline dependency directory not found for {package_name}\")\n\n\ndef bootstrap_dependencies_fail_fast() -> None:\n    install_offline(\"numpy\")\n    install_offline(\"imagecodecs\")\n    install_offline(\"tifffile\")\n    global tifffile\n    tifffile = importlib.reload(tifffile)\n\n\ndef ensure_imagecodecs() -> bool:\n    try:\n        import imagecodecs  # noqa\n        return True\n    except Exception:\n        pass\n    try:\n        install_offline(\"imagecodecs\")\n        import imagecodecs  # noqa\n        global tifffile\n        tifffile = importlib.reload(tifffile)\n        return True\n    except Exception:\n        return False\n\n\ndef read_tiff_lzw_safe(path: Path) -> np.ndarray:\n    try:\n        return tifffile.imread(path)\n    except ValueError as exc:\n        if \"requires the 'imagecodecs' package\" not in str(exc):\n            raise\n\n    ensure_imagecodecs()\n    try:\n        return tifffile.imread(path)\n    except ValueError as exc:\n        if \"requires the 'imagecodecs' package\" not in str(exc):\n            raise\n\n    if Image is None or ImageSequence is None:\n        raise RuntimeError(\"LZW TIFF read failed and Pillow fallback unavailable\")\n    with Image.open(path) as img:\n        frames = [np.array(frame, dtype=np.float32) for frame in ImageSequence.Iterator(img)]\n    if not frames:\n        raise RuntimeError(f\"No frames decoded from TIFF: {path}\")\n    return np.stack(frames, axis=0)\n\n\ndef write_tiff_lzw_safe(path: Path, arr: np.ndarray) -> None:\n    arr = np.asarray(arr)\n    if arr.ndim == 2:\n        arr = arr[np.newaxis, ...]\n    if arr.ndim != 3:\n        raise RuntimeError(f\"Unsupported TIFF array shape for write: {arr.shape}\")\n\n    try:\n        if ensure_imagecodecs():\n            tifffile.imwrite(path, arr, compression=\"LZW\")\n            return\n    except Exception:\n        pass\n\n    if Image is None:\n        raise RuntimeError(\"LZW TIFF write failed: Pillow fallback unavailable\")\n\n    pages = [Image.fromarray(frame.astype(np.uint8)) for frame in arr]\n    if not pages:\n        raise RuntimeError(\"Cannot write empty TIFF volume\")\n    pages[0].save(path, save_all=True, append_images=pages[1:], compression=\"tiff_lzw\")\n\n\nclass NX47AtomNeuron:\n    def __init__(self, n_features: int) -> None:\n        self.w = np.zeros(n_features, dtype=np.float64)\n        self.alpha = np.zeros(n_features, dtype=np.float64)\n        self.beta = np.zeros(n_features, dtype=np.float64)\n        self.b = 0.0\n\n    @staticmethod\n    def _sigmoid(z: np.ndarray) -> np.ndarray:\n        z = np.clip(z, -30, 30)\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def predict_proba(self, x: np.ndarray, grad_x: np.ndarray | None = None) -> np.ndarray:\n        gx = grad_x if grad_x is not None else np.gradient(x, axis=0)\n        z = x @ self.w + (x * x) @ self.alpha + gx @ self.beta + self.b\n        return self._sigmoid(z)\n\n    def fit_prox(self, x: np.ndarray, y: np.ndarray, lr: float, max_iter: int, l1: float, l2: float, progress_cb: Callable[..., None] | None = None, progress_prefix: Dict[str, Any] | None = None) -> Dict[str, float]:\n        n = max(1, x.shape[0])\n        gx = np.gradient(x, axis=0)\n        active_start = int(np.sum((np.abs(self.w) + np.abs(self.alpha) + np.abs(self.beta)) > 1e-8))\n        w_start = self.w.copy()\n        a_start = self.alpha.copy()\n        beta_start = self.beta.copy()\n        active_mid = active_start\n        for it in range(max_iter):\n            p = self.predict_proba(x, gx)\n            err = p - y\n            grad_w = (x.T @ err) / n + l2 * self.w\n            grad_alpha = ((x * x).T @ err) / n + l2 * self.alpha\n            grad_beta = (gx.T @ err) / n + l2 * self.beta\n            grad_b = float(np.mean(err))\n            if progress_cb is not None and ((it + 1) % 10 == 0 or it == 0 or (it + 1) == max_iter):\n                payload = dict(progress_prefix or {})\n                payload.update({'substage': 'fit_prox_iter', 'iter': int(it + 1), 'max_iter': int(max_iter), 'iter_progress_percent': float(100.0 * (it + 1) / max(1, max_iter))})\n                progress_cb(**payload)\n\n            w_temp = self.w - lr * grad_w\n            a_temp = self.alpha - lr * grad_alpha\n            b_temp = self.beta - lr * grad_beta\n            self.w = np.sign(w_temp) * np.maximum(np.abs(w_temp) - lr * l1, 0.0)\n            self.alpha = np.sign(a_temp) * np.maximum(np.abs(a_temp) - lr * l1, 0.0)\n            self.beta = np.sign(b_temp) * np.maximum(np.abs(b_temp) - lr * l1, 0.0)\n            self.b -= lr * grad_b\n            if it == max_iter // 2:\n                active_mid = int(np.sum((np.abs(self.w) + np.abs(self.alpha) + np.abs(self.beta)) > 1e-8))\n        p = self.predict_proba(x, gx)\n        eps = 1e-9\n        ce = -float(np.mean(y * np.log(p + eps) + (1.0 - y) * np.log(1.0 - p + eps)))\n        active_end = int(np.sum((np.abs(self.w) + np.abs(self.alpha) + np.abs(self.beta)) > 1e-8))\n        return {\n            \"cross_entropy\": ce,\n            \"non_zero_weights\": active_end,\n            \"active_neurons_start\": active_start,\n            \"active_neurons_mid\": active_mid,\n            \"active_neurons_end\": active_end,\n            \"weight_delta_l2\": float(np.linalg.norm(self.w - w_start)),\n            \"alpha_delta_l2\": float(np.linalg.norm(self.alpha - a_start)),\n            \"beta_delta_l2\": float(np.linalg.norm(self.beta - beta_start)),\n        }\n\n\n@dataclass\nclass NX47EvolutionMemory:\n    f1_history: List[float] = field(default_factory=list)\n    ratio_history: List[float] = field(default_factory=list)\n    mutation_events: int = 0\n    pruning_events: int = 0\n\n    def update(self, f1_proxy: float, ratio: float) -> None:\n        self.f1_history.append(float(f1_proxy))\n        self.ratio_history.append(float(ratio))\n\n    def adapt_learning_rate(self, base_lr: float, window: int) -> float:\n        if len(self.f1_history) < max(2, window):\n            return float(base_lr)\n        recent = self.f1_history[-window:]\n        spread = float(np.max(recent) - np.min(recent))\n        return float(base_lr * (0.65 if spread < 1e-3 else 1.0))\n\n\ndef compute_proxy_f1(prob: np.ndarray, target: np.ndarray, threshold: float = 0.5) -> float:\n    pred = prob >= threshold\n    tp = float(np.logical_and(pred, target > 0.5).sum())\n    fp = float(np.logical_and(pred, target <= 0.5).sum())\n    fn = float(np.logical_and(~pred, target > 0.5).sum())\n    precision = tp / (tp + fp + 1e-9)\n    recall = tp / (tp + fn + 1e-9)\n    return float(2.0 * precision * recall / (precision + recall + 1e-9))\n\n\ndef choose_adaptive_ratio(prob: np.ndarray, ratios: Tuple[float, ...]) -> Tuple[np.ndarray, Dict[str, Any]]:\n    best_ratio = float(ratios[0])\n    best_score = -1e18\n    best_mask = calibrate_target_ratio(prob, best_ratio)\n    details: List[Dict[str, float]] = []\n    for r in ratios:\n        cand = calibrate_target_ratio(prob, float(r))\n        lbl, comp_count = label(cand.astype(np.uint8))\n        comp_sizes = np.bincount(lbl.ravel()) if comp_count > 0 else np.array([0])\n        coherence = float(cand.mean())\n        noise = float((comp_sizes[1:] < 16).sum()) if comp_count > 0 else 0.0\n        score = coherence - 0.001 * noise\n        details.append({'ratio': float(r), 'score': score, 'coherence': coherence, 'noise_components': noise})\n        if score > best_score:\n            best_score = score\n            best_ratio = float(r)\n            best_mask = cand\n    return best_mask.astype(bool), {'selected_ratio': best_ratio, 'ratio_scan': details}\n\n\ndef choose_slicewise_adaptive_ratio(volume: np.ndarray, prob: np.ndarray, ratios: Tuple[float, ...]) -> Dict[str, Any]:\n    # ratio(x,y,z) proxy: each z slice votes a ratio according to entropy/gradient complexity\n    ent = np.log1p(np.maximum(volume.var(axis=(1, 2)), 1e-12))\n    gx = np.mean(np.abs(np.gradient(volume, axis=1)), axis=(1, 2))\n    gy = np.mean(np.abs(np.gradient(volume, axis=2)), axis=(1, 2))\n    complexity = _zscore(ent + gx + gy)\n    ratios_arr = np.array(ratios, dtype=np.float64)\n    bins = np.linspace(complexity.min() - 1e-9, complexity.max() + 1e-9, len(ratios_arr) + 1)\n    assigned = []\n    for c in complexity:\n        idx = int(np.clip(np.digitize(c, bins) - 1, 0, len(ratios_arr) - 1))\n        assigned.append(float(ratios_arr[idx]))\n    ratio_global = float(np.mean(assigned))\n    ratio_global = float(ratios_arr[np.argmin(np.abs(ratios_arr - ratio_global))])\n    mask_global = calibrate_target_ratio(prob, ratio_global)\n    return {\n        'slice_ratio_profile': assigned,\n        'slice_ratio_mean': float(np.mean(assigned)),\n        'slice_ratio_std': float(np.std(assigned)),\n        'ratio_global_selected': ratio_global,\n        'mask_global': mask_global,\n    }\n\n\ndef dynamic_regularization_lambda(mask: np.ndarray, features: np.ndarray) -> float:\n    var_mask = float(np.var(mask.astype(np.float32)))\n    feat_entropy = float(np.mean(np.log1p(np.maximum(np.var(features, axis=(1, 2)), 1e-12))))\n    return float(var_mask / (abs(feat_entropy) + 1e-8))\n\n\ndef simulate_f1_vs_ratio_curve() -> Dict[str, Any]:\n    ratios = np.linspace(0.01, 0.25, 50)\n    precision = np.clip(1.0 - (ratios * 2.0), 0.01, 1.0)\n    recall = np.clip(ratios * 4.0, 0.01, 1.0)\n    f1_scores = 2.0 * precision * recall / (precision + recall + 1e-8)\n    best_idx = int(np.argmax(f1_scores))\n    return {\n        'ratios': ratios.tolist(),\n        'f1_scores': f1_scores.tolist(),\n        'best_ratio': float(ratios[best_idx]),\n        'best_f1': float(f1_scores[best_idx]),\n    }\n\n\ndef _zscore(arr: np.ndarray) -> np.ndarray:\n    m, s = float(arr.mean()), float(arr.std())\n    return (arr - m) / (s + 1e-6)\n\n\ndef slice_adaptive_fusion(volume: np.ndarray) -> np.ndarray:\n    z = volume.shape[0]\n    if z <= 1:\n        return volume[0]\n    w = np.linspace(1.0, 1.4, z, dtype=np.float32)\n    w = w / (w.sum() + 1e-6)\n    return np.tensordot(w, volume, axes=(0, 0)).astype(np.float32)\n\n\ndef extract_multi_features(volume: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n    fused = slice_adaptive_fusion(volume)\n    proj_mean = 0.7 * np.mean(volume, axis=0) + 0.3 * fused\n    proj_max = np.max(volume, axis=0)\n    gx, gy = sobel(proj_mean, axis=1), sobel(proj_mean, axis=0)\n    grad_mag = np.sqrt(gx * gx + gy * gy)\n    lap = laplace(proj_mean)\n    mu = uniform_filter(proj_mean, size=7)\n    mu2 = uniform_filter(proj_mean * proj_mean, size=7)\n    local_var = np.maximum(mu2 - mu * mu, 0.0)\n    local_entropy = np.log1p(local_var * 255.0)\n    coherence = 1.0 / (1.0 + np.std(volume, axis=0))\n    low = gaussian_filter(proj_mean, sigma=3.0)\n    high = proj_mean - gaussian_filter(proj_mean, sigma=1.0)\n    bandpass = high + (proj_mean - low)\n\n    feats = [proj_mean, proj_max, grad_mag, lap, local_var, local_entropy, coherence, bandpass]\n    names = [\"proj_mean\", \"proj_max\", \"grad_mag\", \"laplace\", \"local_var\", \"local_entropy\", \"coherence_inter_slice\", \"bandpass_response\"]\n    feats = [_zscore(f.astype(np.float32)) for f in feats]\n    return np.stack(feats, axis=0), names\n\n\ndef auto_select_features(features: np.ndarray, names: List[str], top_k: int) -> Tuple[np.ndarray, List[str], np.ndarray]:\n    variances = np.array([float(np.var(features[i])) for i in range(features.shape[0])], dtype=np.float64)\n    order = np.argsort(variances)[::-1]\n    selected, selected_names = [], []\n    for idx in order:\n        cand = features[idx].ravel()\n        keep = True\n        for s in selected:\n            c = np.corrcoef(cand, s.ravel())[0, 1]\n            if np.isfinite(c) and abs(c) >= 0.97:\n                keep = False\n                break\n        if keep:\n            selected.append(features[idx])\n            selected_names.append(names[idx])\n        if len(selected) >= top_k:\n            break\n    if not selected:\n        selected = [features[order[0]]]\n        selected_names = [names[order[0]]]\n    return np.stack(selected, axis=0), selected_names, variances\n\n\ndef pseudo_labels(score_map: np.ndarray, pos_pct: float, neg_pct: float) -> Tuple[np.ndarray, np.ndarray]:\n    flat = score_map.ravel()\n    pos = flat > np.percentile(flat, pos_pct)\n    neg = flat < np.percentile(flat, neg_pct)\n    keep = pos | neg\n    y = np.zeros_like(flat, dtype=np.float64)\n    y[pos] = 1.0\n    return keep, y\n\n\ndef _binary_stats(pred: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n    p = pred.astype(bool)\n    t = y.astype(bool)\n    tp = float(np.logical_and(p, t).sum())\n    fp = float(np.logical_and(p, ~t).sum())\n    fn = float(np.logical_and(~p, t).sum())\n    iou = tp / (tp + fp + fn + 1e-9)\n    dice = (2.0 * tp) / (2.0 * tp + fp + fn + 1e-9)\n    f1 = dice\n    return {'tp': tp, 'fp': fp, 'fn': fn, 'iou': iou, 'dice': dice, 'f1': f1}\n\n\ndef _fbeta_from_stats(stats: Dict[str, float], beta: float) -> float:\n    tp, fp, fn = stats['tp'], stats['fp'], stats['fn']\n    precision = tp / (tp + fp + 1e-9)\n    recall = tp / (tp + fn + 1e-9)\n    b2 = beta * beta\n    return float((1.0 + b2) * precision * recall / (b2 * precision + recall + 1e-9))\n\n\ndef calibrate_thresholds(y_true: np.ndarray, prob: np.ndarray, thresholds: Tuple[float, ...], beta: float) -> Dict[str, Any]:\n    rows: List[Dict[str, float]] = []\n    best = None\n    for th in thresholds:\n        pred = prob >= float(th)\n        stats = _binary_stats(pred, y_true > 0.5)\n        fbeta = _fbeta_from_stats(stats, beta)\n        rec = {'threshold': float(th), 'f1': float(stats['f1']), 'iou': float(stats['iou']), 'dice': float(stats['dice']), 'fbeta': float(fbeta)}\n        rows.append(rec)\n        if best is None or rec['fbeta'] > best['fbeta']:\n            best = rec\n    return {'best': best, 'scan': rows}\n\n\n\n\nclass _TinyUNet2p5D(nn.Module if nn is not None else object):\n    def __init__(self, in_ch: int, base: int = 24) -> None:\n        if nn is None:\n            return\n        super().__init__()\n        self.enc1 = nn.Sequential(nn.Conv2d(in_ch, base, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base, base, 3, padding=1), nn.ReLU(inplace=True))\n        self.enc2 = nn.Sequential(nn.Conv2d(base, base * 2, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base * 2, base * 2, 3, padding=1), nn.ReLU(inplace=True))\n        self.pool = nn.MaxPool2d(2)\n        self.bottleneck = nn.Sequential(nn.Conv2d(base * 2, base * 4, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base * 4, base * 4, 3, padding=1), nn.ReLU(inplace=True))\n        self.up2 = nn.ConvTranspose2d(base * 4, base * 2, 2, stride=2)\n        self.dec2 = nn.Sequential(nn.Conv2d(base * 4, base * 2, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base * 2, base * 2, 3, padding=1), nn.ReLU(inplace=True))\n        self.up1 = nn.ConvTranspose2d(base * 2, base, 2, stride=2)\n        self.dec1 = nn.Sequential(nn.Conv2d(base * 2, base, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(base, base, 3, padding=1), nn.ReLU(inplace=True))\n        self.head = nn.Conv2d(base, 1, 1)\n\n    def forward(self, x: 'torch.Tensor') -> 'torch.Tensor':\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        b = self.bottleneck(self.pool(e2))\n        d2 = self.up2(b)\n        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n        d1 = self.up1(d2)\n        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n        return self.head(d1)\n\n\ndef _extract_2p5d_patches(vol: np.ndarray, lbl2d: np.ndarray, cfg: V139Config, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray]:\n    z, h, w = vol.shape\n    c = max(3, int(cfg.unet_in_slices))\n    if c % 2 == 0:\n        c += 1\n    half = c // 2\n    ps = int(cfg.patch_size)\n    st = int(cfg.patch_stride)\n    xs: List[np.ndarray] = []\n    ys: List[np.ndarray] = []\n    z_center = z // 2\n    for y0 in range(0, max(1, h - ps + 1), st):\n        for x0 in range(0, max(1, w - ps + 1), st):\n            z0 = max(0, z_center - half)\n            z1 = min(z, z_center + half + 1)\n            stack = vol[z0:z1, y0:y0 + ps, x0:x0 + ps]\n            if stack.shape[0] < c:\n                pad = np.repeat(stack[-1:, :, :], c - stack.shape[0], axis=0)\n                stack = np.concatenate([stack, pad], axis=0)\n            if stack.shape[1] != ps or stack.shape[2] != ps:\n                continue\n            lab = lbl2d[y0:y0 + ps, x0:x0 + ps]\n            if lab.shape != (ps, ps):\n                continue\n            xs.append(stack.astype(np.float32))\n            ys.append(lab.astype(np.float32))\n    if not xs:\n        return np.zeros((0, c, ps, ps), dtype=np.float32), np.zeros((0, ps, ps), dtype=np.float32)\n    x_arr = np.stack(xs, axis=0)\n    y_arr = np.stack(ys, axis=0)\n    order = rng.permutation(x_arr.shape[0])\n    return x_arr[order], y_arr[order]\n\n\ndef _dice_loss_from_logits(logits: 'torch.Tensor', target: 'torch.Tensor') -> 'torch.Tensor':\n    prob = torch.sigmoid(logits)\n    inter = (prob * target).sum(dim=(1, 2, 3))\n    den = prob.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) + 1e-6\n    return 1.0 - (2.0 * inter + 1e-6) / den\n\n\ndef train_unet_25d_supervised(train_x: np.ndarray, train_y: np.ndarray, val_x: np.ndarray, val_y: np.ndarray, cfg: V139Config, rng: np.random.Generator) -> Dict[str, Any]:\n    if torch is None or nn is None:\n        return {'status': 'torch_unavailable'}\n    if train_x.shape[0] == 0 or val_x.shape[0] == 0:\n        return {'status': 'empty_patch_set'}\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = _TinyUNet2p5D(in_ch=train_x.shape[1], base=cfg.unet_base_channels).to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=float(cfg.unet_lr))\n    bce = nn.BCEWithLogitsLoss()\n\n    def make_batches(x: np.ndarray, y: np.ndarray, bs: int):\n        for i in range(0, x.shape[0], bs):\n            xb = torch.from_numpy(x[i:i+bs]).to(device)\n            yb = torch.from_numpy(y[i:i+bs])[:, None, :, :].to(device)\n            yield xb, yb\n\n    hist = []\n    best = {'fbeta': -1.0}\n    for ep in range(max(1, int(cfg.unet_epochs))):\n        model.train()\n        losses = []\n        for xb, yb in make_batches(train_x, train_y, int(cfg.unet_batch_size)):\n            opt.zero_grad()\n            lg = model(xb)\n            loss = 0.5 * bce(lg, yb) + 0.5 * _dice_loss_from_logits(lg, yb).mean()\n            loss.backward()\n            opt.step()\n            losses.append(float(loss.detach().cpu().item()))\n\n        model.eval()\n        probs = []\n        ys = []\n        with torch.no_grad():\n            for xb, yb in make_batches(val_x, val_y, int(cfg.unet_batch_size)):\n                lg = model(xb)\n                pb = torch.sigmoid(lg).detach().cpu().numpy()[:, 0]\n                probs.append(pb)\n                ys.append(yb.detach().cpu().numpy()[:, 0])\n        prob = np.concatenate(probs, axis=0).reshape(-1)\n        ytrue = np.concatenate(ys, axis=0).reshape(-1)\n        th_info = calibrate_thresholds(ytrue, prob, cfg.threshold_scan, cfg.fbeta_beta)\n        stat = _binary_stats(prob >= th_info['best']['threshold'], ytrue > 0.5)\n        fbeta = _fbeta_from_stats(stat, cfg.fbeta_beta)\n        row = {\n            'epoch': ep,\n            'train_loss': float(np.mean(losses)) if losses else 0.0,\n            'val_f1': float(stat['f1']),\n            'val_iou': float(stat['iou']),\n            'val_fbeta': float(fbeta),\n            'best_threshold': float(th_info['best']['threshold']),\n        }\n        hist.append(row)\n        if fbeta > best['fbeta']:\n            best = {**row, 'fbeta': float(fbeta)}\n\n    return {\n        'status': 'ok',\n        'epoch_history': hist,\n        'best': best,\n        'threshold_scan_last': th_info['scan'],\n        'model_state': {k: v.detach().cpu().numpy().tolist()[:1] if v.ndim > 0 else float(v.detach().cpu().item()) for k, v in model.state_dict().items()},\n    }\n\n\ndef audit_logits_distribution(prob: np.ndarray, y_true: np.ndarray | None, bins: int) -> Dict[str, Any]:\n    flat = prob.reshape(-1)\n    hist, edges = np.histogram(flat, bins=max(5, int(bins)), range=(0.0, 1.0))\n    payload: Dict[str, Any] = {\n        'min': float(flat.min()) if flat.size else 0.0,\n        'max': float(flat.max()) if flat.size else 0.0,\n        'mean': float(flat.mean()) if flat.size else 0.0,\n        'std': float(flat.std()) if flat.size else 0.0,\n        'hist_counts': hist.tolist(),\n        'hist_edges': edges.tolist(),\n    }\n    if y_true is not None:\n        y = y_true.reshape(-1) > 0.5\n        if np.any(y):\n            payload['pos_mean'] = float(flat[y].mean())\n            payload['pos_std'] = float(flat[y].std())\n        if np.any(~y):\n            payload['neg_mean'] = float(flat[~y].mean())\n            payload['neg_std'] = float(flat[~y].std())\n    return payload\n\ndef _balance_sample_indices(y: np.ndarray, max_samples: int, pos_neg_ratio: float, rng: np.random.Generator) -> np.ndarray:\n    pos_idx = np.where(y > 0.5)[0]\n    neg_idx = np.where(y <= 0.5)[0]\n    if pos_idx.size == 0 or neg_idx.size == 0:\n        all_idx = np.arange(y.size)\n        if all_idx.size <= max_samples:\n            return all_idx\n        return rng.choice(all_idx, size=max_samples, replace=False)\n    n_pos = min(pos_idx.size, int(max_samples * (pos_neg_ratio / (1.0 + pos_neg_ratio))))\n    n_neg = min(neg_idx.size, max_samples - n_pos)\n    sel_pos = rng.choice(pos_idx, size=max(1, n_pos), replace=pos_idx.size < max(1, n_pos))\n    sel_neg = rng.choice(neg_idx, size=max(1, n_neg), replace=neg_idx.size < max(1, n_neg))\n    idx = np.concatenate([sel_pos, sel_neg])\n    rng.shuffle(idx)\n    return idx\n\n\ndef train_nx47_supervised(\n    x_train: np.ndarray,\n    y_train: np.ndarray,\n    x_val: np.ndarray,\n    y_val: np.ndarray,\n    cfg: V139Config,\n    rng: np.random.Generator,\n    memory: NX47EvolutionMemory,\n    progress_cb: Callable[..., None] | None = None,\n) -> Tuple[NX47AtomNeuron, Dict[str, Any]]:\n    best, best_state = None, None\n    leaderboard: List[Dict[str, Any]] = []\n    epoch_history: List[Dict[str, Any]] = []\n    adaptive_lr = memory.adapt_learning_rate(cfg.lr, cfg.f1_stagnation_window)\n    grad_x_val = np.gradient(x_val, axis=0)\n\n    epoch = 0\n    best_obj_seen = None\n    stagnation = 0\n    while True:\n        total_candidates = max(1, max(1, cfg.meta_neurons) * len(cfg.l1_candidates) * len(cfg.l2_candidates))\n        candidate_idx = 0\n        for neuron_id in range(max(1, cfg.meta_neurons)):\n            for l1 in cfg.l1_candidates:\n                for l2 in cfg.l2_candidates:\n                    candidate_idx += 1\n                    if progress_cb is not None and (candidate_idx == 1 or candidate_idx % 3 == 0 or candidate_idx == total_candidates):\n                        progress_cb(\n                            stage='train_supervised',\n                            pct=100.0 * candidate_idx / total_candidates,\n                            substage='hyperparam_search',\n                            file_name='',\n                            index=candidate_idx,\n                            total=total_candidates,\n                            epoch=int(epoch),\n                            neuron_id=int(neuron_id),\n                            l1=float(l1),\n                            l2=float(l2),\n                        )\n                    m = NX47AtomNeuron(n_features=x_train.shape[1])\n                    tr = m.fit_prox(x_train, y_train, lr=adaptive_lr, max_iter=cfg.max_iter, l1=float(l1), l2=float(l2), progress_cb=progress_cb, progress_prefix={'stage': 'train_supervised', 'pct': 100.0 * candidate_idx / total_candidates, 'index': candidate_idx, 'total': total_candidates, 'epoch': int(epoch), 'neuron_id': int(neuron_id), 'l1': float(l1), 'l2': float(l2)})\n                    p = m.predict_proba(x_val, grad_x_val)\n                    ce = -float(np.mean(y_val * np.log(p + 1e-9) + (1.0 - y_val) * np.log(1.0 - p + 1e-9)))\n                    threshold_info = calibrate_thresholds(y_val, p, cfg.threshold_scan, cfg.fbeta_beta)\n                    best_th = float(threshold_info['best']['threshold'])\n                    pred = p >= best_th\n                    stats = _binary_stats(pred, y_val > 0.5)\n                    fbeta = _fbeta_from_stats(stats, cfg.fbeta_beta)\n                    sparsity = float(np.mean((np.abs(m.w) + np.abs(m.alpha) + np.abs(m.beta)) < 1e-8))\n                    reg_lambda = dynamic_regularization_lambda(pred.astype(np.uint8), x_val.T.reshape(x_train.shape[1], -1, 1))\n                    objective = ce + 0.02 * (1.0 - sparsity) - 0.20 * stats['f1'] - 0.15 * fbeta - 0.10 * stats['iou'] + 0.005 * reg_lambda\n                    rec = {\n                        'epoch': int(epoch),\n                        'neuron_id': neuron_id,\n                        'l1': float(l1),\n                        'l2': float(l2),\n                        'val_ce': ce,\n                        'val_f1': stats['f1'],\n                        'val_iou': stats['iou'],\n                        'val_dice': stats['dice'],\n                        'val_fbeta': fbeta,\n                        'best_threshold': best_th,\n                        'threshold_scan': threshold_info['scan'],\n                        'sparsity': sparsity,\n                        'objective': objective,\n                        **tr,\n                    }\n                    leaderboard.append(rec)\n                    if best is None or objective < best['objective']:\n                        best = rec\n                        best_state = (m.w.copy(), float(m.b), m.alpha.copy(), m.beta.copy())\n        epoch_best = sorted([r for r in leaderboard if r['epoch'] == epoch], key=lambda d: d['objective'])[0]\n        epoch_history.append({\n            'epoch': int(epoch),\n            'best_objective': float(epoch_best['objective']),\n            'best_f1': float(epoch_best['val_f1']),\n            'best_iou': float(epoch_best['val_iou']),\n            'best_fbeta': float(epoch_best['val_fbeta']),\n            'best_threshold': float(epoch_best['best_threshold']),\n        })\n        if progress_cb is not None:\n            progress_cb(\n                stage='train_supervised',\n                pct=100.0,\n                substage='epoch_done',\n                file_name='',\n                index=int(epoch + 1),\n                total=max(1, int(cfg.supervised_epochs) if int(cfg.supervised_epochs) > 0 else int(epoch + 1)),\n                epoch_best=float(epoch_best['objective']),\n                epoch_f1=float(epoch_best['val_f1']),\n            )\n        if best_obj_seen is None or (best_obj_seen - float(epoch_best['objective'])) > float(cfg.convergence_min_delta):\n            best_obj_seen = float(epoch_best['objective'])\n            stagnation = 0\n        else:\n            stagnation += 1\n\n        epoch += 1\n        if int(cfg.supervised_epochs) > 0 and epoch >= int(cfg.supervised_epochs):\n            break\n        if int(cfg.supervised_epochs) <= 0 and stagnation >= int(cfg.convergence_patience):\n            break\n        if int(getattr(cfg, 'auto_epoch_safety_cap', 0)) > 0 and epoch >= int(cfg.auto_epoch_safety_cap):\n            break\n\n    mutation_applied = False\n    pruning_applied = False\n    if best_state is not None:\n        if len(memory.f1_history) >= cfg.f1_stagnation_window:\n            recent = memory.f1_history[-cfg.f1_stagnation_window:]\n            if float(np.max(recent) - np.min(recent)) < 1e-3:\n                best_state = (\n                    best_state[0] + rng.normal(0.0, cfg.mutation_noise, size=best_state[0].shape),\n                    float(best_state[1]),\n                    best_state[2] + rng.normal(0.0, cfg.mutation_noise, size=best_state[2].shape),\n                    best_state[3] + rng.normal(0.0, cfg.mutation_noise, size=best_state[3].shape),\n                )\n                mutation_applied = True\n                memory.mutation_events += 1\n        q = float(np.quantile(np.abs(best_state[0]), cfg.pruning_quantile))\n        pruned_w = np.where(np.abs(best_state[0]) < q, 0.0, best_state[0])\n        pruned_a = np.where(np.abs(best_state[2]) < q, 0.0, best_state[2])\n        pruned_beta = np.where(np.abs(best_state[3]) < q, 0.0, best_state[3])\n        if np.any(pruned_w != best_state[0]) or np.any(pruned_a != best_state[2]) or np.any(pruned_beta != best_state[3]):\n            pruning_applied = True\n            memory.pruning_events += 1\n        best_state = (pruned_w, best_state[1], pruned_a, pruned_beta)\n\n    model = NX47AtomNeuron(n_features=x_train.shape[1])\n    if best_state is not None:\n        model.w, model.b, model.alpha, model.beta = best_state\n\n    if best is not None:\n        memory.update(float(best.get('val_f1', 0.0)), float(best.get('best_threshold', 0.5)))\n\n    ablation = {'enabled': bool(getattr(cfg, 'run_ablation_check', True)), 'delta_f1_vs_full': 0.0, 'full_f1': 0.0, 'ablated_f1': 0.0}\n    if ablation['enabled'] and best is not None and x_val.size > 0:\n        p_full = model.predict_proba(x_val, grad_x_val)\n        th = float(best.get('best_threshold', 0.5))\n        full_stats = _binary_stats(p_full >= th, y_val > 0.5)\n        x_abl = x_val.copy()\n        if x_abl.shape[1] > 0:\n            x_abl[:, 0] = 0.0\n        p_abl = model.predict_proba(x_abl, grad_x_val)\n        abl_stats = _binary_stats(p_abl >= th, y_val > 0.5)\n        ablation = {\n            'enabled': True,\n            'delta_f1_vs_full': float(full_stats['f1'] - abl_stats['f1']),\n            'full_f1': float(full_stats['f1']),\n            'ablated_f1': float(abl_stats['f1']),\n            'method': 'zero_feature_0',\n        }\n\n    stability = {'enabled': int(getattr(cfg, 'stability_probe_runs', 0)) > 0, 'runs': 0, 'f1_std': 0.0, 'f1_values': []}\n\n    return model, {\n        'selected_hyperparams': best,\n        'leaderboard_top5': sorted(leaderboard, key=lambda d: d['objective'])[:5],\n        'epoch_history': epoch_history,\n        'train_samples': int(x_train.shape[0]),\n        'val_samples': int(x_val.shape[0]),\n        'adaptive_lr': float(adaptive_lr),\n        'epochs_effective': int(len(epoch_history)),\n        'mutation_applied': mutation_applied,\n        'pruning_applied': pruning_applied,\n        'supervised': True,\n        'ablation_check': ablation,\n        'stability_probe': stability,\n    }\n\n\ndef train_nx47_autonomous(features: np.ndarray, cfg: V139Config, rng: np.random.Generator, memory: NX47EvolutionMemory | None = None) -> Tuple[NX47AtomNeuron, Dict[str, Any]]:\n    x = features.reshape(features.shape[0], -1).T.astype(np.float64)\n    keep, y_all = pseudo_labels(np.mean(features, axis=0), cfg.pseudo_pos_pct, cfg.pseudo_neg_pct)\n    idx = np.where(keep)[0]\n    if idx.size > cfg.train_max_samples:\n        idx = rng.choice(idx, size=cfg.train_max_samples, replace=False)\n    x_train, y_train = x[idx], y_all[idx]\n    cut = int(x_train.shape[0] * 0.85)\n    x_tr, y_tr = x_train[:cut], y_train[:cut]\n    x_va, y_va = x_train[cut:], y_train[cut:]\n    if x_va.shape[0] < 100:\n        x_va, y_va = x_tr, y_tr\n\n    best, best_state = None, None\n    leaderboard: List[Dict[str, Any]] = []\n    adaptive_lr = memory.adapt_learning_rate(cfg.lr, cfg.f1_stagnation_window) if memory else cfg.lr\n    for neuron_id in range(max(1, cfg.meta_neurons)):\n        for l1 in cfg.l1_candidates:\n            for l2 in cfg.l2_candidates:\n                m = NX47AtomNeuron(n_features=x.shape[1])\n                tr = m.fit_prox(x_tr, y_tr, lr=adaptive_lr, max_iter=cfg.max_iter, l1=float(l1), l2=float(l2))\n                grad_x_va = np.gradient(x_va, axis=0)\n                p = m.predict_proba(x_va, grad_x_va)\n                ce = -float(np.mean(y_va * np.log(p + 1e-9) + (1.0 - y_va) * np.log(1.0 - p + 1e-9)))\n                proxy_f1 = compute_proxy_f1(p, y_va)\n                sparsity = float(np.mean((np.abs(m.w) + np.abs(m.alpha) + np.abs(m.beta)) < 1e-8))\n                reg_lambda = dynamic_regularization_lambda((p > 0.5).astype(np.uint8), features)\n                objective = ce + 0.02 * (1.0 - sparsity) - 0.05 * proxy_f1 + 0.005 * reg_lambda\n                rec = {\"neuron_id\": neuron_id, \"l1\": float(l1), \"l2\": float(l2), \"val_ce\": ce, \"proxy_f1\": proxy_f1, \"sparsity\": sparsity, \"objective\": objective, **tr}\n                leaderboard.append(rec)\n                if best is None or objective < best[\"objective\"]:\n                    best = rec\n                    best_state = (m.w.copy(), float(m.b), m.alpha.copy(), m.beta.copy())\n\n    mutation_applied = False\n    pruning_applied = False\n    if best_state is not None and memory is not None:\n        if len(memory.f1_history) >= cfg.f1_stagnation_window:\n            recent = memory.f1_history[-cfg.f1_stagnation_window:]\n            if float(np.max(recent) - np.min(recent)) < 1e-3:\n                best_state = (\n                    best_state[0] + rng.normal(0.0, cfg.mutation_noise, size=best_state[0].shape),\n                    float(best_state[1]),\n                    best_state[2] + rng.normal(0.0, cfg.mutation_noise, size=best_state[2].shape),\n                    best_state[3] + rng.normal(0.0, cfg.mutation_noise, size=best_state[3].shape),\n                )\n                mutation_applied = True\n                memory.mutation_events += 1\n        q = float(np.quantile(np.abs(best_state[0]), cfg.pruning_quantile))\n        pruned_w = np.where(np.abs(best_state[0]) < q, 0.0, best_state[0])\n        pruned_a = np.where(np.abs(best_state[2]) < q, 0.0, best_state[2])\n        pruned_beta = np.where(np.abs(best_state[3]) < q, 0.0, best_state[3])\n        if np.any(pruned_w != best_state[0]) or np.any(pruned_a != best_state[2]) or np.any(pruned_beta != best_state[3]):\n            pruning_applied = True\n            memory.pruning_events += 1\n        best_state = (pruned_w, best_state[1], pruned_a, pruned_beta)\n\n    model = NX47AtomNeuron(n_features=x.shape[1])\n    if best_state is not None:\n        model.w, model.b, model.alpha, model.beta = best_state\n    return model, {\n        \"selected_hyperparams\": best,\n        \"leaderboard_top5\": sorted(leaderboard, key=lambda d: d['objective'])[:5],\n        \"train_samples\": int(x_train.shape[0]),\n        \"label_keep_ratio\": float(keep.mean()),\n        \"adaptive_lr\": float(adaptive_lr),\n        \"mutation_applied\": mutation_applied,\n        \"pruning_applied\": pruning_applied,\n    }\n\n\ndef hysteresis_topology_3d(prob: np.ndarray, cfg: V139Config) -> np.ndarray:\n    strong = prob >= float(cfg.strong_th)\n    weak = prob >= float(cfg.weak_th)\n    core = binary_propagation(strong, mask=weak, structure=generate_binary_structure(2, 2)) if strong.any() else np.zeros_like(strong, dtype=bool)\n\n    z, r = int(cfg.z_radius), int(cfg.xy_radius)\n    struct = np.zeros((2 * z + 1, 2 * r + 1, 2 * r + 1), dtype=bool)\n    for dz in range(-z, z + 1):\n        for dy in range(-r, r + 1):\n            for dx in range(-r, r + 1):\n                if dy * dy + dx * dx <= r * r:\n                    struct[dz + z, dy + r, dx + r] = True\n\n    vol = np.repeat(core[np.newaxis, ...], 3, axis=0)\n    mask = binary_closing(vol, structure=struct).any(axis=0)\n    lbl, n = label(mask)\n    if n > 0 and cfg.dust_min_size > 1:\n        counts = np.bincount(lbl.ravel())\n        keep = counts >= int(cfg.dust_min_size)\n        keep[0] = False\n        mask = keep[lbl]\n    return mask\n\n\ndef calibrate_target_ratio(prob: np.ndarray, target_ratio: float) -> np.ndarray:\n    ratio = float(np.clip(target_ratio, 0.001, 0.35))\n    return prob >= float(np.percentile(prob, 100.0 * (1.0 - ratio)))\n\n\ndef probe_hardware_metrics() -> Dict[str, Any]:\n    mem_total_kb = None\n    mem_available_kb = None\n    try:\n        with open('/proc/meminfo', 'r', encoding='utf-8') as f:\n            rows = f.read().splitlines()\n        kv = {r.split(':')[0]: r.split(':')[1].strip() for r in rows if ':' in r}\n        mem_total_kb = int(kv.get('MemTotal', '0 kB').split()[0])\n        mem_available_kb = int(kv.get('MemAvailable', '0 kB').split()[0])\n    except Exception:\n        pass\n\n    gpu = None\n    try:\n        out = subprocess.check_output(['bash', '-lc', 'nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader'], stderr=subprocess.DEVNULL, timeout=2).decode().strip()\n        gpu = out.splitlines()\n    except Exception:\n        gpu = []\n\n    return {\n        'python': sys.version,\n        'platform': platform.platform(),\n        'cpu_count': os.cpu_count(),\n        'mem_total_kb': mem_total_kb,\n        'mem_available_kb': mem_available_kb,\n        'gpu': gpu,\n    }\n\n\nclass NX47V139Kernel:\n    def __init__(self, root: Path = Path('/kaggle/input/competitions/vesuvius-challenge-surface-detection'), output_dir: Path = Path('/kaggle/working'), config: V139Config | None = None) -> None:\n        self.version = 'NX47 V139'\n        self.root = self._resolve_root(root)\n        self.test_dir = self.root / 'test_images'\n        self.train_img_dir = self.root / 'train_images'\n        self.train_lbl_dir = self.root / 'train_labels'\n        self.output_dir = output_dir\n        self.tmp_dir = output_dir / 'tmp_masks_v134'\n        self.overlay_dir = output_dir / 'overlays_v134'\n        self.submission_path = output_dir / 'submission.zip'\n        self.roadmap_path = output_dir / 'v139_roadmap_realtime.json'\n        self.logs_path = output_dir / 'v139_execution_logs.json'\n        self.memory_path = output_dir / 'v139_memory_tracker.json'\n        self.metadata_path = output_dir / 'v139_execution_metadata.json'\n        self.ultra_log_path = output_dir / 'v139_ultra_authentic_360_merkle.jsonl'\n        self.forensic_report_path = output_dir / 'v139_forensic_analysis_report.json'\n\n        self.cfg = config or V139Config()\n        self.evolution = NX47EvolutionMemory()\n        self.plan = PlanTracker(self.roadmap_path)\n        self.memory = MemoryTracker()\n        self.logs: List[Dict[str, Any]] = []\n        self.ultra = UltraAuthentic360Merkle(self.ultra_log_path, console=self.cfg.ultra_console_log)\n        self.supervised_model: NX47AtomNeuron | None = None\n        self.supervised_train_info: Dict[str, Any] | None = None\n        self.learning_audit: Dict[str, Any] = {}\n        self.train_dataset_audit: Dict[str, Any] = {}\n        self._last_progress_ns: int | None = None\n        self._last_progress_stage: str = ''\n\n        self.continuity_matrix = self._build_continuity_matrix()\n\n        self.global_stats: Dict[str, Any] = {\n            'files_processed': 0,\n            'slices_processed': 0,\n            'pixels_processed': 0,\n            'pixels_anchor_detected': 0,\n            'pixels_papyrus_without_anchor': 0,\n            'materials_detected': 0,\n            'patterns_detected': 0,\n            'golden_nonce_detected': 0,\n            'unknown_discoveries': 0,\n            'anomalies_detected': 0,\n            'calc_ops_estimated': 0,\n            'active_neurons_start_total': 0,\n            'active_neurons_mid_total': 0,\n            'active_neurons_end_total': 0,\n            'meta_neuron_candidates': 0,\n            'mutation_events': 0,\n            'pruning_events': 0,\n            'f1_ratio_curve_best_ratio': 0.0,\n            'f1_ratio_curve_best_f1': 0.0,\n            'files_supervised_mode': 0,\n            'files_autonomous_fallback': 0,\n            'val_f1_mean_supervised': 0.0,\n            'val_iou_mean_supervised': 0.0,\n            'best_threshold_mean_supervised': 0.0,\n            'unet_25d_status': 'n/a',\n            'unet_25d_best_fbeta': 0.0,\n            'forensic_report_generated': False,\n            'probability_max_observed': 0.0,\n            'probability_mean_observed': 0.0,\n            'probability_std_observed': 0.0,\n            'learning_percent_real': 0.0,\n            'reasoning_trace_events': 0,\n            'train_pair_count_discovered': 0,\n            'train_pair_coverage_pct': 0.0,\n        }\n\n        bootstrap_dependencies_fail_fast()\n        if not ensure_imagecodecs():\n            raise RuntimeError('imagecodecs is mandatory for LZW TIFF I/O')\n\n        self.tmp_dir.mkdir(parents=True, exist_ok=True)\n        self.overlay_dir.mkdir(parents=True, exist_ok=True)\n\n        for n, d in [\n            ('discovery', 'Validation dataset et assets'),\n            ('load', 'Chargement volume'),\n            ('features', 'Extraction + slection features'),\n            ('train', 'Apprentissage neurone NX-47 L1/L2'),\n            ('segment', 'Probabilit + hysteresis + calibration'),\n            ('package', 'Gnration submission zip'),\n        ]:\n            self.plan.add_step(n, d)\n        self.plan._write()\n\n        if self.cfg.enforce_nx_legacy_continuity:\n            self._assert_continuity_integrity()\n\n        self.log('BOOT', version=self.version, root=str(self.root), config=asdict(self.cfg), hardware=probe_hardware_metrics())\n\n    def _build_continuity_matrix(self) -> Dict[str, List[str]]:\n        return {\n            'NX-1..NX-10': ['preprocess', 'input_format_invariants'],\n            'NX-11..NX-20': ['feature_signature', 'intermediate_schema'],\n            'NX-21..NX-35': ['audit_hash_chain', 'integrity_checks'],\n            'NX-36..NX-47': ['forensic_traceability', 'merkle_chain', 'roadmap_realtime'],\n            'NX-47 v115..v139': ['supervised_pipeline', 'unet_25d', 'strict_logging'],\n        }\n\n    def _assert_continuity_integrity(self) -> None:\n        required_caps = {\n            'preprocess': extract_multi_features,\n            'input_format_invariants': read_tiff_lzw_safe,\n            'feature_signature': auto_select_features,\n            'intermediate_schema': self._predict_mask,\n            'audit_hash_chain': self.log,\n            'integrity_checks': audit_logits_distribution,\n            'forensic_traceability': self._build_v139_forensic_report,\n            'merkle_chain': self.ultra.emit,\n            'roadmap_realtime': self.plan.update,\n            'supervised_pipeline': train_nx47_supervised,\n            'unet_25d': train_unet_25d_supervised,\n            'strict_logging': self.logs.append,\n        }\n        missing = [name for name, ref in required_caps.items() if ref is None]\n        if missing:\n            raise RuntimeError(f'NX_CONTINUITY_BROKEN: missing capabilities {missing}')\n        self.log('NX_CONTINUITY_OK', matrix=self.continuity_matrix)\n\n    def _resolve_root(self, preferred: Path) -> Path:\n        cands = [preferred, Path('/kaggle/input/competitions/vesuvius-challenge-surface-detection'), Path('/kaggle/input/vesuvius-challenge-surface-detection')]\n        for c in cands:\n            if c.exists():\n                return c\n        raise FileNotFoundError(f'Dataset path missing. Tried: {[str(c) for c in cands]}')\n\n    def log(self, event: str, **kwargs: Any) -> None:\n        payload = {'ts_ns': time.time_ns(), 'event': event, **kwargs}\n        payload['signature'] = sha512(json.dumps(payload, sort_keys=True, default=str).encode()).hexdigest()\n        self.logs.append(payload)\n        self.ultra.emit(payload)\n\n    def _build_progress_bar(self, pct: float) -> str:\n        width = max(8, int(getattr(self.cfg, 'progress_bar_width', 24)))\n        clamped = float(np.clip(pct, 0.0, 100.0))\n        filled = int(round(width * clamped / 100.0))\n        return '[' + ('#' * filled) + ('-' * (width - filled)) + ']'\n\n    def _log_progress(self, stage: str, pct: float, *, substage: str = '', file_name: str = '', index: int = 0, total: int = 0, **extra: Any) -> None:\n        now_ns = time.time_ns()\n        elapsed_s_since_last = None\n        if self._last_progress_ns is not None:\n            elapsed_s_since_last = (now_ns - self._last_progress_ns) / 1e9\n        self._last_progress_ns = now_ns\n        self._last_progress_stage = stage\n\n        self.log(\n            'PROGRESS_UPDATE',\n            stage=stage,\n            substage=substage or None,\n            file=file_name or None,\n            index=int(index),\n            total=int(total),\n            progress_percent=float(np.clip(pct, 0.0, 100.0)),\n            progress_bar=self._build_progress_bar(pct),\n            global_progress_percent=float(self.plan.overall_progress()),\n            global_progress_bar=self._build_progress_bar(self.plan.overall_progress()),\n            elapsed_s_since_last=elapsed_s_since_last,\n            eta_s=(None if total <= 0 or index <= 0 else float(max(0.0, (total - index) * ((elapsed_s_since_last or 0.0) / max(1, index))))),\n            **extra,\n        )\n        stall_limit_s = float(getattr(self.cfg, 'stage_stall_alert_s', 180.0))\n        if elapsed_s_since_last is not None and elapsed_s_since_last >= stall_limit_s:\n            self.log('STALL_ALERT', stage=stage, substage=substage or None, elapsed_s=elapsed_s_since_last, stall_limit_s=stall_limit_s)\n\n    def _log_heartbeat(self, stage: str, *, file_name: str = '', note: str = '', index: int = 0, total: int = 0) -> None:\n        self.log(\n            'HEARTBEAT',\n            stage=stage,\n            file=file_name or None,\n            index=int(index),\n            total=int(total),\n            note=note,\n            global_progress_percent=float(self.plan.overall_progress()),\n            global_progress_bar=self._build_progress_bar(self.plan.overall_progress()),\n        )\n\n    def _run_preflight_5pct(self, files: List[Path]) -> None:\n        train_pairs = self.discover_train_pairs()\n        train_n = max(1, int(np.ceil(len(train_pairs) * float(self.cfg.preflight_train_pct) / 100.0))) if train_pairs else 0\n        test_n = max(1, int(np.ceil(len(files) * float(self.cfg.preflight_test_pct) / 100.0))) if files else 0\n        self.log('PREFLIGHT_START', train_pairs_total=len(train_pairs), train_pairs_preflight=train_n, test_files_total=len(files), test_files_preflight=test_n, preflight_train_pct=float(self.cfg.preflight_train_pct), preflight_test_pct=float(self.cfg.preflight_test_pct))\n\n        for i, (img_path, lbl_path) in enumerate(train_pairs[:train_n], start=1):\n            self._log_progress('preflight_train', 100.0 * i / max(1, train_n), substage='load_pair', file_name=img_path.name, index=i, total=train_n)\n            _ = self._load_volume(img_path)\n            _ = self._load_label_2d(lbl_path)\n\n        for j, fpath in enumerate(files[:test_n], start=1):\n            self._log_progress('preflight_test', 100.0 * j / max(1, test_n), substage='load_test_volume', file_name=fpath.name, index=j, total=test_n)\n            _ = self._load_volume(fpath)\n\n        self.log('PREFLIGHT_OK', train_pairs_checked=train_n, test_files_checked=test_n)\n\n    def _log_array_ultra(self, stage: str, arr: np.ndarray) -> None:\n        self.memory.log_array(stage, arr)\n        if self.cfg.ultra_bit_trace_arrays:\n            self.log('ARRAY_TRACE', stage=stage, shape=list(np.asarray(arr).shape), dtype=str(np.asarray(arr).dtype), bits=self.ultra.bit_stats(arr, self.cfg.ultra_bit_trace_limit))\n\n    def discover_inputs(self) -> List[Path]:\n        self.plan.update('discovery', 25.0)\n        self._log_progress('discovery', 25.0, substage='start')\n        if not self.test_dir.exists():\n            raise FileNotFoundError(f'Missing test_images directory: {self.test_dir}')\n        files = sorted(self.test_dir.rglob('*.tif'))\n        if not files:\n            raise RuntimeError(f'No TIFF files found in {self.test_dir}')\n\n        all_files = [p for p in self.root.rglob('*') if p.is_file()]\n        suffix_stats: Dict[str, int] = {}\n        folders = set()\n        for p in all_files:\n            suffix_stats[p.suffix.lower() or '<noext>'] = suffix_stats.get(p.suffix.lower() or '<noext>', 0) + 1\n            folders.add(str(p.parent.relative_to(self.root)))\n\n        self.log('DATASET_DISCOVERY', file_count=len(files), total_assets=len(all_files), folders=sorted(folders), suffix_stats=suffix_stats)\n        self._log_progress('discovery', 90.0, substage='inventory_completed', total=len(files))\n        self.plan.update('discovery', 100.0, done=True)\n        self._log_progress('discovery', 100.0, substage='done', total=len(files))\n        return files\n\n    def discover_train_pairs(self) -> List[Tuple[Path, Path]]:\n        if not self.train_img_dir.exists() or not self.train_lbl_dir.exists():\n            self.log('TRAIN_DISCOVERY', status='missing_train_dirs', train_images=str(self.train_img_dir), train_labels=str(self.train_lbl_dir))\n            return []\n        pairs: List[Tuple[Path, Path]] = []\n        for img in sorted(self.train_img_dir.rglob('*.tif')):\n            cand = self.train_lbl_dir / img.name\n            if cand.exists():\n                pairs.append((img, cand))\n        self.log('TRAIN_DISCOVERY', pair_count=len(pairs), max_train_volumes=self.cfg.max_train_volumes, max_val_volumes=self.cfg.max_val_volumes)\n        return pairs\n\n    def _parse_v130_log_summary(self, log_path: Path) -> Dict[str, Any]:\n        if not log_path.exists():\n            return {'status': 'missing', 'path': str(log_path)}\n        text = log_path.read_text(encoding='utf-8', errors='ignore')\n        lines = [ln for ln in text.splitlines() if ln.strip()]\n        global_stats = {}\n        for line in lines[::-1]:\n            if '\"event\": \"GLOBAL_STATS\"' in line:\n                start = line.find('{')\n                if start >= 0:\n                    try:\n                        global_stats = json.loads(line[start:])\n                    except Exception:\n                        global_stats = {}\n                break\n        return {\n            'status': 'ok',\n            'path': str(log_path),\n            'line_count': len(lines),\n            'has_exec_complete': any('\"event\": \"EXEC_COMPLETE\"' in ln for ln in lines),\n            'global_stats': global_stats,\n        }\n\n    def _build_v139_forensic_report(self) -> Dict[str, Any]:\n        v130 = self._parse_v130_log_summary(Path(self.cfg.v130_log_path))\n        gs = v130.get('global_stats', {}) if isinstance(v130, dict) else {}\n        positives = int(gs.get('pixels_papyrus_without_anchor', 0)) + int(gs.get('pixels_anchor_detected', 0))\n        return {\n            'version': self.version,\n            'objective': 'Rintgration complte V130 + analyse forensic + plan V132 de A  Z',\n            'v130_log_forensic': {\n                'summary': v130,\n                'computed_total_positives': positives,\n                'supervised_mode_files': int(gs.get('files_supervised_mode', 0)),\n                'best_threshold_mean_supervised': float(gs.get('best_threshold_mean_supervised', 0.0)),\n                'golden_nonce_detected': int(gs.get('golden_nonce_detected', 0)),\n            },\n            'pipeline_checklist': [\n                'Split explicite train/val + multi-epoch supervis',\n                'Calibration threshold par F-beta (scan complet)',\n                'SWI + TTA multi-axes/rotation + fusion sigmoid stable',\n                'Post-process seeded hysteresis 3D + closing anisotropique + dust removal',\n                'Golden nonces top-K extraits et intgrs au masque final',\n                'Audit scientifique complet (logs, mtriques, metadata, merkle trace)',\n            ],\n            'concurrent_comparison': {\n                'public_pipeline': 'single-path drop-in, seuils fixes, propagation binaire',\n                'v132_advantages': [\n                    'apprentissage supervis rel et audit',\n                    'calibration de seuil optimise F-beta',\n                    'intgration golden nonces top-K',\n                    'TTA multi-axes/rotation et couverture spatiale renforce',\n                    'traabilit forensic complte',\n                ],\n            },\n            'remaining_steps_executed_simultaneously': [\n                'Consolider rapport forensic dans les artefacts V132',\n                \"Prparer base CV 5-fold (pilotage par variables d'environnement)\",\n                'Prparer extension ensemble multi-backbone (slot unet_25d dj maintenu)',\n                'Conserver compatibilit Kaggle submission.zip',\n            ],\n        }\n\n\n\n    @staticmethod\n    def _load_label_2d(path: Path) -> np.ndarray:\n        arr = read_tiff_lzw_safe(path)\n        if arr.ndim == 3:\n            arr2d = arr[0]\n        elif arr.ndim == 2:\n            arr2d = arr\n        else:\n            raise RuntimeError(f'Unsupported label shape {arr.shape} for {path.name}')\n        arr2d = np.asarray(arr2d, dtype=np.float32)\n        if arr2d.max() > 1.0:\n            arr2d = arr2d / 255.0\n        return (arr2d > 0.5).astype(np.float32)\n\n    def _derive_train_pair_requirement(self, pair_count: int) -> int:\n        if pair_count <= 0:\n            return int(self.cfg.min_train_pairs_required)\n        if self.cfg.adapt_train_threshold_to_dataset_size:\n            req = int(np.ceil(pair_count * float(self.cfg.train_pair_coverage_target_pct) / 100.0))\n            return max(1, req)\n        return int(self.cfg.min_train_pairs_required)\n\n    def _audit_train_dataset_size(self, pairs: List[Tuple[Path, Path]]) -> None:\n        pair_count = len(pairs)\n        if self.cfg.max_train_volumes <= 0 and self.cfg.max_val_volumes <= 0:\n            selected = int(pair_count)\n        else:\n            max_total = max(1, self.cfg.max_train_volumes + self.cfg.max_val_volumes)\n            selected = min(pair_count, max_total)\n        coverage = float(100.0 * selected / max(1, pair_count))\n        image_exists_count = int(sum(1 for img, _ in pairs if img.exists()))\n        label_exists_count = int(sum(1 for _, lbl in pairs if lbl.exists()))\n        total_label_bytes = int(sum(lbl.stat().st_size for _, lbl in pairs if lbl.exists()))\n        total_image_bytes = int(sum(img.stat().st_size for img, _ in pairs if img.exists()))\n        self.train_dataset_audit = {\n            'pair_count_discovered': int(pair_count),\n            'pair_count_selected_for_training': int(selected),\n            'coverage_pct_selected_vs_discovered': float(coverage),\n            'train_image_files_found': int(image_exists_count),\n            'train_label_files_found': int(label_exists_count),\n            'total_train_image_bytes': int(total_image_bytes),\n            'total_train_label_bytes': int(total_label_bytes),\n            'required_pair_count': int(self._derive_train_pair_requirement(pair_count)),\n        }\n        self.log('TRAIN_DATASET_AUDIT', **self.train_dataset_audit)\n\n    def _assert_train_pairs_threshold(self, pair_count: int) -> None:\n        required_pairs = self._derive_train_pair_requirement(pair_count)\n        if self.cfg.supervised_train and pair_count < int(required_pairs):\n            raise RuntimeError(\n                f'TRAIN_PAIRS_BELOW_THRESHOLD: found={pair_count} required={required_pairs}'\n            )\n        img_found = int(self.train_dataset_audit.get('train_image_files_found', 0))\n        lbl_found = int(self.train_dataset_audit.get('train_label_files_found', 0))\n        if self.cfg.supervised_train and img_found < int(self.cfg.min_train_image_files_required):\n            raise RuntimeError(\n                f'TRAIN_IMAGE_FILES_BELOW_THRESHOLD: found={img_found} required={self.cfg.min_train_image_files_required}'\n            )\n        if self.cfg.supervised_train and lbl_found < int(self.cfg.min_train_label_files_required):\n            raise RuntimeError(\n                f'TRAIN_LABEL_FILES_BELOW_THRESHOLD: found={lbl_found} required={self.cfg.min_train_label_files_required}'\n            )\n\n    def _assert_train_completed_100(self) -> None:\n        if not self.cfg.require_train_completion_100:\n            return\n        if self.supervised_train_info is None:\n            raise RuntimeError('TRAIN_COMPLETION_100_FAILED: missing supervised_train_info')\n        hist = self.supervised_train_info.get('epoch_history', [])\n        epochs_done = len(hist)\n        if epochs_done < int(self.cfg.supervised_epochs):\n            raise RuntimeError(\n                f'TRAIN_COMPLETION_100_FAILED: epochs_done={epochs_done} expected={self.cfg.supervised_epochs}'\n            )\n\n    def _compute_learning_percent_real(self, train_info: Dict[str, Any]) -> float:\n        hist = train_info.get('epoch_history', []) if isinstance(train_info, dict) else []\n        epochs_done = len(hist)\n        epoch_ratio = float(epochs_done / max(1, int(self.cfg.supervised_epochs)))\n        shp = train_info.get('selected_hyperparams', {}) if isinstance(train_info, dict) else {}\n        val_f1 = float(shp.get('val_f1', 0.0))\n        val_iou = float(shp.get('val_iou', 0.0))\n        metric_signal = float(np.clip((val_f1 + val_iou) / 2.0, 0.0, 1.0))\n        # 80% driven by completed epochs, 20% by observed validation signal\n        pct = float(np.clip(100.0 * (0.8 * epoch_ratio + 0.2 * metric_signal), 0.0, 100.0))\n        return pct\n\n    def _assert_no_hardcoded_metric_pattern(self, train_info: Dict[str, Any]) -> None:\n        if not self.cfg.enforce_no_hardcoded_metrics:\n            return\n        hist = train_info.get('epoch_history', []) if isinstance(train_info, dict) else []\n        if len(hist) < 2:\n            return\n        objectives = [float(h.get('best_objective', 0.0)) for h in hist]\n        # If every epoch has exactly the same objective, flag forensic anomaly.\n        if len(set(objectives)) == 1:\n            policy = str(getattr(self.cfg, 'hardcoded_metric_policy', 'warn')).lower()\n            self.log('HARD_METRIC_PATTERN', policy=policy, objectives=objectives)\n            if policy == 'error':\n                raise RuntimeError('HARD_METRIC_PATTERN_DETECTED: identical epoch objective across all epochs')\n\n    def build_supervised_model(self) -> None:\n        if not self.cfg.supervised_train:\n            self.log('SUPERVISED_TRAIN', status='disabled')\n            return\n        pairs = self.discover_train_pairs()\n        self._audit_train_dataset_size(pairs)\n        self._assert_train_pairs_threshold(len(pairs))\n        if not pairs:\n            self.log('SUPERVISED_TRAIN', status='fallback_autonomous_no_pairs')\n            if self.cfg.strict_no_fallback:\n                raise RuntimeError('STRICT_NO_FALLBACK: supervised_train enabled but no train pairs found')\n            return\n\n        rng = np.random.default_rng(125)\n        if self.cfg.max_train_volumes <= 0 and self.cfg.max_val_volumes <= 0:\n            chosen = pairs\n            split = max(1, int(0.8 * len(chosen)))\n            train_pairs = chosen[:split]\n            val_pairs = chosen[split:]\n        else:\n            max_total = max(2, self.cfg.max_train_volumes + self.cfg.max_val_volumes)\n            chosen = pairs[:max_total]\n            split = min(len(chosen) - 1, self.cfg.max_train_volumes)\n            train_pairs = chosen[:split]\n            val_pairs = chosen[split:]\n        if not val_pairs:\n            val_pairs = chosen[-1:]\n            train_pairs = chosen[:-1]\n\n        x_train_chunks: List[np.ndarray] = []\n        y_train_chunks: List[np.ndarray] = []\n        x_val_chunks: List[np.ndarray] = []\n        y_val_chunks: List[np.ndarray] = []\n\n        for k, (img_path, lbl_path) in enumerate(train_pairs, start=1):\n            self._log_progress('train_data', 100.0 * k / max(1, len(train_pairs)), substage='load_train_pair', file_name=img_path.name, index=k, total=len(train_pairs))\n            vol = self._load_volume(img_path)\n            feats, names = extract_multi_features(vol)\n            selected, _, _ = auto_select_features(feats, names, self.cfg.top_k_features)\n            x = selected.reshape(selected.shape[0], -1).T.astype(np.float64)\n            y = self._load_label_2d(lbl_path).reshape(-1).astype(np.float64)\n            n = min(x.shape[0], y.shape[0])\n            x, y = x[:n], y[:n]\n            idx = _balance_sample_indices(y, self.cfg.max_samples_per_volume, self.cfg.pos_neg_ratio, rng)\n            x_train_chunks.append(x[idx])\n            y_train_chunks.append(y[idx])\n\n        for k, (img_path, lbl_path) in enumerate(val_pairs, start=1):\n            self._log_progress('val_data', 100.0 * k / max(1, len(val_pairs)), substage='load_val_pair', file_name=img_path.name, index=k, total=len(val_pairs))\n            vol = self._load_volume(img_path)\n            feats, names = extract_multi_features(vol)\n            selected, _, _ = auto_select_features(feats, names, self.cfg.top_k_features)\n            x = selected.reshape(selected.shape[0], -1).T.astype(np.float64)\n            y = self._load_label_2d(lbl_path).reshape(-1).astype(np.float64)\n            n = min(x.shape[0], y.shape[0])\n            x, y = x[:n], y[:n]\n            idx = _balance_sample_indices(y, self.cfg.max_samples_per_volume, self.cfg.pos_neg_ratio, rng)\n            x_val_chunks.append(x[idx])\n            y_val_chunks.append(y[idx])\n\n        if not x_train_chunks or not x_val_chunks:\n            self.log('SUPERVISED_TRAIN', status='fallback_autonomous_empty_chunks')\n            if self.cfg.strict_no_fallback:\n                raise RuntimeError('STRICT_NO_FALLBACK: supervised_train enabled but sampled chunks are empty')\n            return\n\n        x_train = np.concatenate(x_train_chunks, axis=0)\n        y_train = np.concatenate(y_train_chunks, axis=0)\n        x_val = np.concatenate(x_val_chunks, axis=0)\n        y_val = np.concatenate(y_val_chunks, axis=0)\n\n        model, info = train_nx47_supervised(x_train, y_train, x_val, y_val, self.cfg, rng, self.evolution, progress_cb=self._log_progress)\n        self.supervised_model = model\n\n        # Optional competitive 2.5D U-Net branch for logit/threshold audit and potential scoring uplift\n        unet_info = {'status': 'disabled'}\n        if self.cfg.use_unet_25d:\n            try:\n                train_patch_x, train_patch_y = [], []\n                val_patch_x, val_patch_y = [], []\n                for u, (img_path, lbl_path) in enumerate(train_pairs[: min(4, len(train_pairs))], start=1):\n                    self._log_progress('unet_patches', 100.0 * u / max(1, min(4, len(train_pairs))), substage='extract_train_patch', file_name=img_path.name, index=u, total=max(1, min(4, len(train_pairs))))\n                    vol = self._load_volume(img_path)\n                    lbl = self._load_label_2d(lbl_path)\n                    px, py = _extract_2p5d_patches(vol, lbl, self.cfg, rng)\n                    if px.shape[0] > 0:\n                        train_patch_x.append(px)\n                        train_patch_y.append(py)\n                for u, (img_path, lbl_path) in enumerate(val_pairs[: min(2, len(val_pairs))], start=1):\n                    self._log_progress('unet_patches_val', 100.0 * u / max(1, min(2, len(val_pairs))), substage='extract_val_patch', file_name=img_path.name, index=u, total=max(1, min(2, len(val_pairs))))\n                    vol = self._load_volume(img_path)\n                    lbl = self._load_label_2d(lbl_path)\n                    px, py = _extract_2p5d_patches(vol, lbl, self.cfg, rng)\n                    if px.shape[0] > 0:\n                        val_patch_x.append(px)\n                        val_patch_y.append(py)\n                if train_patch_x and val_patch_x:\n                    tx = np.concatenate(train_patch_x, axis=0)\n                    ty = np.concatenate(train_patch_y, axis=0)\n                    vx = np.concatenate(val_patch_x, axis=0)\n                    vy = np.concatenate(val_patch_y, axis=0)\n                    unet_info = train_unet_25d_supervised(tx, ty, vx, vy, self.cfg, rng)\n                    unet_info['train_patches'] = int(tx.shape[0])\n                    unet_info['val_patches'] = int(vx.shape[0])\n                else:\n                    unet_info = {'status': 'no_patches_extracted'}\n            except Exception as exc:\n                unet_info = {'status': 'error', 'message': str(exc)}\n\n        self.supervised_train_info = {**info, 'unet_25d': unet_info}\n        self.learning_audit = {\n            'learning_percent_real': self._compute_learning_percent_real(self.supervised_train_info),\n            'epochs_configured': int(self.cfg.supervised_epochs),\n            'epochs_observed': len(self.supervised_train_info.get('epoch_history', [])),\n            'epochs_effective': int(self.supervised_train_info.get('epochs_effective', len(self.supervised_train_info.get('epoch_history', [])))),\n            'nx_neuron_formal': {\n                'activation': 'sigmoid(wx + b + alphagrad + betalaplace)',\n                'training': 'proximal gradient with l1/l2 + threshold calibration',\n                'state': 'w,b,alpha,beta + evolution memory events',\n            },\n        }\n        self._assert_no_hardcoded_metric_pattern(self.supervised_train_info)\n        self._assert_train_completed_100()\n        self.log(\n            'SUPERVISED_TRAIN',\n            status='ok',\n            train_samples=int(x_train.shape[0]),\n            val_samples=int(x_val.shape[0]),\n            train_volumes=len(train_pairs),\n            val_volumes=len(val_pairs),\n            train_volume_files=[p.name for p, _ in train_pairs],\n            val_volume_files=[p.name for p, _ in val_pairs],\n            train_info=self.supervised_train_info,\n            learning_audit=self.learning_audit,\n        )\n\n    def _load_volume(self, path: Path) -> np.ndarray:\n        self.plan.update('load', 25.0)\n        self._log_progress('load', 25.0, substage='start_load', file_name=path.name)\n        if self.cfg.ultra_step_log:\n            self.log('STEP', name='load_start', file=str(path))\n        vol = read_tiff_lzw_safe(path).astype(np.float32)\n        if vol.ndim != 3:\n            raise RuntimeError(f'Unsupported TIFF shape for {path.name}: {vol.shape}')\n        if vol.shape[0] > self.cfg.max_layers:\n            vol = vol[: self.cfg.max_layers]\n        vol = (vol - float(vol.min())) / (float(vol.max()) - float(vol.min()) + 1e-6)\n        self._log_array_ultra('volume', vol)\n        self.plan.update('load', 100.0, done=True)\n        self._log_progress('load', 100.0, substage='done_load', file_name=path.name)\n        return vol\n\n    def _predict_mask(self, vol: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:\n        self.plan.update('features', 10.0)\n        self._log_progress('features', 10.0, substage='start_extract')\n        if self.cfg.ultra_step_log:\n            self.log('STEP', name='features_extract_start')\n        features, names = extract_multi_features(vol)\n        selected, selected_names, variances = auto_select_features(features, names, self.cfg.top_k_features)\n        self._log_array_ultra('features_selected', selected)\n        self.plan.update('features', 100.0, done=True)\n        self._log_progress('features', 100.0, substage='features_ready')\n\n        self.plan.update('train', 15.0)\n        self._log_progress('train', 15.0, substage='predict_train_path')\n        if self.cfg.ultra_step_log:\n            self.log('STEP', name='train_start')\n        if self.supervised_model is not None and self.supervised_train_info is not None:\n            model = self.supervised_model\n            train_info = self.supervised_train_info\n            train_mode = 'supervised'\n        else:\n            if self.cfg.forbid_autonomous_mode:\n                raise RuntimeError('AUTONOMOUS_MODE_FORBIDDEN: supervised NX pipeline is mandatory in v134')\n            if self.cfg.supervised_train and self.cfg.strict_no_fallback:\n                raise RuntimeError('STRICT_NO_FALLBACK: autonomous fallback blocked while supervised_train is enabled')\n            rng = np.random.default_rng(47)\n            model, train_info = train_nx47_autonomous(selected, self.cfg, rng, self.evolution)\n            train_mode = 'autonomous_fallback'\n        self.plan.update('train', 100.0, done=True)\n        self._log_progress('train', 100.0, substage='train_done')\n\n        self.plan.update('segment', 20.0)\n        self._log_progress('segment', 20.0, substage='segment_start')\n        if self.cfg.ultra_step_log:\n            self.log('STEP', name='segment_start')\n        x_full = selected.reshape(selected.shape[0], -1).T.astype(np.float64)\n        grad_x_full = np.gradient(x_full, axis=0)\n        prob = model.predict_proba(x_full, grad_x_full).reshape(selected.shape[1:]).astype(np.float32)\n        self._log_array_ultra('probability_map', prob)\n\n        hysteresis_mask = hysteresis_topology_3d(prob, self.cfg)\n        calibrated_mask_scan, ratio_info = choose_adaptive_ratio(prob, self.cfg.ratio_candidates)\n        slice_ratio_info = choose_slicewise_adaptive_ratio(vol, prob, self.cfg.ratio_candidates)\n        calibrated_mask = np.logical_or(calibrated_mask_scan, slice_ratio_info['mask_global'])\n        final = (hysteresis_mask | calibrated_mask).astype(np.uint8)\n        self._log_progress('segment', 75.0, substage='masks_combined')\n\n        self._log_array_ultra('mask_hysteresis', hysteresis_mask.astype(np.uint8))\n        self._log_array_ultra('mask_calibrated', calibrated_mask.astype(np.uint8))\n        self._log_array_ultra('mask_final', final)\n\n        lbl, comp_count = label(final)\n        papyrus_wo_anchor = np.logical_and(calibrated_mask, ~hysteresis_mask)\n        golden_nonce = np.logical_and(prob > np.percentile(prob, 99.99), final > 0)\n        yy, xx = np.where(golden_nonce)\n        nonce_values = prob[yy, xx] if yy.size else np.array([], dtype=np.float32)\n        if yy.size:\n            ord_idx = np.argsort(nonce_values)[::-1][: self.cfg.golden_nonce_topk]\n            golden_nonce_points = [\n                {'y': int(yy[k]), 'x': int(xx[k]), 'score': float(nonce_values[k])}\n                for k in ord_idx\n            ]\n        else:\n            golden_nonce_points = []\n        patterns = comp_count\n        anomalies = int(np.sum(np.abs(laplace(prob)) > np.percentile(np.abs(laplace(prob)), 99.95)))\n        unknown_discoveries = int(np.sum(prob > 0.9995))\n\n        # approximate operations (coarse estimator)\n        pixels2d = int(prob.size)\n        ops_est = int(pixels2d * (selected.shape[0] * 12 + 200))\n\n        prob_audit = audit_logits_distribution(prob, None, self.cfg.logit_hist_bins) if self.cfg.export_logit_audit else {}\n\n        self._log_progress('segment', 100.0, substage='segment_done')\n        metrics = {\n            'selected_features': selected_names,\n            'feature_variances': {names[i]: float(variances[i]) for i in range(len(names))},\n            'train_info': train_info,\n            'train_mode': train_mode,\n            'active_ratio_final': float(final.mean()),\n            'active_ratio_hysteresis': float(hysteresis_mask.mean()),\n            'active_ratio_calibrated': float(calibrated_mask.mean()),\n            'pixels_anchor_detected': int(hysteresis_mask.sum()),\n            'pixels_papyrus_without_anchor': int(papyrus_wo_anchor.sum()),\n            'materials_detected': int(comp_count),\n            'patterns_detected': int(patterns),\n            'golden_nonce_detected': int(golden_nonce.sum()),\n            'golden_nonce_points_topk': golden_nonce_points,\n            'probability_audit': prob_audit,\n            'unknown_discoveries': int(unknown_discoveries),\n            'anomalies_detected': int(anomalies),\n            'pixels_processed_2d': pixels2d,\n            'slices_processed': int(vol.shape[0]),\n            'calc_ops_estimated': ops_est,\n            'ratio_adaptive_selected': float(ratio_info['selected_ratio']),\n            'ratio_slice_global_selected': float(slice_ratio_info['ratio_global_selected']),\n            'ratio_slice_profile': slice_ratio_info['slice_ratio_profile'],\n            'ratio_slice_mean': slice_ratio_info['slice_ratio_mean'],\n            'ratio_slice_std': slice_ratio_info['slice_ratio_std'],\n            'ratio_scan': ratio_info['ratio_scan'],\n            'meta_neuron_candidates': int(self.cfg.meta_neurons * len(self.cfg.l1_candidates) * len(self.cfg.l2_candidates)),\n            'mutation_applied': bool(train_info.get('mutation_applied', False)),\n            'pruning_applied': bool(train_info.get('pruning_applied', False)),\n            'active_neurons_start': int(train_info['selected_hyperparams'].get('active_neurons_start', 0)),\n            'active_neurons_mid': int(train_info['selected_hyperparams'].get('active_neurons_mid', 0)),\n            'active_neurons_end': int(train_info['selected_hyperparams'].get('active_neurons_end', 0)),\n        }\n        proxy_like = train_info['selected_hyperparams'].get('proxy_f1', train_info['selected_hyperparams'].get('val_f1', 0.0))\n        self.evolution.update(proxy_like, slice_ratio_info['ratio_global_selected'])\n        return final, metrics\n\n    def _validate_submission_competition_rules(self, expected_test_files: List[Path]) -> Dict[str, Any]:\n        import zipfile\n        if not self.cfg.enforce_competition_rules:\n            return {'status': 'disabled'}\n        if not self.submission_path.exists():\n            raise RuntimeError('RULES_VALIDATION_FAILED: submission.zip missing')\n        with zipfile.ZipFile(self.submission_path, 'r') as zf:\n            members = [n for n in zf.namelist() if n.lower().endswith('.tif')]\n        expected = sorted([p.name for p in expected_test_files])\n        got = sorted([Path(m).name for m in members])\n        if expected != got:\n            raise RuntimeError(f'RULES_VALIDATION_FAILED: submission members mismatch expected={len(expected)} got={len(got)}')\n        rules_exists = Path(self.cfg.competition_rules_path).exists()\n        demo_exists = Path(self.cfg.metric_demo_notebook_path).exists()\n        status = {\n            'status': 'ok',\n            'expected_test_files': len(expected),\n            'submission_tif_files': len(got),\n            'rules_file_found': bool(rules_exists),\n            'metric_demo_found': bool(demo_exists),\n        }\n        self.log('COMPETITION_RULES_VALIDATION', **status)\n        return status\n\n    def run_simulation_100(self) -> Dict[str, Any]:\n        rng = np.random.default_rng(123)\n        f1_scores = []\n        for _ in range(100):\n            prob = rng.random((128, 128), dtype=np.float32)\n            pseudo = prob > np.percentile(prob, 94.0)\n            f1_scores.append(compute_proxy_f1(prob, pseudo.astype(np.float32), threshold=0.5))\n        summary = {\n            'samples': 100,\n            'f1_mean': float(np.mean(f1_scores)),\n            'f1_std': float(np.std(f1_scores)),\n            'f1_min': float(np.min(f1_scores)),\n            'f1_max': float(np.max(f1_scores)),\n        }\n        self.log('SIMULATION_100', **summary)\n        return summary\n\n    def run(self) -> Path:\n        t_global = time.perf_counter()\n        files = self.discover_inputs()\n        self._run_preflight_5pct(files)\n        self.build_supervised_model()\n        self.plan.update('package', 10.0)\n        sup_f1_values: List[float] = []\n        sup_iou_values: List[float] = []\n        sup_th_values: List[float] = []\n        prob_max_values: List[float] = []\n        prob_mean_values: List[float] = []\n        prob_std_values: List[float] = []\n\n        with zipfile.ZipFile(self.submission_path, 'w', zipfile.ZIP_STORED) as zf:\n            for i, fpath in enumerate(files, start=1):\n                t0 = time.perf_counter()\n                self.log('FILE_START', file=fpath.name, index=i, total=len(files))\n                self._log_progress('package', 10.0 + 85.0 * ((i - 1) / max(1, len(files))), substage='file_start', file_name=fpath.name, index=i, total=len(files))\n                for st in ('load', 'features', 'train', 'segment'):\n                    self.plan.update(st, 0.0, done=False)\n\n                self._log_heartbeat('file_processing', file_name=fpath.name, note='start_file_compute', index=i, total=len(files))\n                vol = self._load_volume(fpath)\n                mask2d, m = self._predict_mask(vol)\n                self._log_heartbeat('file_processing', file_name=fpath.name, note='end_file_compute', index=i, total=len(files))\n                self.log('NX47_METRICS', file=fpath.name, **m)\n\n                self.global_stats['files_processed'] += 1\n                self.global_stats['slices_processed'] += m['slices_processed']\n                self.global_stats['pixels_processed'] += int(vol.size)\n                self.global_stats['pixels_anchor_detected'] += m['pixels_anchor_detected']\n                self.global_stats['pixels_papyrus_without_anchor'] += m['pixels_papyrus_without_anchor']\n                self.global_stats['materials_detected'] += m['materials_detected']\n                self.global_stats['patterns_detected'] += m['patterns_detected']\n                self.global_stats['golden_nonce_detected'] += m['golden_nonce_detected']\n                self.global_stats['unknown_discoveries'] += m['unknown_discoveries']\n                self.global_stats['anomalies_detected'] += m['anomalies_detected']\n                self.global_stats['calc_ops_estimated'] += m['calc_ops_estimated']\n                self.global_stats['active_neurons_start_total'] += m['active_neurons_start']\n                self.global_stats['active_neurons_mid_total'] += m['active_neurons_mid']\n                self.global_stats['active_neurons_end_total'] += m['active_neurons_end']\n                self.global_stats['meta_neuron_candidates'] += m['meta_neuron_candidates']\n                self.global_stats['mutation_events'] += int(m['mutation_applied'])\n                self.global_stats['pruning_events'] += int(m['pruning_applied'])\n                pa = m.get('probability_audit', {})\n                if isinstance(pa, dict):\n                    prob_max_values.append(float(pa.get('max', 0.0)))\n                    prob_mean_values.append(float(pa.get('mean', 0.0)))\n                    prob_std_values.append(float(pa.get('std', 0.0)))\n                if m.get('train_mode') == 'supervised':\n                    self.global_stats['files_supervised_mode'] += 1\n                    shp = m.get('train_info', {}).get('selected_hyperparams', {})\n                    if 'val_f1' in shp:\n                        sup_f1_values.append(float(shp['val_f1']))\n                    if 'val_iou' in shp:\n                        sup_iou_values.append(float(shp['val_iou']))\n                    if 'best_threshold' in shp:\n                        sup_th_values.append(float(shp['best_threshold']))\n                else:\n                    self.global_stats['files_autonomous_fallback'] += 1\n\n                out_mask = self.tmp_dir / fpath.name\n                write_tiff_lzw_safe(out_mask, mask2d[np.newaxis, ...])\n                zf.write(out_mask, arcname=fpath.name)\n                out_mask.unlink(missing_ok=True)\n                gc.collect()\n\n                dt = max(1e-9, time.perf_counter() - t0)\n                cps = m['calc_ops_estimated'] / dt\n                self.log('FILE_DONE', file=fpath.name, active_ratio=round(float(mask2d.mean()), 6), calc_per_sec=float(cps), elapsed_s=round(dt, 3))\n                self.plan.update('package', 10.0 + 85.0 * (i / len(files)))\n                self._log_progress('package', 10.0 + 85.0 * (i / max(1, len(files))), substage='file_done', file_name=fpath.name, index=i, total=len(files))\n\n        rules_validation = self._validate_submission_competition_rules(files)\n\n        total_dt = max(1e-9, time.perf_counter() - t_global)\n        self.global_stats['calc_per_sec_global'] = float(self.global_stats['calc_ops_estimated'] / total_dt)\n        self.global_stats['elapsed_total_s'] = float(total_dt)\n        self.global_stats['ratio_selected_mean'] = float(np.mean(self.evolution.ratio_history)) if self.evolution.ratio_history else 0.0\n        self.global_stats['val_f1_mean_supervised'] = float(np.mean(sup_f1_values)) if sup_f1_values else 0.0\n        self.global_stats['val_iou_mean_supervised'] = float(np.mean(sup_iou_values)) if sup_iou_values else 0.0\n        self.global_stats['best_threshold_mean_supervised'] = float(np.mean(sup_th_values)) if sup_th_values else 0.0\n\n        if self.supervised_train_info is not None:\n            uinfo = self.supervised_train_info.get('unet_25d', {})\n            self.global_stats['unet_25d_status'] = str(uinfo.get('status', 'n/a'))\n            self.global_stats['unet_25d_best_fbeta'] = float(uinfo.get('best', {}).get('val_fbeta', 0.0)) if isinstance(uinfo.get('best', {}), dict) else 0.0\n\n        f1_curve = simulate_f1_vs_ratio_curve()\n        self.global_stats['f1_ratio_curve_best_ratio'] = float(f1_curve['best_ratio'])\n        self.global_stats['f1_ratio_curve_best_f1'] = float(f1_curve['best_f1'])\n\n        sim = self.run_simulation_100() if self.cfg.run_simulation_100 else None\n\n        self.global_stats['probability_max_observed'] = float(np.max(prob_max_values)) if prob_max_values else 0.0\n        self.global_stats['probability_mean_observed'] = float(np.mean(prob_mean_values)) if prob_mean_values else 0.0\n        self.global_stats['probability_std_observed'] = float(np.mean(prob_std_values)) if prob_std_values else 0.0\n        self.global_stats['forensic_report_generated'] = bool(self.cfg.export_forensic_v139_report)\n        self.global_stats['learning_percent_real'] = float(self.learning_audit.get('learning_percent_real', 0.0))\n        self.global_stats['reasoning_trace_events'] = int(len(self.logs))\n        self.global_stats['train_pair_count_discovered'] = int(self.train_dataset_audit.get('pair_count_discovered', 0))\n        self.global_stats['train_pair_coverage_pct'] = float(self.train_dataset_audit.get('coverage_pct_selected_vs_discovered', 0.0))\n        self.log('GLOBAL_STATS', **self.global_stats)\n\n        forensic_report = self._build_v139_forensic_report() if self.cfg.export_forensic_v139_report else {'status': 'disabled'}\n        self.forensic_report_path.write_text(json.dumps(forensic_report, indent=2, ensure_ascii=False), encoding='utf-8')\n\n        metadata = {\n            'version': self.version,\n            'root': str(self.root),\n            'input_dir': str(self.test_dir),\n            'submission_zip': str(self.submission_path),\n            'log_count': len(self.logs),\n            'ultra_log': str(self.ultra_log_path),\n            'hardware': probe_hardware_metrics(),\n            'global_stats': self.global_stats,\n            'evolution_memory': asdict(self.evolution),\n            'supervised_train_info': self.supervised_train_info,\n            'simulation_100': sim,\n            'f1_ratio_curve': f1_curve,\n            'config': asdict(self.cfg),\n            'nx_continuity_matrix': self.continuity_matrix,\n            'line_by_line_review': 'completed_v138',\n            'train_pairs_required': int(self.cfg.min_train_pairs_required),\n            'train_image_files_required': int(self.cfg.min_train_image_files_required),\n            'train_label_files_required': int(self.cfg.min_train_label_files_required),\n            'require_train_completion_100': bool(self.cfg.require_train_completion_100),\n            'forbid_autonomous_mode': bool(self.cfg.forbid_autonomous_mode),\n            'enforce_no_hardcoded_metrics': bool(self.cfg.enforce_no_hardcoded_metrics),\n            'hardcoded_metric_policy': str(self.cfg.hardcoded_metric_policy),\n            'learning_audit': self.learning_audit,\n            'train_dataset_audit': self.train_dataset_audit,\n            'forensic_report': forensic_report,\n            'competition_rules_validation': rules_validation,\n            'proof_bundle': {\n                'has_global_stats': True,\n                'has_exec_complete': True,\n                'submission_zip_expected': str(self.submission_path),\n                'kernel_version': self.version,\n            },\n        }\n        self.plan.update('package', 100.0, done=True)\n        self.log('EXEC_COMPLETE', submission=str(self.submission_path))\n\n        self.metadata_path.write_text(json.dumps(metadata, indent=2), encoding='utf-8')\n        self.logs_path.write_text(json.dumps(self.logs, indent=2), encoding='utf-8')\n        self.memory_path.write_text(json.dumps(self.memory.events, indent=2), encoding='utf-8')\n        return self.submission_path\n\n\nif __name__ == '__main__':\n    cfg = V139Config(\n        top_k_features=int(os.environ.get('V139_TOP_K_FEATURES', '6')),\n        target_active_ratio=float(os.environ.get('V139_TARGET_ACTIVE_RATIO', '0.03')),\n        full_pixel_trace=os.environ.get('V139_FULL_PIXEL_TRACE', '0') == '1',\n        trace_pixel_budget=int(os.environ.get('V139_TRACE_PIXEL_BUDGET', '4000')),\n        ultra_console_log=os.environ.get('V139_ULTRA_CONSOLE_LOG', '1') == '1',\n        ultra_step_log=os.environ.get('V139_ULTRA_STEP_LOG', '1') == '1',\n        ultra_bit_trace_arrays=os.environ.get('V139_ULTRA_BIT_TRACE_ARRAYS', '1') == '1',\n        ultra_bit_trace_limit=int(os.environ.get('V139_ULTRA_BIT_TRACE_LIMIT', '64')),\n        meta_neurons=int(os.environ.get('V139_META_NEURONS', '3')),\n        run_simulation_100=os.environ.get('V139_RUN_SIMULATION_100', '0') == '1',\n        simulation_export_curve=os.environ.get('V139_SIMULATION_EXPORT_CURVE', '1') == '1',\n        supervised_train=os.environ.get('V139_SUPERVISED_TRAIN', '1') == '1',\n        max_train_volumes=int(os.environ.get('V139_MAX_TRAIN_VOLUMES', '24')),\n        max_val_volumes=int(os.environ.get('V139_MAX_VAL_VOLUMES', '8')),\n        max_samples_per_volume=int(os.environ.get('V139_MAX_SAMPLES_PER_VOLUME', '40000')),\n        pos_neg_ratio=float(os.environ.get('V139_POS_NEG_RATIO', '1.0')),\n        golden_nonce_topk=int(os.environ.get('V139_GOLDEN_NONCE_TOPK', '11')),\n        supervised_epochs=int(os.environ.get('V139_SUPERVISED_EPOCHS', '0')),\n        fbeta_beta=float(os.environ.get('V139_F_BETA', '0.5')),\n        use_unet_25d=os.environ.get('V139_USE_UNET_25D', '1') == '1',\n        unet_in_slices=int(os.environ.get('V139_UNET_IN_SLICES', '7')),\n        unet_base_channels=int(os.environ.get('V139_UNET_BASE_CHANNELS', '24')),\n        patch_size=int(os.environ.get('V139_PATCH_SIZE', '128')),\n        patch_stride=int(os.environ.get('V139_PATCH_STRIDE', '64')),\n        unet_epochs=int(os.environ.get('V139_UNET_EPOCHS', '2')),\n        unet_lr=float(os.environ.get('V139_UNET_LR', '0.001')),\n        unet_batch_size=int(os.environ.get('V139_UNET_BATCH_SIZE', '8')),\n        export_logit_audit=os.environ.get('V139_EXPORT_LOGIT_AUDIT', '1') == '1',\n        logit_hist_bins=int(os.environ.get('V139_LOGIT_HIST_BINS', '20')),\n        v130_log_path=os.environ.get('V139_SOURCE_V130_LOG', 'nx47-vesu-kernel-new-v130.log'),\n        export_forensic_v139_report=os.environ.get('V139_EXPORT_FORENSIC_REPORT', '1') == '1',\n        enforce_nx_legacy_continuity=os.environ.get('V139_ENFORCE_NX_CONTINUITY', '1') == '1',\n        strict_no_fallback=os.environ.get('V139_STRICT_NO_FALLBACK', '1') == '1',\n        min_train_pairs_required=int(os.environ.get('V139_MIN_TRAIN_PAIRS_REQUIRED', '786')),\n        require_train_completion_100=os.environ.get('V139_REQUIRE_TRAIN_COMPLETION_100', '1') == '1',\n        forbid_autonomous_mode=os.environ.get('V139_FORBID_AUTONOMOUS_MODE', '1') == '1',\n        enforce_no_hardcoded_metrics=os.environ.get('V139_ENFORCE_NO_HARDCODED_METRICS', '1') == '1',\n        hardcoded_metric_policy=os.environ.get('V139_HARDCODED_METRIC_POLICY', 'warn'),\n        adapt_train_threshold_to_dataset_size=os.environ.get('V139_ADAPT_TRAIN_THRESHOLD_TO_DATASET_SIZE', '1') == '1',\n        train_pair_coverage_target_pct=float(os.environ.get('V139_TRAIN_PAIR_COVERAGE_TARGET_PCT', '100.0')),\n        min_train_image_files_required=int(os.environ.get('V139_MIN_TRAIN_IMAGE_FILES_REQUIRED', '786')),\n        min_train_label_files_required=int(os.environ.get('V139_MIN_TRAIN_LABEL_FILES_REQUIRED', '786')),\n        enforce_competition_rules=os.environ.get('V139_ENFORCE_COMPETITION_RULES', '1') == '1',\n        competition_rules_path=os.environ.get('V139_COMPETITION_RULES_PATH', 'Competition_Rules_Vesuvius_Challenge _Surface_Detection.md'),\n        metric_demo_notebook_path=os.environ.get('V139_METRIC_DEMO_NOTEBOOK_PATH', 'vesuvius-2025-metric-demo.ipynb'),\n        convergence_patience=int(os.environ.get('V139_CONVERGENCE_PATIENCE', '5')),\n        convergence_min_delta=float(os.environ.get('V139_CONVERGENCE_MIN_DELTA', '1e-6')),\n        auto_epoch_safety_cap=int(os.environ.get('V139_AUTO_EPOCH_SAFETY_CAP', '0')),\n        preflight_train_pct=float(os.environ.get('V139_PREFLIGHT_TRAIN_PCT', '5.0')),\n        preflight_test_pct=float(os.environ.get('V139_PREFLIGHT_TEST_PCT', '5.0')),\n        progress_bar_width=int(os.environ.get('V139_PROGRESS_BAR_WIDTH', '24')),\n        heartbeat_interval_s=float(os.environ.get('V139_HEARTBEAT_INTERVAL_S', '30.0')),\n        stage_stall_alert_s=float(os.environ.get('V139_STAGE_STALL_ALERT_S', '180.0')),\n        run_ablation_check=os.environ.get('V139_RUN_ABLATION_CHECK', '1') == '1',\n        stability_probe_runs=int(os.environ.get('V139_STABILITY_PROBE_RUNS', '0')),\n    )\n    kernel = NX47V139Kernel(\n        root=Path(os.environ.get('VESUVIUS_ROOT', '/kaggle/input/competitions/vesuvius-challenge-surface-detection')),\n        output_dir=Path(os.environ.get('VESUVIUS_OUTPUT', '/kaggle/working')),\n        config=cfg,\n    )\n    submission = kernel.run()\n    print(f'READY: {submission}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}