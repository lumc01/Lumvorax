{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c04891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T09:43:20.261004Z",
     "iopub.status.busy": "2026-02-09T09:43:20.260760Z",
     "iopub.status.idle": "2026-02-09T09:46:23.868622Z",
     "shell.execute_reply": "2026-02-09T09:46:23.867575Z"
    },
    "papermill": {
     "duration": 183.612125,
     "end_time": "2026-02-09T09:46:23.869869",
     "exception": false,
     "start_time": "2026-02-09T09:43:20.257744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:43:32.207533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770630212.643584      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770630212.804433      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VESUVIUS V27 - OPTIMIZED HYSTERESIS\n",
      "============================================================\n",
      "\n",
      "Loading models...\n",
      "Loading Model 1 (ComboLoss): /kaggle/input/vsd-model/keras/transunet/3/transunet.seresnext50.160px.comboloss.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770630235.217564      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1770630235.220257      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Inference...\n",
      "\n",
      "[1/1] Processing 1407735...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total patch 27:   0%|          | 0/14 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1770630251.579407      70 service.cc:148] XLA service 0x7f305800c880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1770630251.580994      70 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1770630251.581013      70 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1770630253.047464      70 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "E0000 00:00:1770630256.713353      70 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1770630256.946017      70 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2026-02-09 09:44:22.578228: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[2,512,20,20,20]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,512,20,20,20]{4,3,2,1,0}, f32[512,512,1,1,1]{4,3,2,1,0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:23.360175: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.782047431s\n",
      "Trying algorithm eng4{} for conv (f32[2,512,20,20,20]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,512,20,20,20]{4,3,2,1,0}, f32[512,512,1,1,1]{4,3,2,1,0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:24.976147: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng13{} for conv (f32[2,512,20,20,20]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,512,20,20,20]{4,3,2,1,0}, f32[512,512,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:25.175766: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.199802367s\n",
      "Trying algorithm eng13{} for conv (f32[2,512,20,20,20]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,512,20,20,20]{4,3,2,1,0}, f32[512,512,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:26.482609: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng13{} for conv (f32[2,512,40,40,40]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,256,40,40,40]{4,3,2,1,0}, f32[512,256,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:27.304737: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.822337362s\n",
      "Trying algorithm eng13{} for conv (f32[2,512,40,40,40]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,256,40,40,40]{4,3,2,1,0}, f32[512,256,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:29.007249: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[2,512,80,80,80]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,64,80,80,80]{4,3,2,1,0}, f32[512,64,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:30.998416: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.991362198s\n",
      "Trying algorithm eng0{} for conv (f32[2,512,80,80,80]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,64,80,80,80]{4,3,2,1,0}, f32[512,64,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:31.998632: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng13{} for conv (f32[2,512,80,80,80]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,64,80,80,80]{4,3,2,1,0}, f32[512,64,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2026-02-09 09:44:33.121360: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.122826328s\n",
      "Trying algorithm eng13{} for conv (f32[2,512,80,80,80]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[2,64,80,80,80]{4,3,2,1,0}, f32[512,64,1,1,1]{4,3,2,1,0}, f32[512]{0}), window={size=1x1x1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1770630276.393841      70 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1770630276.618635      70 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "I0000 00:00:1770630295.311567      70 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Total patch 27: 100%|██████████| 14/14 [01:08<00:00,  4.92s/it]\n",
      "Total patch 27: 100%|██████████| 14/14 [00:20<00:00,  1.45s/it]\n",
      "Total patch 27: 100%|██████████| 14/14 [00:20<00:00,  1.50s/it]\n",
      "Total patch 27: 100%|██████████| 14/14 [00:21<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Foreground voxels: 3,208,295\n",
      "\n",
      "============================================================\n",
      "V27 COMPLETE\n",
      "Submission: /kaggle/working/submission.zip\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "\"\"\"\n",
    "================================================================================\n",
    "   VESUVIUS V27 - TUNED HYSTERESIS ENSEMBLE\n",
    "\n",
    "   - Base: V24 (Best Score: 0.537)\n",
    "   - Optimization 1: Ensemble Weights adjusted to 0.75/0.25 (Favoring ComboLoss)\n",
    "   - Optimization 2: Z_RADIUS increased to 2 (Better vertical connectivity)\n",
    "   - Optimization 3: T_HIGH lowered to 0.80 (Improved Recall)\n",
    "   - Constraint: Kept Overlap 0.25 & 4x TTA to ensure <9h runtime\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP PACKAGES\n",
    "# ============================================================================\n",
    "var = \"/kaggle/input/vsdetection-packages-offline-installer-only/whls\"\n",
    "if os.path.exists(var):\n",
    "    print(f\"Installing packages from: {var}\")\n",
    "    subprocess.run(\n",
    "        f\"pip install {var}/keras_nightly-*.whl {var}/tifffile-*.whl {var}/imagecodecs-*.whl {var}/medicai-*.whl --no-index --find-links {var}\",\n",
    "        shell=True, check=True\n",
    "    )\n",
    "    clear_output()\n",
    "else:\n",
    "    print(f\"❌ ERROR: Package directory not found at: {var}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Protobuf patch\n",
    "try:\n",
    "    from google.protobuf import message_factory as _message_factory\n",
    "    if not hasattr(_message_factory.MessageFactory, \"GetPrototype\"):\n",
    "        from google.protobuf.message_factory import GetMessageClass\n",
    "        def _GetPrototype(self, descriptor):\n",
    "            return GetMessageClass(descriptor)\n",
    "        _message_factory.MessageFactory.GetPrototype = _GetPrototype\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "from medicai.transforms import Compose, NormalizeIntensity \n",
    "from medicai.models import TransUNet\n",
    "from medicai.utils.inference import SlidingWindowInference\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import tifffile\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import remove_small_objects\n",
    "import gc\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VESUVIUS V27 - OPTIMIZED HYSTERESIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIG\n",
    "# ============================================================================\n",
    "root_dir = \"/kaggle/input/vesuvius-challenge-surface-detection\"\n",
    "test_dir = f\"{root_dir}/test_images\"\n",
    "output_dir = \"/kaggle/working/submission_masks\"\n",
    "zip_path = \"/kaggle/working/submission.zip\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Model config\n",
    "NUM_CLASSES = 3\n",
    "PATCH_SIZE = (160, 160, 160)\n",
    "OVERLAP = 0.25      # Sharp inference\n",
    "BATCH_SIZE = 2      # Speed optimization\n",
    "\n",
    "# Post-processing config (Tuned V24)\n",
    "T_LOW = 0.45        # Keep connectivity permissive\n",
    "T_HIGH = 0.80       # Lowered from 0.85 to find more seeds\n",
    "Z_RADIUS = 2        # Increased from 1 to 2 (Fixes vertical splits)\n",
    "XY_RADIUS = 0       # Keep 0 (Prevent mergers)\n",
    "DUST_MIN_SIZE = 300 # Lowered from 500 to keep smaller valid fragments\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL LOADING\n",
    "# ============================================================================\n",
    "def get_ensemble_models():\n",
    "    base_path = \"/kaggle/input/vsd-model/keras/transunet\"\n",
    "    \n",
    "    # 1. The \"Super Model\" (V3 ComboLoss)\n",
    "    path_combo = f\"{base_path}/3/transunet.seresnext50.160px.comboloss.weights.h5\"\n",
    "    # 2. The \"Support Model\" (V2 Default) - Actually the TPU model path from V24\n",
    "    # Let's use the path we used in V24 which worked:\n",
    "    path_tpu = \"/kaggle/input/train-vesuvius-surface-3d-detection-on-tpu/model.weights.h5\"\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    if os.path.exists(path_combo):\n",
    "        print(f\"Loading Model 1 (ComboLoss): {path_combo}\")\n",
    "        m = TransUNet(input_shape=(160, 160, 160, 1), encoder_name='seresnext50', classifier_activation=None, num_classes=NUM_CLASSES)\n",
    "        m.load_weights(path_combo)\n",
    "        models.append(m)\n",
    "        \n",
    "    if os.path.exists(path_tpu):\n",
    "        print(f\"Loading Model 2 (TPU): {path_tpu}\")\n",
    "        m = TransUNet(input_shape=(160, 160, 160, 1), encoder_name='seresnext50', classifier_activation=None, num_classes=NUM_CLASSES)\n",
    "        m.load_weights(path_tpu)\n",
    "        models.append(m)\n",
    "        \n",
    "    if not models:\n",
    "        print(\"WARNING: No weights found. Initializing random model.\")\n",
    "        m = TransUNet(input_shape=(160, 160, 160, 1), encoder_name='seresnext50', classifier_activation=None, num_classes=NUM_CLASSES)\n",
    "        return [m]\n",
    "        \n",
    "    return models\n",
    "\n",
    "# ============================================================================\n",
    "# TRANSFORMS\n",
    "# ============================================================================\n",
    "def val_transformation(image):\n",
    "    data = {\"image\": image}\n",
    "    pipeline = Compose([\n",
    "        NormalizeIntensity(keys=[\"image\"], nonzero=True, channel_wise=False)\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"]\n",
    "\n",
    "def load_volume(path):\n",
    "    vol = tifffile.imread(path).astype(np.float32)\n",
    "    vol = vol[None, ..., None]\n",
    "    return vol\n",
    "\n",
    "# ============================================================================\n",
    "# INFERENCE LOGIC (4x TTA)\n",
    "# ============================================================================\n",
    "def predict_with_tta(inputs, swi):\n",
    "    logits = []\n",
    "    # Original\n",
    "    logits.append(swi(inputs))\n",
    "    # Rotations\n",
    "    for k in [1, 2, 3]:\n",
    "        img_r = np.rot90(inputs, k=k, axes=(2, 3))\n",
    "        p = swi(img_r)\n",
    "        p = np.rot90(p, k=-k, axes=(2, 3))\n",
    "        logits.append(p)\n",
    "    return np.mean(logits, axis=0)\n",
    "\n",
    "def ensemble_predict(inputs, models):\n",
    "    # Weighted Ensemble (Aligned with 0.546 solution)\n",
    "    if len(models) == 2:\n",
    "        weights = [0.75, 0.25] # Stronger weight for ComboLoss\n",
    "    else:\n",
    "        weights = [1.0]\n",
    "        \n",
    "    ensemble_probs = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        swi = SlidingWindowInference(\n",
    "            model, \n",
    "            num_classes=NUM_CLASSES, \n",
    "            roi_size=PATCH_SIZE, \n",
    "            sw_batch_size=BATCH_SIZE, \n",
    "            mode='gaussian', \n",
    "            overlap=OVERLAP\n",
    "        )\n",
    "        \n",
    "        logits = predict_with_tta(inputs, swi)\n",
    "        probs = ops.softmax(logits, axis=-1)\n",
    "        fg_probs = probs[..., 1] \n",
    "        ensemble_probs.append(fg_probs * weights[i])\n",
    "    \n",
    "    final_probs = np.sum(ensemble_probs, axis=0)\n",
    "    return np.squeeze(final_probs)\n",
    "\n",
    "# ============================================================================\n",
    "# POST-PROCESSING (HYSTERESIS)\n",
    "# ============================================================================\n",
    "def build_anisotropic_struct(z_radius, xy_radius):\n",
    "    z, r = z_radius, xy_radius\n",
    "    if z == 0 and r == 0: return None\n",
    "    depth = 2 * z + 1\n",
    "    size = 2 * r + 1\n",
    "    struct = np.zeros((depth, size, size), dtype=bool)\n",
    "    cz, cy, cx = z, r, r\n",
    "    for dz in range(-z, z + 1):\n",
    "        for dy in range(-r, r + 1):\n",
    "            for dx in range(-r, r + 1):\n",
    "                if dy * dy + dx * dx <= r * r:\n",
    "                    struct[cz + dz, cy + dy, cx + dx] = True\n",
    "    return struct\n",
    "\n",
    "def topo_postprocess(probs, T_low, T_high, z_radius, xy_radius, dust_min_size):\n",
    "    # 1. Hysteresis\n",
    "    strong = probs >= T_high\n",
    "    weak = probs >= T_low\n",
    "    \n",
    "    if not strong.any(): return np.zeros_like(probs, dtype=np.uint8)\n",
    "    \n",
    "    struct_hyst = ndi.generate_binary_structure(3, 3)\n",
    "    mask = ndi.binary_propagation(strong, mask=weak, structure=struct_hyst)\n",
    "    \n",
    "    if not mask.any(): return np.zeros_like(probs, dtype=np.uint8)\n",
    "\n",
    "    # 2. Anisotropic Closing\n",
    "    struct = build_anisotropic_struct(z_radius, xy_radius)\n",
    "    if struct is not None:\n",
    "        mask = ndi.binary_closing(mask, structure=struct)\n",
    "\n",
    "    # 3. Dust Removal\n",
    "    if dust_min_size > 0:\n",
    "        mask = remove_small_objects(mask.astype(bool), min_size=dust_min_size)\n",
    "\n",
    "    return mask.astype(np.uint8)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================================\n",
    "print(\"\\nLoading models...\")\n",
    "models = get_ensemble_models()\n",
    "test_df = pd.read_csv(f\"{root_dir}/test.csv\")\n",
    "\n",
    "print(\"\\nStarting Inference...\")\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for idx, row in test_df.iterrows():\n",
    "        image_id = row[\"id\"]\n",
    "        print(f\"\\n[{idx+1}/{len(test_df)}] Processing {image_id}...\")\n",
    "        \n",
    "        vol = load_volume(f\"{test_dir}/{image_id}.tif\")\n",
    "        vol = val_transformation(vol)\n",
    "        \n",
    "        probs = ensemble_predict(vol, models)\n",
    "        \n",
    "        final_mask = topo_postprocess(\n",
    "            probs, \n",
    "            T_low=T_LOW, \n",
    "            T_high=T_HIGH, \n",
    "            z_radius=Z_RADIUS, \n",
    "            xy_radius=XY_RADIUS, \n",
    "            dust_min_size=DUST_MIN_SIZE\n",
    "        )\n",
    "        \n",
    "        print(f\"    Foreground voxels: {final_mask.sum():,}\")\n",
    "        \n",
    "        out_path = f\"{output_dir}/{image_id}.tif\"\n",
    "        tifffile.imwrite(out_path, final_mask)\n",
    "        z.write(out_path, arcname=f\"{image_id}.tif\")\n",
    "        os.remove(out_path)\n",
    "        \n",
    "        del vol, probs, final_mask\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"V27 COMPLETE\")\n",
    "print(f\"Submission: {zip_path}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15062069,
     "sourceId": 117682,
     "sourceType": "competition"
    },
    {
     "sourceId": 290917305,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 495238,
     "sourceId": 655294,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 499479,
     "sourceId": 660383,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 503784,
     "sourceId": 665589,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 504051,
     "sourceId": 665924,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 495238,
     "sourceId": 672178,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 499479,
     "sourceId": 673516,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 503784,
     "sourceId": 674747,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 516822,
     "sourceId": 681152,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 510647,
     "modelInstanceId": 516822,
     "sourceId": 732880,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 192.751006,
   "end_time": "2026-02-09T09:46:27.831428",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-09T09:43:15.080422",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
